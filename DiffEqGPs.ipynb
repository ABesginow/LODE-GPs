{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(0), float(1), int(50))\n",
    "one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8734672a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d5dedb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all kernels: [Diff_SE_kernel(), Diff_SE_kernel()]\n",
      "[[AdditiveKernel(\n",
      "  (kernels): ModuleList(\n",
      "    (0): diffed_SE_kernel()\n",
      "    (1): diffed_SE_kernel()\n",
      "  )\n",
      "), AdditiveKernel(\n",
      "  (kernels): ModuleList(\n",
      "    (0): diffed_SE_kernel()\n",
      "    (1): diffed_SE_kernel()\n",
      "  )\n",
      ")], [AdditiveKernel(\n",
      "  (kernels): ModuleList(\n",
      "    (0): diffed_SE_kernel()\n",
      "    (1): diffed_SE_kernel()\n",
      "  )\n",
      "), AdditiveKernel(\n",
      "  (kernels): ModuleList(\n",
      "    (0): diffed_SE_kernel()\n",
      "    (1): diffed_SE_kernel()\n",
      "  )\n",
      ")]]\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel()\n",
    "        kernel2 = Diff_SE_kernel()\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        L = matrix(2, 2, (1, dx1, 0, 1))\n",
    "        R = matrix(2, 2, (1, 0, dx2, 1))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        #kernel0 = Diff_SE_kernel()\n",
    "        #kernel1 = Diff_SE_kernel()\n",
    "        #kernel2 = Diff_SE_kernel()\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel2]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([0., 0.], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([0.], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.6055, 0.6063, 0.6065],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.6042, 0.6055, 0.6063],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.6024, 0.6042, 0.6055],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9998, 0.9992],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9998, 1.0000, 0.9998],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9992, 0.9998, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.6055, 0.6063, 0.6065],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.6042, 0.6055, 0.6063],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.6024, 0.6042, 0.6055],\n",
      "        ...,\n",
      "        [0.6055, 0.6042, 0.6024,  ..., 1.0000, 0.9998, 0.9992],\n",
      "        [0.6063, 0.6055, 0.6042,  ..., 0.9998, 1.0000, 0.9998],\n",
      "        [0.6065, 0.6063, 0.6055,  ..., 0.9992, 0.9998, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 2.0000,  0.0000,  1.9992,  ...,  0.6063,  0.6065,  0.6065],\n",
      "        [ 0.0000,  1.0000, -0.0204,  ...,  0.6189, -0.6065,  0.6065],\n",
      "        [ 1.9992, -0.0204,  2.0000,  ...,  0.6055,  0.6439,  0.6063],\n",
      "        ...,\n",
      "        [ 0.6063,  0.6189,  0.6055,  ...,  1.0000, -0.0204,  0.9998],\n",
      "        [ 0.6065, -0.6065,  0.6439,  ..., -0.0204,  2.0000,  0.0000],\n",
      "        [ 0.6065,  0.6065,  0.6063,  ...,  0.9998,  0.0000,  1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 2.0000,  0.0000,  1.9992,  ...,  0.6063,  0.6065,  0.6065],\n",
      "        [ 0.0000,  1.0000, -0.0204,  ...,  0.6189, -0.6065,  0.6065],\n",
      "        [ 1.9992, -0.0204,  2.0000,  ...,  0.6055,  0.6439,  0.6063],\n",
      "        ...,\n",
      "        [ 0.6063,  0.6189,  0.6055,  ...,  1.0000, -0.0204,  0.9998],\n",
      "        [ 0.6065, -0.6065,  0.6439,  ..., -0.0204,  2.0000,  0.0000],\n",
      "        [ 0.6065,  0.6065,  0.6063,  ...,  0.9998,  0.0000,  1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.1000, -0.1000], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.1000], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.1000, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.9000, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.9000, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.1000, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.8438, 1.8431, 1.8411,  ..., 0.4878, 0.4901, 0.4920],\n",
      "        [1.8431, 1.8438, 1.8431,  ..., 0.4851, 0.4878, 0.4901],\n",
      "        [1.8411, 1.8431, 1.8438,  ..., 0.4821, 0.4851, 0.4878],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9000, 0.8998, 0.8994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8998, 0.9000, 0.8998],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8994, 0.8998, 0.9000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.8438, 1.8431, 1.8411,  ..., 0.4878, 0.4901, 0.4920],\n",
      "        [1.8431, 1.8438, 1.8431,  ..., 0.4851, 0.4878, 0.4901],\n",
      "        [1.8411, 1.8431, 1.8438,  ..., 0.4821, 0.4851, 0.4878],\n",
      "        ...,\n",
      "        [0.4878, 0.4851, 0.4821,  ..., 0.9000, 0.8998, 0.8994],\n",
      "        [0.4901, 0.4878, 0.4851,  ..., 0.8998, 0.9000, 0.8998],\n",
      "        [0.4920, 0.4901, 0.4878,  ..., 0.8994, 0.8998, 0.9000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.8438,  0.0000,  1.8431,  ...,  0.4901,  0.6787,  0.4920],\n",
      "        [ 0.0000,  0.9000, -0.0152,  ...,  0.6054, -0.4920,  0.5954],\n",
      "        [ 1.8431, -0.0152,  1.8438,  ...,  0.4878,  0.7119,  0.4901],\n",
      "        ...,\n",
      "        [ 0.4901,  0.6054,  0.4878,  ...,  0.9000, -0.0152,  0.8998],\n",
      "        [ 0.6787, -0.4920,  0.7119,  ..., -0.0152,  1.8438,  0.0000],\n",
      "        [ 0.4920,  0.5954,  0.4901,  ...,  0.8998,  0.0000,  0.9000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.8438,  0.0000,  1.8431,  ...,  0.4901,  0.6787,  0.4920],\n",
      "        [ 0.0000,  0.9000, -0.0152,  ...,  0.6054, -0.4920,  0.5954],\n",
      "        [ 1.8431, -0.0152,  1.8438,  ...,  0.4878,  0.7119,  0.4901],\n",
      "        ...,\n",
      "        [ 0.4901,  0.6054,  0.4878,  ...,  0.9000, -0.0152,  0.8998],\n",
      "        [ 0.6787, -0.4920,  0.7119,  ..., -0.0152,  1.8438,  0.0000],\n",
      "        [ 0.4920,  0.5954,  0.4901,  ...,  0.8998,  0.0000,  0.9000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.2000, -0.2000], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.2000], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.1908, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.8010, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.7999, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.1994, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.7468, 1.7462, 1.7443,  ..., 0.3874, 0.3902, 0.3928],\n",
      "        [1.7462, 1.7468, 1.7462,  ..., 0.3843, 0.3874, 0.3902],\n",
      "        [1.7443, 1.7462, 1.7468,  ..., 0.3809, 0.3843, 0.3874],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7999, 0.7998, 0.7994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7998, 0.7999, 0.7998],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7994, 0.7998, 0.7999]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.7468, 1.7462, 1.7443,  ..., 0.3874, 0.3902, 0.3928],\n",
      "        [1.7462, 1.7468, 1.7462,  ..., 0.3843, 0.3874, 0.3902],\n",
      "        [1.7443, 1.7462, 1.7468,  ..., 0.3809, 0.3843, 0.3874],\n",
      "        ...,\n",
      "        [0.3874, 0.3843, 0.3809,  ..., 0.7999, 0.7998, 0.7994],\n",
      "        [0.3902, 0.3874, 0.3843,  ..., 0.7998, 0.7999, 0.7998],\n",
      "        [0.3928, 0.3902, 0.3874,  ..., 0.7994, 0.7998, 0.7999]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.7468,  0.0000,  1.7462,  ...,  0.3902,  0.6659,  0.3928],\n",
      "        [ 0.0000,  0.7999, -0.0113,  ...,  0.5730, -0.3928,  0.5651],\n",
      "        [ 1.7462, -0.0113,  1.7468,  ...,  0.3874,  0.6963,  0.3902],\n",
      "        ...,\n",
      "        [ 0.3902,  0.5730,  0.3874,  ...,  0.7999, -0.0113,  0.7998],\n",
      "        [ 0.6659, -0.3928,  0.6963,  ..., -0.0113,  1.7468,  0.0000],\n",
      "        [ 0.3928,  0.5651,  0.3902,  ...,  0.7998,  0.0000,  0.7999]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.7468,  0.0000,  1.7462,  ...,  0.3902,  0.6659,  0.3928],\n",
      "        [ 0.0000,  0.7999, -0.0113,  ...,  0.5730, -0.3928,  0.5651],\n",
      "        [ 1.7462, -0.0113,  1.7468,  ...,  0.3874,  0.6963,  0.3902],\n",
      "        ...,\n",
      "        [ 0.3902,  0.5730,  0.3874,  ...,  0.7999, -0.0113,  0.7998],\n",
      "        [ 0.6659, -0.3928,  0.6963,  ..., -0.0113,  1.7468,  0.0000],\n",
      "        [ 0.3928,  0.5651,  0.3902,  ...,  0.7998,  0.0000,  0.7999]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.3001, -0.2998], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.3000], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.2857, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.7024, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.6997, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.2968, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.7017, 1.7010, 1.6990,  ..., 0.3036, 0.3064, 0.3091],\n",
      "        [1.7010, 1.7017, 1.7010,  ..., 0.3006, 0.3036, 0.3064],\n",
      "        [1.6990, 1.7010, 1.7017,  ..., 0.2974, 0.3006, 0.3036],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6997, 0.6996, 0.6994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6996, 0.6997, 0.6996],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6994, 0.6996, 0.6997]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.7017, 1.7010, 1.6990,  ..., 0.3036, 0.3064, 0.3091],\n",
      "        [1.7010, 1.7017, 1.7010,  ..., 0.3006, 0.3036, 0.3064],\n",
      "        [1.6990, 1.7010, 1.7017,  ..., 0.2974, 0.3006, 0.3036],\n",
      "        ...,\n",
      "        [0.3036, 0.3006, 0.2974,  ..., 0.6997, 0.6996, 0.6994],\n",
      "        [0.3064, 0.3036, 0.3006,  ..., 0.6996, 0.6997, 0.6996],\n",
      "        [0.3091, 0.3064, 0.3036,  ..., 0.6994, 0.6996, 0.6997]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.7017,  0.0000,  1.7010,  ...,  0.3064,  0.5919,  0.3091],\n",
      "        [ 0.0000,  0.6997, -0.0085,  ...,  0.5260, -0.3091,  0.5198],\n",
      "        [ 1.7010, -0.0085,  1.7017,  ...,  0.3036,  0.6204,  0.3064],\n",
      "        ...,\n",
      "        [ 0.3064,  0.5260,  0.3036,  ...,  0.6997, -0.0085,  0.6996],\n",
      "        [ 0.5919, -0.3091,  0.6204,  ..., -0.0085,  1.7017,  0.0000],\n",
      "        [ 0.3091,  0.5198,  0.3064,  ...,  0.6996,  0.0000,  0.6997]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.7017,  0.0000,  1.7010,  ...,  0.3064,  0.5919,  0.3091],\n",
      "        [ 0.0000,  0.6997, -0.0085,  ...,  0.5260, -0.3091,  0.5198],\n",
      "        [ 1.7010, -0.0085,  1.7017,  ...,  0.3036,  0.6204,  0.3064],\n",
      "        ...,\n",
      "        [ 0.3064,  0.5260,  0.3036,  ...,  0.6997, -0.0085,  0.6996],\n",
      "        [ 0.5919, -0.3091,  0.6204,  ..., -0.0085,  1.7017,  0.0000],\n",
      "        [ 0.3091,  0.5198,  0.3064,  ...,  0.6996,  0.0000,  0.6997]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.4002, -0.3994], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.3999], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.3732, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.6041, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.5995, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.3896, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.6836, 1.6827, 1.6801,  ..., 0.2346, 0.2372, 0.2396],\n",
      "        [1.6827, 1.6836, 1.6827,  ..., 0.2320, 0.2346, 0.2372],\n",
      "        [1.6801, 1.6827, 1.6836,  ..., 0.2292, 0.2320, 0.2346],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5995, 0.5994, 0.5992],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5994, 0.5995, 0.5994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5992, 0.5994, 0.5995]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.6836, 1.6827, 1.6801,  ..., 0.2346, 0.2372, 0.2396],\n",
      "        [1.6827, 1.6836, 1.6827,  ..., 0.2320, 0.2346, 0.2372],\n",
      "        [1.6801, 1.6827, 1.6836,  ..., 0.2292, 0.2320, 0.2346],\n",
      "        ...,\n",
      "        [0.2346, 0.2320, 0.2292,  ..., 0.5995, 0.5994, 0.5992],\n",
      "        [0.2372, 0.2346, 0.2320,  ..., 0.5994, 0.5995, 0.5994],\n",
      "        [0.2396, 0.2372, 0.2346,  ..., 0.5992, 0.5994, 0.5995]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.6836,  0.0000,  1.6827,  ...,  0.2372,  0.4644,  0.2396],\n",
      "        [ 0.0000,  0.5995, -0.0063,  ...,  0.4676, -0.2396,  0.4627],\n",
      "        [ 1.6827, -0.0063,  1.6836,  ...,  0.2346,  0.4906,  0.2372],\n",
      "        ...,\n",
      "        [ 0.2372,  0.4676,  0.2346,  ...,  0.5995, -0.0063,  0.5994],\n",
      "        [ 0.4644, -0.2396,  0.4906,  ..., -0.0063,  1.6836,  0.0000],\n",
      "        [ 0.2396,  0.4627,  0.2372,  ...,  0.5994,  0.0000,  0.5995]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.6836,  0.0000,  1.6827,  ...,  0.2372,  0.4644,  0.2396],\n",
      "        [ 0.0000,  0.5995, -0.0063,  ...,  0.4676, -0.2396,  0.4627],\n",
      "        [ 1.6827, -0.0063,  1.6836,  ...,  0.2346,  0.4906,  0.2372],\n",
      "        ...,\n",
      "        [ 0.2372,  0.4676,  0.2346,  ...,  0.5995, -0.0063,  0.5994],\n",
      "        [ 0.4644, -0.2396,  0.4906,  ..., -0.0063,  1.6836,  0.0000],\n",
      "        [ 0.2396,  0.4627,  0.2372,  ...,  0.5994,  0.0000,  0.5995]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.5004, -0.4984], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.4997], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.4329, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.5075, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.4992, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.4744, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.6625, 1.6613, 1.6576,  ..., 0.1783, 0.1804, 0.1825],\n",
      "        [1.6613, 1.6625, 1.6613,  ..., 0.1760, 0.1783, 0.1804],\n",
      "        [1.6576, 1.6613, 1.6625,  ..., 0.1737, 0.1760, 0.1783],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4992, 0.4992, 0.4990],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4992, 0.4992, 0.4992],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4990, 0.4992, 0.4992]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.6625, 1.6613, 1.6576,  ..., 0.1783, 0.1804, 0.1825],\n",
      "        [1.6613, 1.6625, 1.6613,  ..., 0.1760, 0.1783, 0.1804],\n",
      "        [1.6576, 1.6613, 1.6625,  ..., 0.1737, 0.1760, 0.1783],\n",
      "        ...,\n",
      "        [0.1783, 0.1760, 0.1737,  ..., 0.4992, 0.4992, 0.4990],\n",
      "        [0.1804, 0.1783, 0.1760,  ..., 0.4992, 0.4992, 0.4992],\n",
      "        [0.1825, 0.1804, 0.1783,  ..., 0.4990, 0.4992, 0.4992]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.6625,  0.0000,  1.6613,  ...,  0.1804,  0.3042,  0.1825],\n",
      "        [ 0.0000,  0.4992, -0.0047,  ...,  0.4004, -0.1825,  0.3967],\n",
      "        [ 1.6613, -0.0047,  1.6625,  ...,  0.1783,  0.3254,  0.1804],\n",
      "        ...,\n",
      "        [ 0.1804,  0.4004,  0.1783,  ...,  0.4992, -0.0047,  0.4992],\n",
      "        [ 0.3042, -0.1825,  0.3254,  ..., -0.0047,  1.6625,  0.0000],\n",
      "        [ 0.1825,  0.3967,  0.1804,  ...,  0.4992,  0.0000,  0.4992]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.6625,  0.0000,  1.6613,  ...,  0.1804,  0.3042,  0.1825],\n",
      "        [ 0.0000,  0.4992, -0.0047,  ...,  0.4004, -0.1825,  0.3967],\n",
      "        [ 1.6613, -0.0047,  1.6625,  ...,  0.1783,  0.3254,  0.1804],\n",
      "        ...,\n",
      "        [ 0.1804,  0.4004,  0.1783,  ...,  0.4992, -0.0047,  0.4992],\n",
      "        [ 0.3042, -0.1825,  0.3254,  ..., -0.0047,  1.6625,  0.0000],\n",
      "        [ 0.1825,  0.3967,  0.1804,  ...,  0.4992,  0.0000,  0.4992]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.6010, -0.5966], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.5996], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.4767, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.4149, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.3989, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.5485, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.6430, 1.6412, 1.6357,  ..., 0.1317, 0.1334, 0.1350],\n",
      "        [1.6412, 1.6430, 1.6412,  ..., 0.1299, 0.1317, 0.1334],\n",
      "        [1.6357, 1.6412, 1.6430,  ..., 0.1281, 0.1299, 0.1317],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3989, 0.3988, 0.3987],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3988, 0.3989, 0.3988],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3987, 0.3988, 0.3989]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.6430, 1.6412, 1.6357,  ..., 0.1317, 0.1334, 0.1350],\n",
      "        [1.6412, 1.6430, 1.6412,  ..., 0.1299, 0.1317, 0.1334],\n",
      "        [1.6357, 1.6412, 1.6430,  ..., 0.1281, 0.1299, 0.1317],\n",
      "        ...,\n",
      "        [0.1317, 0.1299, 0.1281,  ..., 0.3989, 0.3988, 0.3987],\n",
      "        [0.1334, 0.1317, 0.1299,  ..., 0.3988, 0.3989, 0.3988],\n",
      "        [0.1350, 0.1334, 0.1317,  ..., 0.3987, 0.3988, 0.3989]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.6430,  0.0000,  1.6412,  ...,  0.1334,  0.1597,  0.1350],\n",
      "        [ 0.0000,  0.3989, -0.0034,  ...,  0.3265, -0.1350,  0.3238],\n",
      "        [ 1.6412, -0.0034,  1.6430,  ...,  0.1317,  0.1727,  0.1334],\n",
      "        ...,\n",
      "        [ 0.1334,  0.3265,  0.1317,  ...,  0.3989, -0.0034,  0.3988],\n",
      "        [ 0.1597, -0.1350,  0.1727,  ..., -0.0034,  1.6430,  0.0000],\n",
      "        [ 0.1350,  0.3238,  0.1334,  ...,  0.3988,  0.0000,  0.3989]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.6430,  0.0000,  1.6412,  ...,  0.1334,  0.1597,  0.1350],\n",
      "        [ 0.0000,  0.3989, -0.0034,  ...,  0.3265, -0.1350,  0.3238],\n",
      "        [ 1.6412, -0.0034,  1.6430,  ...,  0.1317,  0.1727,  0.1334],\n",
      "        ...,\n",
      "        [ 0.1334,  0.3265,  0.1317,  ...,  0.3989, -0.0034,  0.3988],\n",
      "        [ 0.1597, -0.1350,  0.1727,  ..., -0.0034,  1.6430,  0.0000],\n",
      "        [ 0.1350,  0.3238,  0.1334,  ...,  0.3988,  0.0000,  0.3989]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.7020, -0.6934], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.6994], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.5182, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.3233, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.2979, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.6119, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.6328, 1.6298, 1.6207,  ..., 0.0921, 0.0934, 0.0946],\n",
      "        [1.6298, 1.6328, 1.6298,  ..., 0.0909, 0.0921, 0.0934],\n",
      "        [1.6207, 1.6298, 1.6328,  ..., 0.0895, 0.0909, 0.0921],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2979, 0.2979, 0.2979],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2979, 0.2979, 0.2979],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2979, 0.2979, 0.2979]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.6328, 1.6298, 1.6207,  ..., 0.0921, 0.0934, 0.0946],\n",
      "        [1.6298, 1.6328, 1.6298,  ..., 0.0909, 0.0921, 0.0934],\n",
      "        [1.6207, 1.6298, 1.6328,  ..., 0.0895, 0.0909, 0.0921],\n",
      "        ...,\n",
      "        [0.0921, 0.0909, 0.0895,  ..., 0.2979, 0.2979, 0.2979],\n",
      "        [0.0934, 0.0921, 0.0909,  ..., 0.2979, 0.2979, 0.2979],\n",
      "        [0.0946, 0.0934, 0.0921,  ..., 0.2979, 0.2979, 0.2979]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.6328,  0.0000,  1.6298,  ...,  0.0934,  0.0709,  0.0946],\n",
      "        [ 0.0000,  0.2979, -0.0023,  ...,  0.2477, -0.0946,  0.2458],\n",
      "        [ 1.6298, -0.0023,  1.6328,  ...,  0.0921,  0.0755,  0.0934],\n",
      "        ...,\n",
      "        [ 0.0934,  0.2477,  0.0921,  ...,  0.2979, -0.0023,  0.2979],\n",
      "        [ 0.0709, -0.0946,  0.0755,  ..., -0.0023,  1.6328,  0.0000],\n",
      "        [ 0.0946,  0.2458,  0.0934,  ...,  0.2979,  0.0000,  0.2979]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.6328,  0.0000,  1.6298,  ...,  0.0934,  0.0709,  0.0946],\n",
      "        [ 0.0000,  0.2979, -0.0023,  ...,  0.2477, -0.0946,  0.2458],\n",
      "        [ 1.6298, -0.0023,  1.6328,  ...,  0.0921,  0.0755,  0.0934],\n",
      "        ...,\n",
      "        [ 0.0934,  0.2477,  0.0921,  ...,  0.2979, -0.0023,  0.2979],\n",
      "        [ 0.0709, -0.0946,  0.0755,  ..., -0.0023,  1.6328,  0.0000],\n",
      "        [ 0.0946,  0.2458,  0.0934,  ...,  0.2979,  0.0000,  0.2979]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.8035, -0.7881], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.7993], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.4978, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.2303, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.1961, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.6666, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.5684, 1.5625, 1.5450,  ..., 0.0574, 0.0582, 0.0590],\n",
      "        [1.5625, 1.5684, 1.5625,  ..., 0.0566, 0.0574, 0.0582],\n",
      "        [1.5450, 1.5625, 1.5684,  ..., 0.0557, 0.0566, 0.0574],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1961, 0.1961, 0.1960],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1961, 0.1961, 0.1961],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1960, 0.1961, 0.1961]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.5684, 1.5625, 1.5450,  ..., 0.0574, 0.0582, 0.0590],\n",
      "        [1.5625, 1.5684, 1.5625,  ..., 0.0566, 0.0574, 0.0582],\n",
      "        [1.5450, 1.5625, 1.5684,  ..., 0.0557, 0.0566, 0.0574],\n",
      "        ...,\n",
      "        [0.0574, 0.0566, 0.0557,  ..., 0.1961, 0.1961, 0.1960],\n",
      "        [0.0582, 0.0574, 0.0566,  ..., 0.1961, 0.1961, 0.1961],\n",
      "        [0.0590, 0.0582, 0.0574,  ..., 0.1960, 0.1961, 0.1961]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.5684e+00,  0.0000e+00,  1.5625e+00,  ...,  5.8187e-02,\n",
      "          3.7859e-02,  5.8969e-02],\n",
      "        [ 0.0000e+00,  1.9609e-01, -1.4407e-03,  ...,  1.6498e-01,\n",
      "         -5.8969e-02,  1.6379e-01],\n",
      "        [ 1.5625e+00, -1.4407e-03,  1.5684e+00,  ...,  5.7382e-02,\n",
      "          3.9055e-02,  5.8187e-02],\n",
      "        ...,\n",
      "        [ 5.8187e-02,  1.6498e-01,  5.7382e-02,  ...,  1.9609e-01,\n",
      "         -1.4407e-03,  1.9608e-01],\n",
      "        [ 3.7859e-02, -5.8969e-02,  3.9055e-02,  ..., -1.4407e-03,\n",
      "          1.5684e+00,  0.0000e+00],\n",
      "        [ 5.8969e-02,  1.6379e-01,  5.8187e-02,  ...,  1.9608e-01,\n",
      "          0.0000e+00,  1.9609e-01]], grad_fn=<CatBackward>)\n",
      "tensor([[ 1.5684e+00,  0.0000e+00,  1.5625e+00,  ...,  5.8187e-02,\n",
      "          3.7859e-02,  5.8969e-02],\n",
      "        [ 0.0000e+00,  1.9609e-01, -1.4407e-03,  ...,  1.6498e-01,\n",
      "         -5.8969e-02,  1.6379e-01],\n",
      "        [ 1.5625e+00, -1.4407e-03,  1.5684e+00,  ...,  5.7382e-02,\n",
      "          3.9055e-02,  5.8187e-02],\n",
      "        ...,\n",
      "        [ 5.8187e-02,  1.6498e-01,  5.7382e-02,  ...,  1.9609e-01,\n",
      "         -1.4407e-03,  1.9608e-01],\n",
      "        [ 3.7859e-02, -5.8969e-02,  3.9055e-02,  ..., -1.4407e-03,\n",
      "          1.5684e+00,  0.0000e+00],\n",
      "        [ 5.8969e-02,  1.6379e-01,  5.8187e-02,  ...,  1.9608e-01,\n",
      "          0.0000e+00,  1.9609e-01]], grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.9055, -0.8797], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.8988], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.4457, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.1855, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(0.0943, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.7150, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.4777, 1.4690, 1.4431,  ..., 0.0263, 0.0267, 0.0270],\n",
      "        [1.4690, 1.4777, 1.4690,  ..., 0.0259, 0.0263, 0.0267],\n",
      "        [1.4431, 1.4690, 1.4777,  ..., 0.0255, 0.0259, 0.0263],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0943, 0.0943, 0.0942],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0943, 0.0943, 0.0943],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0942, 0.0943, 0.0943]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.4777, 1.4690, 1.4431,  ..., 0.0263, 0.0267, 0.0270],\n",
      "        [1.4690, 1.4777, 1.4690,  ..., 0.0259, 0.0263, 0.0267],\n",
      "        [1.4431, 1.4690, 1.4777,  ..., 0.0255, 0.0259, 0.0263],\n",
      "        ...,\n",
      "        [0.0263, 0.0259, 0.0255,  ..., 0.0943, 0.0943, 0.0942],\n",
      "        [0.0267, 0.0263, 0.0259,  ..., 0.0943, 0.0943, 0.0943],\n",
      "        [0.0270, 0.0267, 0.0263,  ..., 0.0942, 0.0943, 0.0943]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[ 1.4777e+00,  0.0000e+00,  1.4690e+00,  ...,  2.6671e-02,\n",
      "          1.7847e-02,  2.7041e-02],\n",
      "        [ 0.0000e+00,  9.4266e-02, -6.5407e-04,  ...,  8.0077e-02,\n",
      "         -2.7041e-02,  7.9529e-02],\n",
      "        [ 1.4690e+00, -6.5407e-04,  1.4777e+00,  ...,  2.6292e-02,\n",
      "          1.8345e-02,  2.6671e-02],\n",
      "        ...,\n",
      "        [ 2.6671e-02,  8.0077e-02,  2.6292e-02,  ...,  9.4266e-02,\n",
      "         -6.5407e-04,  9.4260e-02],\n",
      "        [ 1.7847e-02, -2.7041e-02,  1.8345e-02,  ..., -6.5407e-04,\n",
      "          1.4777e+00,  0.0000e+00],\n",
      "        [ 2.7041e-02,  7.9529e-02,  2.6671e-02,  ...,  9.4260e-02,\n",
      "          0.0000e+00,  9.4266e-02]], grad_fn=<CatBackward>)\n",
      "tensor([[ 1.4777e+00,  0.0000e+00,  1.4690e+00,  ...,  2.6671e-02,\n",
      "          1.7847e-02,  2.7041e-02],\n",
      "        [ 0.0000e+00,  9.4266e-02, -6.5407e-04,  ...,  8.0077e-02,\n",
      "         -2.7041e-02,  7.9529e-02],\n",
      "        [ 1.4690e+00, -6.5407e-04,  1.4777e+00,  ...,  2.6292e-02,\n",
      "          1.8345e-02,  2.6671e-02],\n",
      "        ...,\n",
      "        [ 2.6671e-02,  8.0077e-02,  2.6292e-02,  ...,  9.4266e-02,\n",
      "         -6.5407e-04,  9.4260e-02],\n",
      "        [ 1.7847e-02, -2.7041e-02,  1.8345e-02,  ..., -6.5407e-04,\n",
      "          1.4777e+00,  0.0000e+00],\n",
      "        [ 2.7041e-02,  7.9529e-02,  2.6671e-02,  ...,  9.4260e-02,\n",
      "          0.0000e+00,  9.4266e-02]], grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.0078, -0.9670], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.9979], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.3789, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.1912, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.0028, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.7581, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.3789, 1.3711, 1.3478,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.3711, 1.3789, 1.3711,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.3478, 1.3711, 1.3789,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.3789, 1.3711, 1.3478,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.3711, 1.3789, 1.3711,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.3478, 1.3711, 1.3789,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.3789e+00, 0.0000e+00, 1.3711e+00,  ..., 0.0000e+00, 1.5825e-06,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.3711e+00, 0.0000e+00, 1.3789e+00,  ..., 0.0000e+00, 2.7499e-06,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.5825e-06, 0.0000e+00, 2.7499e-06,  ..., 0.0000e+00, 1.3789e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n",
      "tensor([[1.3789e+00, 0.0000e+00, 1.3711e+00,  ..., 0.0000e+00, 1.5825e-06,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.3711e+00, 0.0000e+00, 1.3789e+00,  ..., 0.0000e+00, 2.7499e-06,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.5825e-06, 0.0000e+00, 2.7499e-06,  ..., 0.0000e+00, 1.3789e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.1103, -1.0487], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.0962], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.3020, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.2217, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.0898, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.7967, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.3020, 1.2965, 1.2802,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.2965, 1.3020, 1.2965,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.2802, 1.2965, 1.3020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.3020, 1.2965, 1.2802,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.2965, 1.3020, 1.2965,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.2802, 1.2965, 1.3020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.3020e+00, 0.0000e+00, 1.2965e+00,  ..., 0.0000e+00, 4.9774e-05,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2965e+00, 0.0000e+00, 1.3020e+00,  ..., 0.0000e+00, 7.5071e-05,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [4.9774e-05, 0.0000e+00, 7.5071e-05,  ..., 0.0000e+00, 1.3020e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n",
      "tensor([[1.3020e+00, 0.0000e+00, 1.2965e+00,  ..., 0.0000e+00, 4.9774e-05,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2965e+00, 0.0000e+00, 1.3020e+00,  ..., 0.0000e+00, 7.5071e-05,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [4.9774e-05, 0.0000e+00, 7.5071e-05,  ..., 0.0000e+00, 1.3020e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.2131, -1.1227], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.1935], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.2185, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.2632, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.1680, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.8315, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.2185, 1.2148, 1.2039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.2148, 1.2185, 1.2148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.2039, 1.2148, 1.2185,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.2185, 1.2148, 1.2039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.2148, 1.2185, 1.2148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.2039, 1.2148, 1.2185,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.2185e+00, 0.0000e+00, 1.2148e+00,  ..., 0.0000e+00, 8.9366e-04,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2148e+00, 0.0000e+00, 1.2185e+00,  ..., 0.0000e+00, 1.1962e-03,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [8.9366e-04, 0.0000e+00, 1.1962e-03,  ..., 0.0000e+00, 1.2185e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n",
      "tensor([[1.2185e+00, 0.0000e+00, 1.2148e+00,  ..., 0.0000e+00, 8.9366e-04,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2148e+00, 0.0000e+00, 1.2185e+00,  ..., 0.0000e+00, 1.1962e-03,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [8.9366e-04, 0.0000e+00, 1.1962e-03,  ..., 0.0000e+00, 1.2185e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.3161, -1.1864], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.2895], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.1324, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.3038, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.2385, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.8628, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.1324, 1.1299, 1.1223,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1299, 1.1324, 1.1299,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1223, 1.1299, 1.1324,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.1324, 1.1299, 1.1223,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1299, 1.1324, 1.1299,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1223, 1.1299, 1.1324,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.1324, 0.0000, 1.1299,  ..., 0.0000, 0.0050, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1299, 0.0000, 1.1324,  ..., 0.0000, 0.0062, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0000, 0.0062,  ..., 0.0000, 1.1324, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.1324, 0.0000, 1.1299,  ..., 0.0000, 0.0050, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1299, 0.0000, 1.1324,  ..., 0.0000, 0.0062, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0000, 0.0062,  ..., 0.0000, 1.1324, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.4193, -1.2369], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.3840], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(1.0515, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.3283, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.3022, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.8911, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.0515, 1.0494, 1.0434,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0494, 1.0515, 1.0494,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0434, 1.0494, 1.0515,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.0515, 1.0494, 1.0434,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0494, 1.0515, 1.0494,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0434, 1.0494, 1.0515,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.0515, 0.0000, 1.0494,  ..., 0.0000, 0.0102, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0494, 0.0000, 1.0515,  ..., 0.0000, 0.0123, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0102, 0.0000, 0.0123,  ..., 0.0000, 1.0515, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.0515, 0.0000, 1.0494,  ..., 0.0000, 0.0102, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0494, 0.0000, 1.0515,  ..., 0.0000, 0.0123, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0102, 0.0000, 0.0123,  ..., 0.0000, 1.0515, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.5225, -1.2716], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.4764], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(0.9847, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.3288, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.3598, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.9167, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.9847, 0.9828, 0.9771,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9828, 0.9847, 0.9828,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9771, 0.9828, 0.9847,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.9847, 0.9828, 0.9771,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9828, 0.9847, 0.9828,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9771, 0.9828, 0.9847,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[0.9847, 0.0000, 0.9828,  ..., 0.0000, 0.0097, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9828, 0.0000, 0.9847,  ..., 0.0000, 0.0116, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0097, 0.0000, 0.0116,  ..., 0.0000, 0.9847, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.9847, 0.0000, 0.9828,  ..., 0.0000, 0.0097, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9828, 0.0000, 0.9847,  ..., 0.0000, 0.0116, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0097, 0.0000, 0.0116,  ..., 0.0000, 0.9847, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.6257, -1.2887], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.5665], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(0.9352, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.3088, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.4121, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.9399, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.9352, 0.9332, 0.9271,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9332, 0.9352, 0.9332,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9271, 0.9332, 0.9352,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.9352, 0.9332, 0.9271,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9332, 0.9352, 0.9332,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9271, 0.9332, 0.9352,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[0.9352, 0.0000, 0.9332,  ..., 0.0000, 0.0049, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9332, 0.0000, 0.9352,  ..., 0.0000, 0.0061, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0049, 0.0000, 0.0061,  ..., 0.0000, 0.9352, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.9352, 0.0000, 0.9332,  ..., 0.0000, 0.0049, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9332, 0.0000, 0.9352,  ..., 0.0000, 0.0061, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0049, 0.0000, 0.0061,  ..., 0.0000, 0.9352, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.7288, -1.2877], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.6544], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(0.8971, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.2762, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.4595, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.9609, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.8971, 0.8947, 0.8874,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8947, 0.8971, 0.8947,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8874, 0.8947, 0.8971,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.8971, 0.8947, 0.8874,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8947, 0.8971, 0.8947,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8874, 0.8947, 0.8971,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[0.8971, 0.0000, 0.8947,  ..., 0.0000, 0.0013, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8947, 0.0000, 0.8971,  ..., 0.0000, 0.0017, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0013, 0.0000, 0.0017,  ..., 0.0000, 0.8971, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.8971, 0.0000, 0.8947,  ..., 0.0000, 0.0013, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8947, 0.0000, 0.8971,  ..., 0.0000, 0.0017, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0013, 0.0000, 0.0017,  ..., 0.0000, 0.8971, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.8318, -1.2694], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.7399], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(0.8592, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.2409, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.5025, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.9801, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.8592, 0.8561, 0.8470,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8561, 0.8592, 0.8561,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8470, 0.8561, 0.8592,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.8592, 0.8561, 0.8470,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8561, 0.8592, 0.8561,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8470, 0.8561, 0.8592,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[8.5922e-01, 0.0000e+00, 8.5615e-01,  ..., 0.0000e+00, 1.5564e-04,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [8.5615e-01, 0.0000e+00, 8.5922e-01,  ..., 0.0000e+00, 2.2044e-04,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.5564e-04, 0.0000e+00, 2.2044e-04,  ..., 0.0000e+00, 8.5922e-01,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n",
      "tensor([[8.5922e-01, 0.0000e+00, 8.5615e-01,  ..., 0.0000e+00, 1.5564e-04,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [8.5615e-01, 0.0000e+00, 8.5922e-01,  ..., 0.0000e+00, 2.2044e-04,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.5564e-04, 0.0000e+00, 2.2044e-04,  ..., 0.0000e+00, 8.5922e-01,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.9346, -1.2355], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.8235], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(0.8124, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.2128, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.5416, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(1.9974, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.8124, 0.8087, 0.7976,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8087, 0.8124, 0.8087,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7976, 0.8087, 0.8124,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.8124, 0.8087, 0.7976,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8087, 0.8124, 0.8087,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7976, 0.8087, 0.8124,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[8.1243e-01, 0.0000e+00, 8.0871e-01,  ..., 0.0000e+00, 1.2978e-05,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [8.0871e-01, 0.0000e+00, 8.1243e-01,  ..., 0.0000e+00, 2.0276e-05,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2978e-05, 0.0000e+00, 2.0276e-05,  ..., 0.0000e+00, 8.1243e-01,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n",
      "tensor([[8.1243e-01, 0.0000e+00, 8.0871e-01,  ..., 0.0000e+00, 1.2978e-05,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [8.0871e-01, 0.0000e+00, 8.1243e-01,  ..., 0.0000e+00, 2.0276e-05,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2978e-05, 0.0000e+00, 2.0276e-05,  ..., 0.0000e+00, 8.1243e-01,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(20)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    for parameter in model.named_parameters():\n",
    "        print(parameter)\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75730997",
   "metadata": {},
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-2.0371, -1.1883], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.9052], requires_grad=True))\n",
      "('covar_module.12482531872.var', Parameter containing:\n",
      "tensor(0.7536, requires_grad=True))\n",
      "('covar_module.12482531872.length', Parameter containing:\n",
      "tensor(0.1982, requires_grad=True))\n",
      "('covar_module.12482531968.var', Parameter containing:\n",
      "tensor(-0.5772, requires_grad=True))\n",
      "('covar_module.12482531968.length', Parameter containing:\n",
      "tensor(2.0133, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "tensor([[0.7536, 0.7496, 0.7378,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7496, 0.7536, 0.7496,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7378, 0.7496, 0.7536,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Symmetric result:\n",
      "tensor([[0.7536, 0.7496, 0.7378,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7496, 0.7536, 0.7496,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7378, 0.7496, 0.7536,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Interleaved result:\n",
      "tensor([[7.5361e-01, 0.0000e+00, 7.4962e-01,  ..., 0.0000e+00, 2.2496e-06,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [7.4962e-01, 0.0000e+00, 7.5361e-01,  ..., 0.0000e+00, 3.7612e-06,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.2496e-06, 0.0000e+00, 3.7612e-06,  ..., 0.0000e+00, 7.5361e-01,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "tensor([[7.5361e-01, 0.0000e+00, 7.4962e-01,  ..., 0.0000e+00, 2.2496e-06,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [7.4962e-01, 0.0000e+00, 7.5361e-01,  ..., 0.0000e+00, 3.7612e-06,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.2496e-06, 0.0000e+00, 3.7612e-06,  ..., 0.0000e+00, 7.5361e-01,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "Result:\n",
      "tensor([[0.7536, 0.7496, 0.7378,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7496, 0.7536, 0.7496,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7378, 0.7496, 0.7536,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Symmetric result:\n",
      "tensor([[0.7536, 0.7496, 0.7378,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7496, 0.7536, 0.7496,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7378, 0.7496, 0.7536,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Interleaved result:\n",
      "tensor([[7.5361e-01, 0.0000e+00, 7.4962e-01,  ..., 0.0000e+00, 5.9845e-23,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [7.4962e-01, 0.0000e+00, 7.5361e-01,  ..., 0.0000e+00, 1.6817e-22,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [5.9845e-23, 0.0000e+00, 1.6817e-22,  ..., 0.0000e+00, 7.5361e-01,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "tensor([[7.5361e-01, 0.0000e+00, 7.4962e-01,  ..., 0.0000e+00, 5.9845e-23,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [7.4962e-01, 0.0000e+00, 7.5361e-01,  ..., 0.0000e+00, 1.6817e-22,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [5.9845e-23, 0.0000e+00, 1.6817e-22,  ..., 0.0000e+00, 7.5361e-01,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(50)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(0), float(2), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0a03a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Observed Values (Likelihood)')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAADSCAYAAACW5MO6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+SklEQVR4nO3deXxU1d348c93ZpJMViBhCTuKgrKEVURBUCygSFFcqqC2dXkULFXr0pafWrG1m/pYbX3UUituFFCk1gepCq1WZfFh3wURWQLZyL5PJnN+f9xJmITJPpmZJN/365VXZu69c++ZO/Od773nnnuOGGNQSimlVGjYQl0ApZRSqiPTRKyUUkqFkCZipZRSKoQ0ESullFIhpIlYKaWUCiFNxEoppVQItctELCKLROStUJejKUTkhyLyRSus91IRSQ30ehux3Wki8l4jlrtZRD72eW5E5JxmbK/6dSLysog85n0ctPcvIkdE5Dvex/eKyO+Csd32TGO5xno1lttpLLfJROz9ou8WkRIRSReRl0Skc6jL1RpExCkieSIyxc+8P4jIylCUqxF+A1R/eesKSmPMUmPMtEBu2Bgzzxjzq0CusxkWA7eISPcQlyOsaSxXz9NY9qOjxHKbS8Qi8iDwe+BhoBMwHugPrBWRyCCWwxGM7RhjyoAVwPdrbd8OzAFeD0Y5mkJELgA6GWM2hbosoeL93P5Jrc9NnaaxXL19jeUwFoxYblOJWEQSgCeAHxtjPjTGVBhjjgDfwwrgW3wWd4rIChEpFJFtIjLCZz0/E5ET3nkHRORy73SbiPxcRL4RkWwReVtEEr3zBniPBO8QkWPAv0XkQxFZUKuMO0XkWu/j80RkrYjkeLfzPZ/lkkTkfREpEJH/AwbW89ZfB64TkRifadOxPr9/ishtIrLf+34Oi8jd9ezDGkezIvKaiDzp83ymiOzwHrlvEJGUhvabH1cC/6nn/fiWp85qPBGZKCLHReQy7/Pbve8zV0Q+EpH+dbyuxnvyTntQRDJFJE1EbvOZ3klE3hCRLBE5KiKPiojNO8/mfX7U+9o3RKSTz2tv9c7LFpFH/BTlU+CqxuyHjkZjWWNZY9mHMabN/AFXAG7A4Wfe68Ay7+NFQAVwPRABPAR86308GDgO9PIuOwAY6H18P7AJ6ANEAX/2WecAwABvALFANNYR0nqfMgwB8ryvjfVu5zbAAYwGTgFDvcsuB972LjcMOAF8Uc97Pwjc4vN8GfCc9/FVWMEvwGSgBBjtnXcpkOrzOgOc4/P8NeBJ7+PRQCZwIWAHfgAc8b6fOvebn7K+Azxca1qN7fpM/6Hv+65aDuvH6Tgwzjv9GuAQcL53fz4KbPC3/lrv6VKs78wvvZ//DO/+6eKd/wbwDyDe+54OAnd4593u3ebZQBywCnjT57MuAiZ598+z3u18x6dMo4GcUMdNOP6hsayxrLF8et+FOiCbGLy3AOl1zPsdsNYneDf5zLMBacAl3i9GJvAdIKLWOvYDl/s874n1I+DgdPCe7TM/HigG+nuf/xp41fv4RuDzWuv/M/C4NzAqgPN85v2G+oP3UeBj7+ME7xdwVB3Lvgfc5/PlbWzwvgT8qta6DmD9INS53/xsfy0wr9a0pgTvQuAoMNxn+j+rgsrnMy3x2ff1BW8pPj/43vcx3vs5lANDfObdDXzqffwv4B6feYN9vg+/AJb7zIsFXNQM3nOBylDHTTj+obGssVzzM+3QsdymqqaxjkK7iv9rOj2986scr3pgjPEAqVhHgIewjpYXAZkislxEenkX7Q/83VuVk4cVzJVAjzrWWwh8ANzknXQTsNRnXRdWrcu7vpuBZKAb1hegel1YX9b6vAFcJiK9sc4ODhljtgOIyJUisslbbZaHdaTYtYH1+dMfeLBWmfvS8H6rLRfrh6257gfeNsbsrlW2533KlYN11tC7EevLNsa4fZ6XYB0VdwUiqbnvj/qss5efeQ6s70Mvan4XioHsWtuNB/IbUb6OSGNZY1lj2autJeKNWEc91/pOFJFYrGsZ//KZ3Ndnvg2riuokgDHmb8aYiVhfCIPVYASsD+NKY0xnnz+nMeaEz3pNrTItA+aIyEVYVVyf+KzrP7XWFWeMmQ9kYVV99PVZT7/63rgx5hjwOdYPwK1YwYyIRAHvAs8APYwxnYE1WF9sf0oA3+tTyT6PjwO/rlXmGGPMMm8Z6tpvte0CBtX3fhpwA3CNiNxfq2x31ypbtDFmQwu2cwrrqLi/z7R+WFWLYH1fas9zAxlYZ2W+37EYIKnW+s8HdragfO2ZxrLGssayV5tKxMaYfKwGHn8SkStEJEJEBmBdx0gF3vRZfIyIXOs94r4fK+g3ichgEZni/dKXYVV1VHpf8zLw66qGAyLSTUSubqBYa7A+4F8CK7xH7ACrgUHeRgAR3r8LROR8Y0wl1jWKRSISIyJDsK7hNOR1YAEwgdNH65FY1zWyALeIXAnUdwvBDmCuiNhF5AqsqqoqfwHmiciFYokVkatEJL6B/eZvn0z2Mz1SrFs4qv7sdbz+JHA5cK+I3OOd9jKwUESGQnXDjBvqeZ8N8n4Ob2N95vHez/0BoOq+1WXAT0TkLBGJw6pyXOE9Il8JzBSrEUok1udfO54mY1XDqVo0ljWWNZZrvoE29wfcAezB+gJlYF2v6eIzf5F3564ACoHtnG7wkAL8n3d6DlaQVTVasGF9eAe8878BfuOdNwDryNFf45K/euddUGv6YKzqriysqo5/AyO987p5t13gLc+vqOe6kjl97aIQ+Get6T/y7oc8rB+w5dS8ruJ7XWkssNe7njexvqBP+sy/AtjsXVca1g9jfH37rY6ybgYu9Hlu/PzdSR0NPLyPz8KqQrrT+/xWYLd3nx3Hew3Pz+teq+v9e6cdwXv9B+iCFaxZ3nX+ArD5fB9+4Z2e5V3O93v2A+CY97N9pNZ6nVgJpUeo4yWc/9BY1ljWWEa8G1IqoERkGlbjiGtCXZZQEJEfA32NMT8NdVmUagmN5daPZU3ESimlVAgF5BqxiPxERPaKyB4RWSYizkCsVykVfBrPSgVXixOxWE3w7wXGGmOGYd3PdVP9r1JKhSONZ6WCL1Ctph1AtLdVYwzeWwuUUm2SxrNSQdTiRGys+/KewWpxlgbkG2M+rv9VSqlwpPGsVPC1eNQREekCXI3VPD0PeEdEbjHGvFVrubuAuwBiY2PHnHfeeS3dtFLt3tatW08ZY7oFa3uNiWeNZaWarr5YDsTwX98BvjXGZAGIyCrgYk7fSA2AMWYx1riOjB071mzZsiUAm1aqfRORhrpLDLQG41ljWammqy+WA3GN+Bgw3turjGD1orI/AOtVSgWfxrNSQRaIa8RfYvV8sw2rpxQb3qNlpVTbovGsVPAFomoaY8zjWEOCKaXaOI1npYIrIIlYhY+KigpSU1MpKysLdVFUEzidTvr06UNERESoi6LChMZy29ScWNZE3M6kpqYSHx/PgAEDsC7xqXBnjCE7O5vU1FTOOuusUBdHhQmN5banubHcpoZBVA0rKysjKSlJA7cNERGSkpL0zEfVoLHc9jQ3ljURt0MauG2PfmbKH/1etD3N+cw0EauAS01N5eqrr+bcc89l4MCB3HfffbhcLgBee+01FixYEOISnikuLs7vdLvdzsiRIxk6dCgjRozg2WefxePx+F22ypEjR/jb3/7WGsVUKqg0loMTy5qIFWlpaUyePJn09PQWr8sYw7XXXss111zD119/zcGDBykqKuKRRx4JQEn9c7vdrbbu6OhoduzYwd69e1m7di1r1qzhiSeeqPc1mohVqGgs1y2sY9kYE/S/MWPGGNU69u3b1+TXzJ8/39hsNjN//vwWb3/dunXmkksuqTEtPz/fJCYmmuLiYrNkyRIza9YsM336dDNo0CCzaNEiY4wxRUVFZsaMGSYlJcUMHTrULF++3BhjzJYtW8ykSZPM6NGjzbRp08zJkyeNMcZMnjzZLFy40EyaNMksWrTI9O/f31RWVhpjjCkuLjZ9+vQxLpfLHDp0yEyfPt2MHj3aTJw40ezfv98YY8zhw4fN+PHjzdixY82jjz5qYmNj/b6f2tO/+eYbk5iYaDwej/n222/NxIkTzahRo8yoUaPM+vXrjTHGXHjhhSYhIcGMGDHCPPvss3UuV5u/zw7YYkIQo43901huPRrLHSeWNXjbmaYEr9PpNMAZf06ns9nbf/755839999/xvSRI0eanTt3miVLlpjk5GRz6tQpU1JSYoYOHWo2b95sVq5cae68887q5fPy8ozL5TIXXXSRyczMNMYYs3z5cnPbbbcZY6zg9f2xmTVrlvn3v/9dvdwdd9xhjDFmypQp5uDBg8YYYzZt2mQuu+wyY4wx3/3ud83rr79ujDHmhRdeaHTwGmNM586dTXp6uikuLjalpaXGGGMOHjxoqr7Xn3zyibnqqquql69rudo0EStfGssdJ5a1aroDO3z4MHPnziUmJgaAmJgYbr75Zr799ttmr9MY47exgu/0qVOnkpSURHR0NNdeey1ffPEFw4cPZ926dfzsZz/j888/p1OnThw4cIA9e/YwdepURo4cyZNPPklqamr1Om+88cYaj1esWAHA8uXLufHGGykqKmLDhg3ccMMNjBw5krvvvpu0tDQA1q9fz5w5cwC49dZbm/wewbrP87/+678YPnw4N9xwA/v27fO7fGOXU6q5NJbbdizrfcQdWM+ePUlISKCsrAyn00lZWRkJCQkkJyc3e51Dhw7l3XffrTGtoKCA48ePM3DgQLZu3XpGcIsIgwYNYuvWraxZs4aFCxcybdo0Zs+ezdChQ9m4caPfbcXGxlY/njVrFgsXLiQnJ4etW7cyZcoUiouL6dy5Mzt27PD7+ua0bjx8+DB2u53u3bvzxBNP0KNHD3bu3InH48HpdPp9zR/+8IdGLadUc2kst+1Y1jPiDi4jI4N58+axadMm5s2b1+JGHpdffjklJSW88cYbAFRWVvLggw/ywx/+sPpofe3ateTk5FBaWsp7773HhAkTOHnyJDExMdxyyy089NBDbNu2jcGDB5OVlVUdvBUVFezdu9fvduPi4hg3bhz33XcfM2fOxG63k5CQwFlnncU777wDWEe/O3fuBGDChAksX74cgKVLlzbqvWVlZTFv3jwWLFiAiJCfn0/Pnj2x2Wy8+eabVFZWAhAfH09hYWH16+paTqlA0lhuw7FcV511a/7pdaXW05wGHoF27NgxM3PmTHPOOeeYs88+2yxYsMCUlZUZY4xZsmSJueGGG8yMGTNqNPD48MMPzfDhw82IESPM2LFjzebNm40xxmzfvt1ccsklJiUlxQwZMsQsXrzYGGNdV6papso777xjAPPpp59WTzt8+LCZPn26SUlJMeeff7554oknqqdXNfD47W9/W+d1JZvNZkaMGGGGDBliUlJSzNNPP13dkOTgwYNm+PDh5sILLzQ///nPq9fhcrnMlClTTEpKinn22WfrXK42vUasfGksd5xYFuOtIw8mHcO09ezfv5/zzz8/1MVQzeDvsxORrcaYsSEqUoM0lluPxnLb1dRY1qpppZRSKoQ0ESullFIhpIlYKaWUCiFNxEoppVQIaSJWSimlQkgTsVJKKRVCmohVwIlIja7m3G433bp1Y+bMmSEslVKqqTSWg0MTsQq42NhY9uzZQ2lpKWD1vtO7d+8Ql0op1VQay8ERkEQsIp1FZKWIfCUi+0XkokCsV7VdV155JR988AEAy5Ytq+6UHaC4uJjbb7+dCy64gFGjRvGPf/wDsMb+vOSSSxg9ejSjR49mw4YNAHz66adceumlXH/99Zx33nncfPPNhKIjmo5C41n50lhufYEa9OF54ENjzPUiEgnEBGi9qgXuvx/q6CO92UaOhOeea3i5m266iV/+8pfMnDmTXbt2cfvtt/P5558D8Otf/5opU6bw6quvkpeXx7hx4/jOd75D9+7dWbt2LU6nk6+//po5c+ZQ1WvT9u3b2bt3L7169WLChAmsX7+eiRMnBvbNqSoaz2FGY7l9a3EiFpEEYBLwQwBjjAtwtXS9qm1LSUnhyJEjLFu2jBkzZtSY9/HHH/P+++/zzDPPAFBWVsaxY8fo1asXCxYsYMeOHdjtdg4ePFj9mnHjxtGnTx8ARo4cyZEjRzp88LYGjWdVm8Zy6wvEGfHZQBawRERGAFuB+4wxxb4LichdwF0A/fr1C8BmVUMac7TbmmbNmsVDDz3Ep59+SnZ2dvV0YwzvvvsugwcPrrH8okWL6hxiLCoqqvqx3W7H7Xa3/hvomBqMZ43l4NNYbt8CcY3YAYwGXjLGjAKKgZ/XXsgYs9gYM9YYM7Zbt24B2KwKd7fffju/+MUvGD58eI3p06dP509/+lP1taHt27cDOlxgmGgwnjWWOx6N5dYViEScCqQaY770Pl+JFciqg+vTpw/33XffGdMfe+wxKioqSElJYdiwYTz22GMA3HPPPbz++uuMHz+egwcP1hgsXAWNxrM6g8Zy6wrIMIgi8jlwpzHmgIgsAmKNMQ/XtbwOndZ6dOi0titchkFsSjxrLLcejeW2q6mxHKhW0z8GlnpbWB4GbgvQepVSwafxrFQQBSQRG2N2AGE7eLlSqvE0npUKLu1ZSymllAohTcRKKaVUCGkiVkoppUJIE7FSSikVQpqIVcClp6dz0003MXDgQIYMGcKMGTNqdHHXWJ9//jlDhw5l5MiRnDhxguuvv97vcpdeeil6C41SrUPjufUF6vYlFab+sLbpAVOfn0wdVO98YwyzZ8/mBz/4AcuXLwdgx44dZGRkMGhQ/a+tbenSpTz00EPcdpt198zKlSubV2il2oFgxzJoPAeLnhGrgPrkk0+IiIhg3rx51dNGjhzJxIkTefjhhxk2bBjDhw9nxYoVQN3Dor3yyiu8/fbb/PKXv+Tmm2/myJEjDBs2DIDS0lJuuukmUlJSuPHGG6vHSgWrE/qLLrqI0aNHc8MNN1BUVATAgAEDePzxxxk9ejTDhw/nq6++AqCoqIjbbruN4cOHk5KSwrvvvlvvepTqSDSeg0MTsQqoPXv2MGbMmDOmr1q1ih07drBz507WrVvHww8/TFpaGmD1T/vcc8+xb98+Dh8+zPr167nzzjuZNWsWTz/9NEuXLq2xrpdeeomYmBh27drFI488wtatWwE4deoUTz75JOvWrWPbtm2MHTuWZ599tvp1Xbt2Zdu2bcyfP796tJhf/epXdOrUid27d7Nr1y6mTJnS4HqU6ig0noNDq6ZVUHzxxRfMmTMHu91Ojx49mDx5Mps3byYhIaHJw6J99tln3HvvvYA1RFtKSgoAmzZtYt++fUyYMAEAl8vFRRedHtP+2muvBWDMmDGsWrUKgHXr1lVXuQF06dKF1atX17sepTo6jefA0kSsAmro0KF+r/3U16d5c4ZFExG/25g6dSrLli2rdzu+2zDGnLGuhtajVEeh8RwcWjWtAmrKlCmUl5fzl7/8pXra5s2b6dKlCytWrKCyspKsrCw+++wzxo0b16xtTJo0qbp6a8+ePezatQuA8ePHs379eg4dOgRASUlJg607p02bxgsvvFD9PDc3t1nrUao90ngODk3EKqBEhL///e+sXbuWgQMHMnToUBYtWsTcuXNJSUlhxIgRTJkyhaeeeork5ORmbWP+/PkUFRWRkpLCU089Vf0D0K1bN1577TXmzJlDSkoK48ePr27EUZdHH32U3Nxchg0bxogRI/jkk0+atR6l2iON5+AIyDCITaVDp7UeHTqt7QqXYRCbQmO59Wgst11NjWU9I1ZKKaVCSBOxUkopFUKaiJVSSqkQ0kTcDoXiur9qGf3MlD/6vWh7mvOZaSJuZ5xOJ9nZ2RrAbYgxhuzsbJxOZ6iLosKIxnLb09xY1g492pk+ffqQmppKVlZWqIuimsDpdFb3RqQUaCy3Vc2JZU3E7UxERARnnXVWqIuhlGohjeWOQ6umlVJKqRAKWCIWEbuIbBeR1YFap1IqNDSelQqeQJ4R3wfsD+D6lFKho/GsVJAEJBGLSB/gKuCVQKxPKRU6Gs9KBVegzoifA34KeOpaQETuEpEtIrJFWwEqFdaeo5541lhWKrBanIhFZCaQaYzZWt9yxpjFxpixxpix3bp1a+lmlVKtoDHxrLGsVGAF4ox4AjBLRI4Ay4EpIvJWANarlAo+jWelgqzFidgYs9AY08cYMwC4Cfi3MeaWFpdMKRV0Gs9KBZ/eR6yUUkqFUEB71jLGfAp8Gsh1KqVCQ+NZqeDQM2KllFIqhDQRK6WUUiGkiVgppZQKIU3ESimlVAhpIlZKKaVCSBOxUkopFUKaiJVSSqkQ0kSslFJKhZAmYqWUUiqENBErpZRSIaSJWCmllAohTcRKKaVUCGkiVkoppUJIE7FSSikVQpqIlVJKqRDSRKyUUkqFkCZipZRSKoQ0ESullFIhpIlYKaWUCiFNxEoppVQItTgRi0hfEflERPaLyF4RuS8QBVPtlzEGj8eEuhjKD41npYLPEYB1uIEHjTHbRCQe2Coia40x+wKwbtVG5Ra7OJpTQk5xOdlFLnJLXJRVePAYg/Hm4EiHDWeEnegIOzGRduKiHMQ7HcQ7I0iIdpAQHUFcpAObTUL7ZjoWjWelgqzFidgYkwakeR8Xish+oDcQFoHrcntIzy8jv7SC/NIKCssqiLDbSIi2fuwTYyLpnuAMdTHbhRKXmwPphXyVXkh6flmDy7vcHlxuDwWlFXUuYxMh3ukgzukgPspBbJT1OCbSTkyEA2ekjZhIB5F2G5EOvdLSUuEez0q1R4E4I64mIgOAUcCXgVxvc6Tll7LnRAEHMwpxuT31Lts5JoLByfEM6ZlA55jIIJWw/XC5PfzftzlsP5aLO8BVzh5jqg+iGmITIdJhJWSHTXDYhQi7DbsIdptgswl2EWwCIoKI9RoBRLx/eM++a/6zHkvgzsx7JERxXnJCwNbXGsIpnpVqzwKWiEUkDngXuN8YU+Bn/l3AXQD9+vUL1GbPcDS7mM++PsWpwvJGvyavpIIvD+fw5eEc+ifFMPHcrnSP17Pkhhhj2J9WyPpDpygqd4e6OHiMoayikrKKylAXpUHn94wP60RcXzwHK5aV6igCkohFJAIraJcaY1b5W8YYsxhYDDB27NiAt9QpKnfznwNZHMwobNF6jmaXcCznGEN6JnDxOV2JiwpopUG7UeJys2Z3OsdzSkJdFBVgDcVza8eyUh1Ni7OMWPV1fwX2G2OebXmRmm7H8TzWHzrVYBV0YxkDe08W8HVmERPO6crIvp0Dst72Ii2/lA92pVFYFvqzYBVY4RDPSnU0gTjdmwDcCuwWkR3eaf/PGLMmAOuuV1lFJR/vy+CbzKJWWb/L7eGTrzI5ml3MtCHJREfaW2U7bcnu1Hw+OZBJpd5+1F6FLJ6V6qgC0Wr6C2q2aQmK9PwyPtidVm+L20A5nFXMW5uOMn1oMv2SYlp9e+HqPwez2HY0N9TFUK0oVPGsVEfWJu/32HYsl7e3HA9KEq5SVO5m1fZUth7NCdo2w4UxhrX7MjQJK6VUK2hTLZHKKipZuy+DQ61UFd0QY+Czg6fILa7gsvO6Y+8AHU1Uegwf7U3nQHrLGsEppZTyr80k4swCqyo6ryR4Z8F12X0in7zSCmam9MQZ0X6vG7srPXywO43DWcWhLopSSrVbYV81XekxbD6Sw4rNx5uUhAuyM3nhwVsoyMlq1vyGHM8pYcXm4xSUhf7AoDVUeowmYaWUCoKwTsTHc0pY+uVRvvj6VIM9NtVOrB8vfZFv92zh47f+p1HzmyOn2MXbm4+TU+xq9jrCkSZhFUhpaWlMnjyZ9PT0UBdFqbAkxgT/NpSxY8eaLVu21LvMJ19lsuN4XqPXufKPi9j4wXIQwXjOvJ9YbDbrIm8d8+0RkTz9we5Gb89XdKSd2aN606Md9Fnt8RjW7Enj64zQXIfvKM7vGc8Vw3o2uJyIbDXGjA1CkZqlMbF8zz338PLLL3PRVTdx/b2L6l22IDuTN37zAN9/5A8kJHYLYEmVaj0/mTqowWXqi+WwPSNOzW1cj00/nZnCA9MGs2H1MowxfpMsgPF4/M4Xm3WNd9SlM5pd1lJXJSu3prb5XqY8HsOHe9M1CauAiI6ORkR46aWXMMawYfUyHpg2mAemn1ddM9UaNVUdVUsvt6nQCdtE3FiPvr6O0ZfNJCLKOhutSqwAjsgoALr26l893xEZhSPy9MAOxmP1S7xl7Xs8MG0wP52ZUue26vuiu9we/rHjBEdOtc3qXGO0dbQKrMOHDzN37lxiYqx7763Ys2KyKtFWJd4n5k6qcUBdlbTri0dVkx7EtF1tptV0XRKSuuOMiaOi3Bp2ryqxArhd5YCDnMwYPO7J2OyDcLv6AIXEdSkhsYeL4wffx3iOERHlZPiEqcy662d1bsv3i+6viq2i0vD+zpPMGN6Tc7rHBfidth4rCWfwlSZhFUA9e/YkISGBsjIrNq14tGxYvYwNq5edXrjWJbLGxKOy/HRmit9964iM4qnVu0JYMtVYbT4RF2RnsuPzD0mZdCWu0mIObluPp7ISR+QQkpKfIDv9ctyuLgBYObociKIoF4pyAf4Esp2K8rew2Ur9Xpdqyhe90mP4YFca04f1COvRdapUddaxP+2MAbOUarGMjIxmDR9ZUV6GMyauw18nbsw180dfX8f7i3/P7g3rqCgvwxEZhTM6lrt/vyTIpVXN1earpj9e+iKlhfnEJXQmsXsvPJWXIvIpbtdeMo5dg9v1GXA7MAlrfPNowIkjYhgxCTfSZ9ASuvXuA/w3W9b9iUeuy+SrrTWv9dau/o6IcjJ6ynd59I1/+S2Txxg+3JPOnhP5rfjOW84Yw7r9mew9qUlYtY5Vq1Zx/PhxRl82s8ZlI18ip3+GxGbnvAsmMXbqbApzTwWrmGGrvurmqktliOCMicPtKscRGYXbVU5Rfg4bVy8PQYlVc7TZM+Izz1I/AZ4F5hDfpYT4xKUUZD9NWckBKsrLiIhy0impB9lpYI+Ayop9jJyUwvX3TmDlH+8jK3UbsZ1+THH+91i8MIm4zmu46zc96HNOp+rqb98vujMmDozhhQdv8Xu0agys25+Bq9LD6H5dgrtzGsHj7TFLq6NVa+vZsyfOmLgal418GWM1oBSxgfGQ2KN3g62r26uqM+BjX+3EXXH6tsjqqnwRFi37nITEbtVJevUrz7Dv/z4FEa2ibqPa5BlxQXYmvc4+j2ETpuKIjAZ+BHyFyPVcev0xHnnjBA++eAHDLz6/RvL0eCq5eOYc7nv+bS6eOYeNH6yobiACByjOXwCcCzxDUd5Unr1nCOuWJeKphMK87BqvLcw9xcdLX+Tw7s08e89svw24jIH/HMjiy8PZwd1BDXBXeli9O02TsAqawrxsJnx3Lnf/bglde/e3bifEql3q1DWZsVNn88CLf6+OrY7aArgquY6cPOOMWriuvfojcEbDti3r3qOkIA9jTJNq7lT4aJNnxB8vfZHjB3bRtddY3K5VwBXAx4yc/CGz7ppXvVxV8hw/40Y2rVlBQU4W1/34cQCu+/HjTJ07n/cX/55d69f6HEnmAz8DXgaeZs2S61jz2lc89ubLdOlujb/75Ufv1jjyLMjJYtFNE+s88tzwTTauSg+XnBv6610VlR7+d+dJjma37VutVNty2+MvVD8eNPIiNp48Vn2APHT8ZdVnwFXxufKPi6rP9nIyTrT7+4pr1/BtWfdejfkV5WWcOnnUelJX3w/GsO2T1QA1au7a835rL9pUIq75ZR1H1ol3gB6I7UdcNCOPwtyaR8++wV8V4L6qqpwrK1yIzVbrHuNviYi6hV5nHyXt2/t4Zh587/4MRkwq4tHX1/HEzZPPuCfZ7SrnpzNT/CbjLUdyKS6vZOqQHiEbLKK43M37O0+Snl8Wku0rBf4PkKvUlZCemDuJ//5wP9A+O/2o3eBKbHaMp5JufQZw7YLHefdPizh14mi964iIchIT35lzR13E5Gt/eMa+VeGrTSXi+55bzks/v4Oy4lvwVD4NpDF47ELmPDS32QFZ9aOQcfwwRbnZlBTlU5CdiYiNivIycjN+x63/bzhv/bYnrz85jIlX53LZDZnEJHSmOO/0kIg2m52Rl86o93aL/WkFFJW7QzJYxKmict7bfoLCMvcZ89rjD5sKX/UdIFclpKozuyrG4+GBaYNxREYxbtq19d5G2BbVdRtmVuoR/vzz28DboE1EqOoNUWx2OiV1Jy8rDRFbnbULKvy1qUS8fvW7lBT8DvgvRNZgzC2kHXYA1zV7nb4/CgBLnlhAQmI3xs+4kaW/e5D0o4dY/dd7KC89Ss+z3uOLf8xgz4YEivPcRMclUFpciIjg8VQ2qhroeE4J72w5ztWjepPgjGh2uZviyKliPtidhsvtv9exhu6PVipYqhISWI23qhpyRUQ5cVe4cLvKq+8/bm+NkQrzsrlg6mwK87Krb8Osup/68O4t5GWlkZjch+y049UN22x2OxO+O9dv7YJqO8K2r+k3Nx7hVJHVatCqrooDVgKXAk8CvwCssl88c05AE0jt6rGa7gBeAg4C3wW+xe6IYPyVN1CQk3VGYq9LbJSdK4b2pF9STGAK7Ycxhs1Hctn4TTYeP59zXe+zvfywhbOO1Nc0wB/WHmz0OqsOhgvzctj1+Yfe25sMYy6/Gk+lu7r61rfTj/ZUk7Py+cfZuGYF9ojIOn+HmvObo1pPS/uabhNnxHf9ej2vPNYLV1kX4GbgbzXmB/rIuKp6rGYjLmtgiITED8nPnonHvQz4ksFjfs+ch2c3+YeguLySVdtTGds/kYsHJmEL8HXjgrIKPtqTTmpuaZ3L1L4u1djejCpcwvEDTo4dcFKUb6es2EZpkY2KchvR8ZXEJlQSE19Jp65ukvu76N7XRVR08A/4VNtUlViWPLHgjLO9+M5JZ9xG2B6SsO/lId9r6J+teo2D2zdSUpjXrg8+OrqwT8R7NsSy9KmBGFMIXIYjcjtul9V/dH52RpMSSGP5a8QlNhsedwWRUdGYyrXYIyZRWfEeX+94krRvT5GQ2PRWyMbA5iM5nMgr4YphPekUHZiq6oMZhfxrfyZlFf7v26xS1/3R/gI875SDL/+ZwMFtsRw7GEVlhXXNyu4wRMdWEh3nwRFpKP06iqICO25XzTvjEntU0PucMvoNtv76DConOtZ/VblS4P9a8pInFtTZ0Kst87085Pu+5zz8u+oz5PZ28KFOC8tEnJaWxpPzbyKx92tsWtObHv1zyc++hBGTBjH52oVsWrOC/Zv/06pHxrUbccV1SaJH37PZvX6tz9Hqs+ze8CCvPHY2N/88jZGTmjdq0cm8Mt7YcIQRfTsz7qzEZjfkOplXyvpDp+o9C66tvhasxsCRfU4+f68zu76Ix3ig7+AyLrk6j7OHlTJgSBmxnSrx14Ohq0zIzYwg41gkGUcjSTsSyYlDTnavjwdAxNC9n4v+55XR//wy+p9XSo/+LuzBbcOm2pCC7EyKC/K47sePk5DYrV00RmpM97n1xahqHwJyjVhErgCeB+zAK8aY39W3fEPXle644wFeffVSYBawhO79niHr+P4a45n6Nqqq+nKG4lpJaZGNV37RiyN7o7nux5kMu+jrFrVAjoqwMaZfF0b260yUo3FZKbOgjI2HszmcFbiRn05+G8mqP3Xn8J4YnLGVjL8ynwnfzSepZ0WL1ltcYCP1oJOjX1lV20f3R1NcYL1PR6SHXmeX0/fccnoNLCe5fzk9+rmIiW9/Z87hfI24KfHcGteI61I15nhjxjVuKwqyM+u8PKRnvW1HS68RtzgRi4gdq+XSVCAV2AzMMcbsq+s1dQVvdHS0d6SWN4EbgZ8AZ/axGm6NiVxlwl8fT+Lr7Yn0OXcJJw7dwZjLr25RRwR2m9Czk5P+SbEMSIoh3tvC2mDwGEjPL+NodjFHsksoKG1+cqx961J5qfDRm0l8tqoL0XEepn//FBdMLWi1a7zGwKmTERz7yknqoShSv7b+l5ecPghJSHTTtbeLpOQKuvRwk5hcQadEN3Fd3CQkWtek6+jGOGyFayJuajwHIxG39UaF9d0eWJCdyX//6FqKck9hj4ikssLVrg40OopwSMQXAYuMMdO9zxcCGGN+W9dr6gretLQ0HnroIVat+pKysl7A5zXmOyKjSJk4LSyPFh+YPhzMG1gHEI9htewGsdmqOyIIR75nGcMufooVz/Yg/1QE46/M46o7ThGbEPyzUY8HcjOsau30o1bV9qm0CHLTI8jPdmBMzbpwEUNUjIfoOA/OWA/OmEoinYaISENklHXt2hFhsEcYHA6DzW6w2aj+LzZrHVVjD4jgrW431n/x3Vb9ZW/sQEM9EqJYcEsnhg5taH1BT8RNiufGJOL774fVnzS/Jzd3RQVZJ45QUpDrLaON2E5dSOrZD0dEBO6KCjKOHaJHv3NwRATnlsD61C5PVuoRCnIySUjsTrc+A2osWzUvIiqaHv0GUpCTSWVFBckDzg1N4VWzzLwshueeq3+Z1m413Rs47vM8FbjQTyHuAu4C6Nevn98VVY1f6nJ9i9i+xfjkALHZqKxwhV1DhZpH6zcDZcCvsEZ5eqRGRwThdPRes9x2NqweyobVfUD2cu9z8QwYErret2w2SOpZQVLPCoZcWLO63e0ScrMcFObaKcxxUJhnpyjPQWmRzdt6205ZidWKu6DchqtMcFcIlRWC2209Nh7BU8kZCT3Yxp5Dg4k4BBqM58bEciA5IiKqO7oAa5AIm81enXRzM05QVlxIbsaJGokuVAm6qjxH92+vMb0gJ5OCnMzqzjl8f+AqyktJ/XoPiI2Bw8P2bjXVSgKRiP39mp1xmm2MWQwsBusouq6VZWRkMG/ePD79cjs5p05RmHeK+M5dqxtLNbWhQu/O0fRNjKFTdASdYyLoFB2Bu9JQUFZBQVkFeSUVfJ1RSG5J86p3a98CBLcBJcD/A2JwRC4kZWL4DHBeVU123/Mr+OTtV9i1fi9u1xJgMkk9P2Le7xNISg79WUVdHJGGbr0r6Na7ZdeqwTrzNh6retwY8XkMGLG+xD7f1NqVRy2pTBrUI45ZY5Obv4LW02A8NzaWqzz3HPRfm9qswtRVLV2Ya6OkKKJWn+/Wnz0ikqc/2M3KPy7i2FfL6T0wOFW99fc/YNXoRUZFk5jcmxsf+DWfvP1KHdeGm7evVOg0pmq6PoFIxKlAX5/nfYCTzV3ZqlWrgJodejRVdKSd83smMKxXAklxUX6X6RRzOtlMOKcr6fll7E8v4EB6IaWu+m/78eV7C1BVT0CJyb8lJ70UeAC3K56o6H+HzVl81W0SGz9YQXnpBbhdfwVigFsZPKaSpORFIS5h8Nhs+Iw/VjuftO59zwmdDU5nq26iuQIazy1V373uhTlZvLzwDspLi6348/bP7Kl088C0wdXrCFYPXP7Kag29eqy6cw63q5ySwjw2frCi0bcOqvYvEIl4M3CuiJwFnABuAuYGYL1N5rAJYwZ0YdyARBz2po3wmNzJSXInJxcPTGLzt7lsP5aL29O4H+PatxdYtzhtxeM5wKY1d/B/H3Xhwiu/4v0/P1ndYCPY/TufeZtEHLAQOMQPH9/D19s8FOToQOwqfOIZ6r/X/eO3/ofi/NP9vVf1z1x7MJZA9zPQlLJ6PJVnjBMMVHfTKTYb9z3/tt6W1MG1OBEbY9wisgD4COt2h1eNMXtbXLIm6pcYw5TzutMlNrJF64ly2Jl4bleG9+nE+kOnONCIMXtrdzzge39j2rd/4+j+ubz48L9xle6p7s852P07n+4t7BPcrt8CP8buWMf8p12cPfQcUia0/XsyVcuFSzz7qn2gu2H18upE5k/tM9GK8jIO7dgUkrIW5GRx7x+W8e6fnmDPpn+fPkgQGzHxCcx/6nV6n31eu7gnWjVfm+hruj6RDhuXDe7OkF4JgSpeDYezili7L4OSJlRXQ+0z0LuBF4EvgGuA3DOWD3S1mb8z7mVPP8XmtTdi3Zny38BPuXjmjXqrRAiE6+1LTRXM+4ir+Lv31jfxVla46NKjN+dfMKnG4C2B7pO+KVY+/zgbPlh+xvRQlkkFTktvX2pa/W2Y6RwTwY0X9G21JAxwdrc4bhnfn/5NHJzh0dfXMfqymTgio4A/Y9XuXQhsIKHreO906+h99JTv8ugb/wpouX3PuAHSj0Sy8/NfApOwGpQ9BHjYsHoZD0wbzE9npgR0+0q1lrqqgC+eOYf7nn+bi2fOoffA8/nyo3f57/lXk370EED1d/3hq4a3SrkKsjN54cFb/FYxF+Zlk5jcB7HV/MnV+FMQpl1cNsbZ3WKZPjQ5KOP6xkY5mD2qN1uP5rL+kP+RjGo7s7/qFSDpYP5OUc7/4vFciSNyd8Crzfx3mVcMvEV8YjS3LtzL9k9PsXuDs1X66VYqGPxVAVdV71b9r33mXNWYa9SlMxq9naa05ajvclPV5av6etJSHVebPCMed1Yis0b0CkoSriIijB2QyNUjexEV0bjdVvVjMTBlHMn9z+WcEeWMuvQ3GIqx2T9n+q1fkNz/HApysqrPXJuq9lF41Zl4RJQTsCO2J4F/kNzfzU9eOMbQi6K1taZq8257/AWu+/Hj9B5oXV/1171t1cFw1T3IVY25tqx9r9FnobVrlvz56cwUHpg2mA2rl2GMqfcstykDraiOo00lYhG4dHA3JpzTFWlsF0YBNqBrLDeO7duokZKqfizueep1fvqX1dzz1OtcfffV9B00D49nOx/8dSzpRx8GoptdRVX7h+L0j09PkM8xnkeA1xgw5H46d3UDpw8QqqrxCnO1tbRqnwrzsrlg6mzOu2ASNu+IIr6Xg6oOZE98s7/GAW19ybX+g9/T67/v+RV+q6o1/lRtbaZq2m4Tpg9NZnByfKiLQlJcFHPG9eN/d57kRF7jRzoCK3EeP/ARoy+L5cSh75Fx7E5gAnATwyf0rNF6sr5qsfpGbUnu/wTwZ2+PE3OBZWz6J2z65xvVnR1U0daaqr3xjZuqM+WVzz+O8XiqW1HbbHYSErux8o+L+HbPFt763UNkHvumulq5vvuXP37rf2pUQdd1lrvxgxV+q6r9De+oOrY20Wo60mFjZkpP+ifFBqN4jeau9PDB7rRGjXpUd68738Ea5KIzMQlvsvDVy6r7d6492kzVD8zsex7hnecfJyGpOwe2fE5FeRmOyCgiIseT3H8F3+7tQb/B+cR3eYCD2/9W4/rY2KnXMPfh3wdyN6hm0FbTrcffKE1Vo7UV5eew87MPG1yHIzKKcVNns3HNiuqW2IiccY9y1bLnXzCpejS4Z380u87lwqmbWxU4IR/0oTmakogjHTauHtmLPl2a1mo5WDwew9r9Gew7WVDvcv4aaZzuP7c78BRwK1AA/B74I1ZXmaeJzQbG0L3fQDKPfUNSr/6cOnEEu2Mole7HgBtxRBQx47ZSJs3OZdUL/m+ZAP1RCDVNxIFX3yhNQL3dT/ouWzWwzLt/eqLGUKvZ6anExCU0OGShDm3Y8bTr25ciHTauGdU7bJMwgM0mTBvSg9H9u9S7nL/qq7HfucZ7bakA+CHIKOA/wG+xehV8F7iTqh4HjceDMYaMo4cxZhynTnwf2ECleydwFfAr3BV9eH9xd35+dUqD18eUak/qulb76Bv/OmOeIzIKR2QkiFTfUuQ7sAzGUFyQx9Sb76H3wPOYOnc+rrJSxG5vsKGVNshSTRW214gjHTZmj+pNr87RoS5Kg0SEyYO64XTY2PBNdp3L+bvlIr5z0ukzY7MLq8OPi7Du9b0CuNb76lJO93/sACIBD1aPhL8CXgIycURG4YxO5O7fL6H32ecBp6+P6Y+Cas8aSoC15wH06H8O8V26UpSbXWNgmdq3IlU9z8vqXR3Dn616jR2f/ZNpt/zojHjyF+tK1SVsE/EVw3o2qmVyOLnw7CQcdhufHfQfdP4aaSx5YgEXTJ1NYV42B7Z+4b22tNH7B3A+MB3wrcY0wHZgLZBTff3X4e1YvshVzsbVy6uvj+mPguoo6vuuF+Zln9Hvc8bRQ2QcPYQjMoqf/mV1nY0gq+Skp7L+f//Glx+9y7hp11JamF/vfcOgDbJUw8L2GnFbtis1j39/ldmkYfJWPv84G9esqG4QYnUC4qFrr/7kZ2dUN7iKTehMdFwC5aXFFGRnVo/4hIjfcflaci040mEj0m6jxFXZqE5MVOPpNeLQaOj67YlD+2qM6OSIjCK+S1cKc0/5JGjB3+hc2u6i42rpNeKwPSNuy1L6dMZuE9bty2x0Aqs6ks84frhGNdn+zf+p/kGorHCRMnEa19+7qLoVaGMakjRWVISN85MT6JHgpEdCFImxkYgIxhjKKjwUu9ycyC3lm6wiUnNLqWzk6FRKhYuGqq83rnm7ekSnqpjLzThJzcRb83uvvWOpltJE3EqG9upEhN3Gh3vSG5Ww/PUMBFbV9fkXTD6jqs1f1dfK5x9vVgOR6Eg7o/p2ZmS/zkQ5zuytTESIjrQTHWmna1wUI/p2pqyikm+yithxPI/MgoZboyoVLvxVX/trcW2NcWwjrlNnnLHx5GWm466wpiUl9w3J6E6qfdJE3IoG9YjHYRM+2JXW6LGNa2vKtaamXgu224RxZyUyul8XIh1Na0DvjLAztFcnhvbqxLHsErYczeFodknDL1QdUmOq7oLlJ1M/Pv1k3iwA0tLSeOihh3jvvfcoKSkhJiaG2bNn88wzz5CcnMz8+fNZvHgxTqcTl8tFfJSN782fz1133cXNN9/M3r17yfjPUh5/8cUQvSvVlmkibmVnd4vjmlG9eX/nSVzuM2/yD6SmJO2ucZFMH5ZM93hni7fbLymGfkkxZBaUsfFwdqM6OFEqnPTs2ZOEhATKyspwOp2UlZWRkJBAcnIyABkZGcybN4+77rqLxYsXk5aWxquvvsqLPon3pZde4qWXXsLpdFJa2rQe91THpok4CPomxnDt6N78Y8dJSps4rnGgicDIvp2ZeE5XHPbA3kbePcHJ1SN7k55fxqbD2Xx7ShOyajv8Jdsqq1atqn78P/9j9ete31m0Uk2hiThIenaK5saxffn79hPkl1aEpAzOCDtXDEvmrK6t21Vocicn14zqTVp+KV8eztGErNoEf8m2Pg2dRSvVWGHds1Z70yU2kpvG9aVnp5ZXBzdVjwQncy/s1+pJ2FfPTtFcM6o3cy/sx9ndYgnRgFlKtZqqs+hNmzYxb9480tPTQ10k1QbpGXGQxUQ6uG5MHz7ck86hzKKgbHN4705cOrhbwKuiG6uHt8o6p9jFjuO57E8rbPXr5UoFQ1PPopXyRxNxCETYrdGkth3LZf2h7Fa7H9cZYefy87szqEfoh44ESIyNZMp5Pbh4YFf2nsxn38mC6hG2lFKqo2pRIhaRp4HvAi7gG+A2Y0xeAMrV7okIY/on0qdLDGt2p5FXEtjrxn0TY5g+tAfxzvDrJtQZYWdM/0TG9E8ks7CMA+mFHEgvpLDMHeqidWgaz0qFRkvrKtcCw4wxKcBBYGHLi9SxVF27HdorISDXUCMdNiYN6sZ1o3uHZRKurXu8k0vO7cadl5zN9y/qz6RB3eifFEOEXS8oh4DGs1Ih0KIzYmOMz53xbAKub1lxOqYoh51pQ5MZ3b8L6w+datZ9uA6bkNK3M+MGJBIdeWbvWG1BUlwUSXFRjOnfBY/HcKq4nMyCcjIKysgucpFb4qIkxLd/tWcaz0qFRiCvEd8OrAjg+jqcrnFRXD2yNyfyStl2NJdjOSUNNmqKdzoY2C2OsQO6tIkz4May2YTu8U66xzsZ1rtT9fSyikrySysoLHNTXO6m2OWmpLySMncl5RUeytyVuNwe3JWGCo/1X/vEbhaNZ6WCpMFELCLrAH83xj1ijPmHd5lHADewtJ713AXcBdCvX79mFbaj6N05mt6do6n0GE7mlXI0u4SCstPXkAWr84wBSTEkxUWFrqAh4Iyw44yw0yOh8a/xeAyVxkrIHmPwGDA+/42xuvE3xlR35+87VoehxpNm832pMyI0tRaBiGeNZaUCq8XDIIrID4B5wOXGmEZ1Ntzeh0FUKlCCPQxiU+NZY1mpxmm1YRBF5ArgZ8DkxiZhpVR40nhWKjRa2mr6BSAeWCsiO0Tk5QCUSSkVGhrPSoVAS1tNnxOogiilQkvjWanQ0L6mlVJKqRDSRKyUUkqFkCZipZRSKoQ0ESullFIhpIlYKaWUCiFNxEoppVQIaSJWSimlQkgTsVJKKRVCmoiVUkqpENJErJRSSoVQi0dfatZGRbKAow0s1hU4FYTiBJqWO/jaatkbU+7+xphuwShMczQylqF9f0bhSMsdXC2K5ZAk4sYQkS3BHP4tULTcwddWy95Wy90cbfW9armDq6OWW6umlVJKqRDSRKyUUkqFUDgn4sWhLkAzabmDr62Wva2Wuzna6nvVcgdXhyx32F4jVkoppTqCcD4jVkoppdq9kCdiEblCRA6IyCER+bmf+SIif/TO3yUio0NRztoaUe5LRSRfRHZ4/34RinLWJiKvikimiOypY3647u+Gyh12+1tE+orIJyKyX0T2ish9fpYJy/3dHBrLwaWxHFytGs/GmJD9AXbgG+BsIBLYCQyptcwM4J+AAOOBL0NZ5iaU+1JgdajL6qfsk4DRwJ465ofd/m5kucNufwM9gdHex/HAwbbw/W7me9VYDn7ZNZaDW+5Wi+dQnxGPAw4ZYw4bY1zAcuDqWstcDbxhLJuAziLSM9gFraUx5Q5LxpjPgJx6FgnH/d2YcocdY0yaMWab93EhsB/oXWuxsNzfzaCxHGQay8HVmvEc6kTcGzju8zyVM99YY5YJtsaW6SIR2Ski/xSRocEpWouF4/5urLDd3yIyABgFfFlrVlve3740lsNPOO7vxgrr/R3oeHYErGTNI36m1W7G3Zhlgq0xZdqG1aVZkYjMAN4Dzm3tggVAOO7vxgjb/S0iccC7wP3GmILas/28pC3s79o0lsNPOO7vxgjr/d0a8RzqM+JUoK/P8z7AyWYsE2wNlskYU2CMKfI+XgNEiEjX4BWx2cJxfzcoXPe3iERgBe1SY8wqP4u0yf3th8Zy+AnH/d2gcN7frRXPoU7Em4FzReQsEYkEbgLer7XM+8D3va3RxgP5xpi0YBe0lgbLLSLJIiLex+Ow9nV20EvadOG4vxsUjvvbW56/AvuNMc/WsVib3N9+aCyHn3Dc3w0K1/3dmvEc0qppY4xbRBYAH2G1XnzVGLNXROZ5578MrMFqiXYIKAFuC1V5qzSy3NcD80XEDZQCNxlvs7pQEpFlWK0Su4pIKvA4EAHhu7+hUeUOx/09AbgV2C0iO7zT/h/QD8J7fzeVxnLwaSwHXavFs/aspZRSSoVQqKumlVJKqQ5NE7FSSikVQpqIlVJKqRDSRKyUUkqFkCZipZRSKoQ0ESullFIhpIlYKaWUCiFNxEoppVQI/X9xjc2p/th+gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(3)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-3, 8])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-3, 8])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b432934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0, -0.4060058497098381],\n",
       " [0.0, 1.0, 0.0],\n",
       " [-0.4060058497098381, 0.0, 1.0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = float(SE.diff(x2).diff(x1)(int(v1), int(v2), lengthscale, variance))\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sigma^2, e^(-1/2*(x1 - x2)^2/l^2)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.6065, -0.1353],\n",
       "        [-0.6065,  1.0000,  0.6065],\n",
       "        [-0.6767, -0.6065,  1.0000]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1 \n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "left_poly = dx2\n",
    "right_poly = 1\n",
    "diffed_kernel2 = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate() + diffed_kernel2(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[l_11 l_12 l_13]\n",
      "[l_21 l_22 l_23]\n",
      "[l_31 l_32 l_33]\n",
      "[m_11 m_12 m_13]\n",
      "[m_21 m_22 m_23]\n",
      "[m_31 m_32 m_33]\n",
      "[r_11 r_12 r_13]\n",
      "[r_21 r_22 r_23]\n",
      "[r_31 r_32 r_33]\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_11 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_21 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_31\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_12 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_22 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_32\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_13 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_23 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_33\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_11 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_21 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_31\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_12 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_22 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_32\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_13 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_23 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_33\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_11 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_21 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_31\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_12 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_22 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_32\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_13 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_23 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_33\n",
      "\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_11 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_21 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_12 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_22 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_13 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_23 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_33\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_11 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_21 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_12 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_22 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_13 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_23 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_33\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_11 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_21 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_12 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_22 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_13 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_23 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff_sage(L, M, R, context=None):\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "        map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    # Every row in 'M' is combined with each elem of the row given in 'R'\n",
    "    # Or: For each elemtn in row 'R' combine with 'row_M'\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        # Each element in L gets exactly one element in 'row_M' to multiply\n",
    "        # Or: Combine each element in row_M with exactly one element in 'L'\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp = m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp = m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp = m_elem.diff(l_elem)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp += m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp += m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp += m_elem.diff(l_elem)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "    return temp\n",
    "\n",
    "def diff_sage(matrix, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(matrix)[1])] for j in range(np.shape(matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = calc_cell_diff_sage(l, matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(matrix)[0])][\n",
    "                    int(i % np.shape(matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0d27f4c05b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mSEKernelMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_sage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEKernelMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcov_matr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "L = matrix(2, 2, (x1, x1, 0, x1))\n",
    "R = matrix(2, 2, (x2, 0, x2, x2))\n",
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), None], [None, sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "diffed_SE_sage_matrix_kernel = diff_sage(SEKernelMatrix, left_matrix=L, right_matrix=R)\n",
    "pprint.pprint(diffed_SE_sage_matrix_kernel)\n",
    "cov_matr = [[None for i in range(len(X)*len(diffed_SE_sage_matrix_kernel))] for j in range(len(X)*len(diffed_SE_sage_matrix_kernel))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    for row in range(len(diffed_SE_sage_matrix_kernel)):\n",
    "        for col in range(len(diffed_SE_sage_matrix_kernel)):\n",
    "            # Blockwise\n",
    "            cov_matr[int(i/len(X))+row*len(X)][int(i%len(X))+col*len(X)] = diffed_SE_sage_matrix_kernel[row][col].substitute(x1=int(v1), x2=int(v2), l=lengthscale, sigma=variance)\n",
    "            # Interleaved\n",
    "            #cov_matr[int(((i*len(diffed_SE_sage_matrix_kernel))+row)/(len(X)*len(diffed_SE_sage_matrix_kernel)))*2+row][int((i*len(diffed_SE_sage_matrix_kernel))+col)%(len(X)*len(diffed_SE_sage_matrix_kernel))] = float(diffed_SE_sage_matrix_kernel[row][col].substitute(x1=int(v1), x2=int(v2), l=lengthscale, sigma=variance))\n",
    "cov_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "\n",
    "covar_x = covar_module(X)\n",
    "covar_x.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = [[2, 0, -6*e^(-2), 1, e^(-1/2), -e^(-2)],\n",
    " [0, 2, 0, -e^(-1/2), 1, e^(-1/2)],\n",
    " [-6*e^(-2), 0, 2, -5*e^(-2), -e^(-1/2), 1],\n",
    " [1, e^(-1/2), -e^(-2), 1, 0, -3*e^(-2)],\n",
    " [-e^(-1/2), 1, e^(-1/2), 0, 1, 0],\n",
    " [-5*e^(-2), -e^(-1/2), 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = [[2, 0, -6*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 2, 0, 0, 1, 0],\n",
    " [-6*e^(-2), 0, 2, -3*e^(-2), 0, 1],\n",
    " [1, 0, -3*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 1, 0, 0, 1, 0],\n",
    " [-3*e^(-2), 0, 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = torch.Tensor(matr)\n",
    "import pprint\n",
    "pprint.pprint(matr)\n",
    "print(matr[0::3, 0::3])\n",
    "H_x = 3\n",
    "torch.vstack([torch.hstack([matr[k::H_x, l::H_x] for l in range(H_x)]) for k in range(H_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968eb98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = var('a, b, c, d')\n",
    "A = matrix(2,2, (a, b, c, d))\n",
    "B = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "C = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "print(A)\n",
    "print(B)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2885ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['a', 'b', 'c']\n",
    "y = x                 # x and y reference the same object\n",
    "z = ['a', 'b', 'c']   # x and z reference different objects\n",
    "#z\n",
    "\n",
    "\n",
    "print(x is z)\n",
    "z = x\n",
    "print(x is z)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
