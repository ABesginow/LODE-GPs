{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99ad177f",
   "metadata": {},
   "source": [
    "def replace_mat_variables(m, original:str = 'x', replace:str = None):\n",
    "    m = copy(m)\n",
    "    x = var(original)\n",
    "    if not replace is None:\n",
    "        x1 = var(replace)\n",
    "        for i, row in enumerate(m):\n",
    "            for j, entry in enumerate(row):\n",
    "                m[i, j] = entry.substitute(x1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85d84a63",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# TODO Nochmal durchlaufen lassen\n",
    "def get_prepared_SNF(matrix, left_var=var('dx1'), right_var=var('dx2')):\n",
    "    d, u, v = matrix.smith_form()\n",
    "    (r, c) = np.shape(d)\n",
    "    if r > c:\n",
    "        assert \"More rows than columns in diagonal matrix D\"\n",
    "    dim = max(r,c)\n",
    "    cov_fkt_matr = [[0 for i in range(dim)] for j in range(dim)]\n",
    "    if not d == u*matrix*v:\n",
    "        assert \"The calculation of the Smith form failed or is not possible\"\n",
    "    V_left_transpose = replace_mat_variables(v.transpose(), replace='dx1')\n",
    "    V_right = replace_mat_variables(v, replace='dx2')\n",
    "    \n",
    "    return V_left_transpose, V_right"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d750964e",
   "metadata": {},
   "source": [
    "R.<x> = QQ[]\n",
    "m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "#dx1 = var('dx1')\n",
    "#m[0, 0].substitute(dx1)\n",
    "get_prepared_SNF(m)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d56d1013",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def test_get_prepared_SNF():\n",
    "    m = matrix(2,2,(1,0,1,0))\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [1][1]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0.],[0., 1.]], \"Test 1 failed\"\n",
    "    \n",
    "    R.<x> = QQ[]\n",
    "    m=x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [2][2]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0., 0.],[0., 0., 0.],[0., 0., 1.]], \"Test 2 failed\"\n",
    "    \n",
    "test_get_cov_fkt_from_SNF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(-2), float(2), int(50))\n",
    "# The original sin/cos data\n",
    "#one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.02)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(3)*torch.pow(train_x, int(2)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = int(3)*train_x**int(2) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Combined poly + sin/cos\n",
    "#one = torch.mul(torch.sin(train_x), train_x)+ torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.mul(torch.cos(train_x), train_x) + torch.sin(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# only sin/cos\n",
    "#one = torch.mul(torch.sin(train_x), torch.cos(train_x)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.mul(torch.cos(train_x), torch.cos(train_x)) - torch.mul(torch.sin(train_x), torch.sin(train_x)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "train_y = torch.stack([one,two], int(-1))\n",
    "#train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385213ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0000, -1.9184, -1.8367, -1.7551, -1.6735, -1.5918, -1.5102, -1.4286,\n",
      "        -1.3469, -1.2653, -1.1837, -1.1020, -1.0204, -0.9388, -0.8571, -0.7755,\n",
      "        -0.6939, -0.6122, -0.5306, -0.4490, -0.3673, -0.2857, -0.2041, -0.1224,\n",
      "        -0.0408,  0.0408,  0.1224,  0.2041,  0.2857,  0.3673,  0.4490,  0.5306,\n",
      "         0.6122,  0.6939,  0.7755,  0.8571,  0.9388,  1.0204,  1.1020,  1.1837,\n",
      "         1.2653,  1.3469,  1.4286,  1.5102,  1.5918,  1.6735,  1.7551,  1.8367,\n",
      "         1.9184,  2.0000])\n",
      "tensor([[-7.8867, 12.0190],\n",
      "        [-7.1659, 11.3208],\n",
      "        [-6.3685,  9.8042],\n",
      "        [-5.4901,  9.1701],\n",
      "        [-4.8626,  8.0502],\n",
      "        [-3.8630,  7.5623],\n",
      "        [-3.2745,  6.6173],\n",
      "        [-3.0323,  6.3024],\n",
      "        [-2.8664,  5.1874],\n",
      "        [-1.5771,  5.1255],\n",
      "        [-1.6478,  4.0896],\n",
      "        [-1.3055,  3.9604],\n",
      "        [-1.0817,  2.9709],\n",
      "        [-0.8594,  2.8358],\n",
      "        [-0.7968,  2.1306],\n",
      "        [-0.2734,  1.8103],\n",
      "        [-0.2616,  1.5663],\n",
      "        [ 0.0763,  1.2530],\n",
      "        [ 0.2967,  0.3075],\n",
      "        [-0.0701,  0.6148],\n",
      "        [ 0.2412,  0.1388],\n",
      "        [ 0.0133,  0.4589],\n",
      "        [-0.2855,  0.2763],\n",
      "        [ 0.1637,  0.1381],\n",
      "        [-0.2114,  0.2489],\n",
      "        [-0.1707, -0.1850],\n",
      "        [ 0.1607, -0.1447],\n",
      "        [ 0.2600,  0.0270],\n",
      "        [ 0.2257,  0.4567],\n",
      "        [ 0.2712,  0.3881],\n",
      "        [ 0.0979,  0.8005],\n",
      "        [ 0.0412,  1.0299],\n",
      "        [ 0.1508,  1.3278],\n",
      "        [ 0.0405,  1.4521],\n",
      "        [ 0.1525,  1.7330],\n",
      "        [ 0.4375,  2.3321],\n",
      "        [ 0.8401,  2.6566],\n",
      "        [ 1.3235,  3.3974],\n",
      "        [ 1.0778,  3.4789],\n",
      "        [ 1.5139,  4.0763],\n",
      "        [ 2.3868,  4.8539],\n",
      "        [ 2.5370,  5.5193],\n",
      "        [ 2.7515,  5.7893],\n",
      "        [ 3.5003,  6.8473],\n",
      "        [ 4.0045,  7.5405],\n",
      "        [ 4.6145,  8.1543],\n",
      "        [ 5.4014,  9.0287],\n",
      "        [ 6.4391, 10.1757],\n",
      "        [ 7.0565, 10.9267],\n",
      "        [ 7.6447, 12.2450]])\n",
      "torch.Size([50, 2])\n"
     ]
    }
   ],
   "source": [
    "print(train_x)\n",
    "print(train_y)\n",
    "print(np.shape(train_y))\n",
    "\n",
    "# = torch.Tensor([[float(-0.3), float(0.99)],[float(-0.07), float(1.01)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5884c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(train_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37706537",
   "metadata": {},
   "source": [
    "In Reihenfolge:\n",
    "- Mal ohne Ableitung durchlaufen lassen\n",
    "- Mal mit 1-en auf der Diagonale\n",
    "- Mal mit der Ableitungsdiagonale drehen\n",
    "- Gradienten ausgeben lassen\n",
    "- Mal den Datenvektor mit L multiplizieren und als neuen \"Ersteller\" fÃ¼r die Daten nehmen\n",
    "- Lasse L und R nicht quadratisch sein\n",
    "- Einfach -> L (2x3)\n",
    "- Schwer -> L (3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D object at 0x26bfdac10>,\n",
       " <matplotlib.lines.Line2D object at 0x26bfdac40>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec0044",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & dx_1 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "R =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 0\\\\\n",
    "dx_2 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "\\hat{k} =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "SE_1 & 0\\\\\n",
    "0 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "k =& L*\\hat{k}*R\\\\\n",
    "=& \\left[\n",
    "\\begin{matrix}\n",
    "dx_1 dx_2 SE_2 + SE_1 & dx_1 SE_2\\\\\n",
    "dx_2 SE_2 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            k1       dx2^2*k1]\n",
       "[      dx1^2*k1 dx1^2*dx2^2*k1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx1, dx2, k1, k2, f, g = var('dx1, dx2, k1, k2, f, g')\n",
    "K = matrix(2,2, (k1, 0, 0, 0))\n",
    "L = matrix(2, 2, (1, 0, dx1^2, 1))\n",
    "R = matrix(2, 2, (1, dx2^2, 0, 1))\n",
    "L*K*R\n",
    "# used to see how the data should be created if I \n",
    "# decide to create it exactly as I create the kernel\n",
    "#K = matrix(2,1, (f, g))\n",
    "#L*L*K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5dedb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all kernels: [Diff_SE_kernel()]\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(121)\u001b[0;36mextract_operand_list\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    119 \u001b[0;31m    \u001b[0;31m# Check if polynomial is an int/float -> List of operands is just the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m    \u001b[0;31m# number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 121 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolynomial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    122 \u001b[0;31m        \u001b[0mlist_of_operands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpolynomial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    123 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(121)\u001b[0;36mextract_operand_list\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    119 \u001b[0;31m    \u001b[0;31m# Check if polynomial is an int/float -> List of operands is just the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m    \u001b[0;31m# number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 121 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolynomial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    122 \u001b[0;31m        \u001b[0mlist_of_operands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpolynomial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    123 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel(var=0, length=0)\n",
    "        kernel2 = Diff_SE_kernel(var=0, length=0)\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        L = matrix(2, 2, (1, 0, dx1, 1))\n",
    "        R = matrix(2, 2, (1, dx2, 0, 1))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, None]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        \n",
    "        #kernel0 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel1 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel2 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel0 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel1 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel0 = Diff_SE_kernel(var = 0, length=0)\n",
    "        #kernel1 = Diff_SE_kernel(var = 0, length=0.01)\n",
    "        #kernel2 = Diff_SE_kernel(var = 0, length=0.02)\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel1]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "#likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2, has_global_noise=False, has_task_noise=False)\n",
    "likelihood._set_task_noises(torch.Tensor([float(0.0001),float(0.0001)]))\n",
    "#likelihood._set_noise(torch.tensor(float(0.0001)))\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(75)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "param_dict = {p[0]:[] for p in model.named_parameters() if 'covar' in p[0]}\n",
    "param_dict['loss'] = []\n",
    "param_dict['noise'] = []\n",
    "if len(likelihood.task_noises) > 1:\n",
    "    param_dict['task_noises'] = [[] for i in range(len(likelihood.task_noises))]\n",
    "for p in model.named_parameters():\n",
    "    if 'covar' in p[0]:\n",
    "        param_dict[f\"{p[0]}_grad\"] = []\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    param_dict['loss'].append(loss.item())\n",
    "    #pdb.set_trace()\n",
    "    loss.backward()\n",
    "    for parameter in model.named_parameters():\n",
    "        if 'covar' in parameter[0]:\n",
    "            param_dict[parameter[0]].append(parameter[1].item())\n",
    "            #param_dict[f\"{parameter[0]}_grad\"].append(parameter[1].grad.item())\n",
    "    param_dict['noise'].append(likelihood.noise.item())\n",
    "    for l in range(len(likelihood.task_noises)):\n",
    "        param_dict['task_noises'][l].append(likelihood.task_noises[l].item())\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood\n",
    "#torch.autograd.functional.hessian(likelihood, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0219bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_key in param_dict:\n",
    "    if param_key == 'task_noises':\n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(param_dict[param_key], label=param_key)\n",
    "    \n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d928e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likelihood.noise)\n",
    "print(likelihood.task_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b924f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = matrix(QQ, 4, 4, (2,0,0.6065,0.6065,0,1,-0.6065,0.6065,0.6065,-0.6065,2,0,0.6065,0.6065,0,1))\n",
    "L = A.cholesky()\n",
    "L*L.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(120)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(-2), float(7), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(4)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-30, 30])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-30, 30])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = matrix(1, 2, (1, 2))\n",
    "b = matrix(2, 2, (1, 2, 3, 4))\n",
    "a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(float(-2), float(2), int(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = float(SE.diff(x2).diff(x1).diff(x1).diff(x2)(int(v1), int(v2), lengthscale, variance))\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SE)\n",
    "print(SE.diff(x2))\n",
    "#print(SE.diff(x1).diff(x2))\n",
    "#print(SE.diff(x1).diff(x2).diff(x1))\n",
    "#print(SE.diff(x1).diff(x2).diff(x1).diff(x2))\n",
    "#float(SE.diff(x2).diff(x1)(float(1.), float(1.), 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1^3 \n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "left_poly = dx2\n",
    "right_poly = 1\n",
    "diffed_kernel2 = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate() + diffed_kernel2(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff_sage(L, M, R, context=None):\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "        map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    # Every row in 'M' is combined with each elem of the row given in 'R'\n",
    "    # Or: For each elemtn in row 'R' combine with 'row_M'\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        # Each element in L gets exactly one element in 'row_M' to multiply\n",
    "        # Or: Combine each element in row_M with exactly one element in 'L'\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp = m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp = m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp = m_elem.diff(l_elem)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp += m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp += m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp += m_elem.diff(l_elem)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "    return temp\n",
    "\n",
    "def diff_sage(matrix, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(matrix)[1])] for j in range(np.shape(matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = calc_cell_diff_sage(l, matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(matrix)[0])][\n",
    "                    int(i % np.shape(matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "L = matrix(2, 2, (x1, x1, 0, x1))\n",
    "R = matrix(2, 2, (x2, 0, x2, x2))\n",
    "x1, x2, l, sigma, l2, sigma2 = var('x1, x2, l, sigma, l2, sigma2')\n",
    "lengthscale = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance = 1\n",
    "lengthscale2 = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance2 = 1\n",
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), sigma2^2*exp(-(x1-x2)^2/(2*l2^2))], [sigma2^2*exp(-(x1-x2)^2/(2*l2^2)), sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "#diffed_SE_sage_matrix_kernel = diff_sage(SEKernelMatrix, left_matrix=L, right_matrix=R)\n",
    "#pprint.pprint(diffed_SE_sage_matrix_kernel)\n",
    "cov_matr = [[None for i in range(len(X)*len(SEKernelMatrix))] for j in range(len(X)*len(SEKernelMatrix))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    for row in range(len(SEKernelMatrix)):\n",
    "        for col in range(len(SEKernelMatrix)):\n",
    "            # Blockwise\n",
    "            #cov_matr[int(i/len(X))+row*len(X)][int(i%len(X))+col*len(X)] = SEKernelMatrix[row][col].substitute(x1=int(v1), x2=int(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2)\n",
    "            # Interleaved\n",
    "            text=f\"x-pos: {int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row}\" +\\\n",
    "            f\" y-pos: {int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))}\" + \\\n",
    "            f\" x1, x2: {v1}, {v2}\\n\" +\\\n",
    "            f\"(x1-x2)^2: {(v1-v2)**2}\"+\\\n",
    "            f\" exp((x1-x2)^2): {np.exp((v1-v2)**2)}\\n\"+\\\n",
    "            f\"val: {float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))}\"\n",
    "            print(text)\n",
    "            print(\"---\")\n",
    "            cov_matr[int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row][int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))] = float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))\n",
    "cov_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd554171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(torch.Tensor(cov_matr).eig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7195921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780479da",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(-(-2-0.66)^2/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b359f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "\n",
    "covar_x = covar_module(X)\n",
    "covar_x.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = [[2, 0, -6*e^(-2), 1, e^(-1/2), -e^(-2)],\n",
    " [0, 2, 0, -e^(-1/2), 1, e^(-1/2)],\n",
    " [-6*e^(-2), 0, 2, -5*e^(-2), -e^(-1/2), 1],\n",
    " [1, e^(-1/2), -e^(-2), 1, 0, -3*e^(-2)],\n",
    " [-e^(-1/2), 1, e^(-1/2), 0, 1, 0],\n",
    " [-5*e^(-2), -e^(-1/2), 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = [[2, 0, -6*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 2, 0, 0, 1, 0],\n",
    " [-6*e^(-2), 0, 2, -3*e^(-2), 0, 1],\n",
    " [1, 0, -3*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 1, 0, 0, 1, 0],\n",
    " [-3*e^(-2), 0, 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = torch.Tensor(matr)\n",
    "import pprint\n",
    "pprint.pprint(matr)\n",
    "print(matr[0::3, 0::3])\n",
    "H_x = 3\n",
    "torch.vstack([torch.hstack([matr[k::H_x, l::H_x] for l in range(H_x)]) for k in range(H_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa5cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = var('a, b, c, d')\n",
    "A = matrix(2,2, (a, b, c, d))\n",
    "B = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "C = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "print(A)\n",
    "print(B)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d1b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, x, y, dx1 = var('a, b, c, d, x, y, dx1')\n",
    "poly = (a*(2*(c+b)+a)+a)*y\n",
    "#poly = a*b*dx1**3\n",
    "print(type(poly))\n",
    "#poly = 839840583*x^75\n",
    "print(poly.degree(dx1))\n",
    "print(poly.operands())\n",
    "print([op.is_numeric() for op in poly.operands()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c43f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_list = []\n",
    "l1 = [[42, 17], [128, 256]]\n",
    "for i, l in enumerate(l1):\n",
    "    if i == 0:\n",
    "        func1 = lambda : l[0]*l[1]\n",
    "        return_list.append(func1)\n",
    "    else: \n",
    "        func2 = lambda : l[0]*l[1]\n",
    "        return_list.append(func2)\n",
    "\n",
    "for func in return_list:\n",
    "    print(func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967647fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
