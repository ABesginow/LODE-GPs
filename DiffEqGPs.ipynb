{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(0), float(1), int(50))\n",
    "one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361022cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8734672a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5dedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel()\n",
    "        kernel2 = Diff_SE_kernel()\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        # TODO test what happens with \n",
    "        #L = matrix(2, 2, (dx1, q, 0, dx1))\n",
    "        # -> does it learn q as a parameter?\n",
    "        #AND\n",
    "        #L = matrix(2, 2, (q*dx1, q, 0, dx1))\n",
    "        # -> does it learn multiple separate q?\n",
    "        L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "        R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        #kernel0 = Diff_SE_kernel()\n",
    "        #kernel1 = Diff_SE_kernel()\n",
    "        #kernel2 = Diff_SE_kernel()\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel2]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 1.0000, 1.9988,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9988, 0.9994, 2.0000,  ..., 0.0505, 0.0500, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0500,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 2.2222,  0.9091,  2.2205,  ...,  0.1265, -0.2812,  0.1044],\n",
      "        [ 0.9091,  1.3580,  0.9086,  ..., -0.1387,  0.1044, -0.1718],\n",
      "        [ 2.2205,  0.9086,  2.2222,  ...,  0.1490, -0.2270,  0.1265],\n",
      "        ...,\n",
      "        [ 0.1265, -0.1387,  0.1490,  ...,  1.3580,  0.9086,  1.3570],\n",
      "        [-0.2812,  0.1044, -0.2270,  ...,  0.9086,  2.2222,  0.9091],\n",
      "        [ 0.1044, -0.1718,  0.1265,  ...,  1.3570,  0.9091,  1.3580]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.9923,  0.8990,  1.9908,  ...,  0.1612, -0.2623,  0.1397],\n",
      "        [ 0.8990,  1.8344,  0.8986,  ..., -0.4292,  0.1397, -0.4689],\n",
      "        [ 1.9908,  0.8986,  1.9923,  ...,  0.1829, -0.2138,  0.1612],\n",
      "        ...,\n",
      "        [ 0.1612, -0.4292,  0.1829,  ...,  1.8344,  0.8986,  1.8326],\n",
      "        [-0.2623,  0.1397, -0.2138,  ...,  0.8986,  1.9923,  0.8990],\n",
      "        [ 0.1397, -0.4689,  0.1612,  ...,  1.8326,  0.8990,  1.8344]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.7877,  0.8562,  1.7863,  ...,  0.1715, -0.2593,  0.1512],\n",
      "        [ 0.8562,  2.5569,  0.8558,  ..., -0.9104,  0.1512, -0.9500],\n",
      "        [ 1.7863,  0.8558,  1.7877,  ...,  0.1919, -0.2161,  0.1715],\n",
      "        ...,\n",
      "        [ 0.1715, -0.9104,  0.1919,  ...,  2.5569,  0.8558,  2.5537],\n",
      "        [-0.2593,  0.1512, -0.2161,  ...,  0.8558,  1.7877,  0.8562],\n",
      "        [ 0.1512, -0.9500,  0.1715,  ...,  2.5537,  0.8562,  2.5569]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.6865,  0.8096,  1.6850,  ...,  0.1738, -0.3342,  0.1548],\n",
      "        [ 0.8096,  3.7028,  0.8092,  ..., -1.6195,  0.1548, -1.6366],\n",
      "        [ 1.6850,  0.8092,  1.6865,  ...,  0.1929, -0.2951,  0.1738],\n",
      "        ...,\n",
      "        [ 0.1738, -1.6195,  0.1929,  ...,  3.7028,  0.8092,  3.6965],\n",
      "        [-0.3342,  0.1548, -0.2951,  ...,  0.8092,  1.6865,  0.8096],\n",
      "        [ 0.1548, -1.6366,  0.1738,  ...,  3.6965,  0.8096,  3.7028]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.6479,  0.7861,  1.6462,  ...,  0.1741, -0.4632,  0.1557],\n",
      "        [ 0.7861,  5.3360,  0.7857,  ..., -2.2861,  0.1557, -2.2412],\n",
      "        [ 1.6462,  0.7857,  1.6479,  ...,  0.1926, -0.4291,  0.1741],\n",
      "        ...,\n",
      "        [ 0.1741, -2.2861,  0.1926,  ...,  5.3360,  0.7857,  5.3235],\n",
      "        [-0.4632,  0.1557, -0.4291,  ...,  0.7857,  1.6479,  0.7861],\n",
      "        [ 0.1557, -2.2412,  0.1741,  ...,  5.3235,  0.7861,  5.3360]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.6032,  0.7944,  1.6013,  ...,  0.1745, -0.5865,  0.1559],\n",
      "        [ 0.7944,  6.8673,  0.7940,  ..., -2.4641,  0.1559, -2.3555],\n",
      "        [ 1.6013,  0.7940,  1.6032,  ...,  0.1932, -0.5609,  0.1745],\n",
      "        ...,\n",
      "        [ 0.1745, -2.4641,  0.1932,  ...,  6.8673,  0.7940,  6.8467],\n",
      "        [-0.5865,  0.1559, -0.5609,  ...,  0.7940,  1.6032,  0.7944],\n",
      "        [ 0.1559, -2.3555,  0.1745,  ...,  6.8467,  0.7944,  6.8673]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.5019,  0.8339,  1.4996,  ...,  0.1736, -0.6440,  0.1540],\n",
      "        [ 0.8339,  7.2697,  0.8335,  ..., -2.4038,  0.1540, -2.2791],\n",
      "        [ 1.4996,  0.8335,  1.5019,  ...,  0.1934, -0.6315,  0.1736],\n",
      "        ...,\n",
      "        [ 0.1736, -2.4038,  0.1934,  ...,  7.2697,  0.8335,  7.2462],\n",
      "        [-0.6440,  0.1540, -0.6315,  ...,  0.8335,  1.5019,  0.8339],\n",
      "        [ 0.1540, -2.2791,  0.1736,  ...,  7.2462,  0.8339,  7.2697]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.5463e+02,  0.0000e+00],\n",
      "        [ 1.4591e+02,  0.0000e+00],\n",
      "        [ 4.3144e+01,  0.0000e+00],\n",
      "        [ 2.5530e+01,  0.0000e+00],\n",
      "        [ 1.5976e+01,  0.0000e+00],\n",
      "        [ 6.0042e+00,  0.0000e+00],\n",
      "        [ 2.3647e+00,  0.0000e+00],\n",
      "        [ 4.4148e-01,  0.0000e+00],\n",
      "        [ 2.4170e-01,  0.0000e+00],\n",
      "        [ 4.4162e-02,  0.0000e+00],\n",
      "        [-1.5408e-02,  0.0000e+00],\n",
      "        [ 6.6889e-03,  0.0000e+00],\n",
      "        [ 1.4094e-03,  0.0000e+00],\n",
      "        [ 1.3100e-04,  0.0000e+00],\n",
      "        [ 9.2492e-05,  0.0000e+00],\n",
      "        [ 9.4891e-06,  0.0000e+00],\n",
      "        [-7.8274e-06,  0.0000e+00],\n",
      "        [-5.8646e-06,  0.0000e+00],\n",
      "        [-4.5291e-06,  2.7185e-06],\n",
      "        [-4.5291e-06, -2.7185e-06],\n",
      "        [ 5.4553e-06,  0.0000e+00],\n",
      "        [ 2.6405e-06,  4.1500e-06],\n",
      "        [ 2.6405e-06, -4.1500e-06],\n",
      "        [-3.4552e-06,  2.9348e-06],\n",
      "        [-3.4552e-06, -2.9348e-06],\n",
      "        [-4.6942e-06,  2.3078e-07],\n",
      "        [-4.6942e-06, -2.3078e-07],\n",
      "        [ 3.9392e-06,  1.4524e-06],\n",
      "        [ 3.9392e-06, -1.4524e-06],\n",
      "        [-1.9706e-07,  3.8808e-06],\n",
      "        [-1.9706e-07, -3.8808e-06],\n",
      "        [ 3.9911e-06,  0.0000e+00],\n",
      "        [-3.6301e-06,  9.6423e-07],\n",
      "        [-3.6301e-06, -9.6423e-07],\n",
      "        [ 3.0885e-06,  1.0107e-06],\n",
      "        [ 3.0885e-06, -1.0107e-06],\n",
      "        [-2.6806e-06,  1.3031e-06],\n",
      "        [-2.6806e-06, -1.3031e-06],\n",
      "        [ 1.6193e-06,  2.3917e-06],\n",
      "        [ 1.6193e-06, -2.3917e-06],\n",
      "        [ 2.9039e-06,  0.0000e+00],\n",
      "        [ 1.9743e-06,  2.1306e-06],\n",
      "        [ 1.9743e-06, -2.1306e-06],\n",
      "        [-3.1647e-06,  0.0000e+00],\n",
      "        [-2.7404e-06,  0.0000e+00],\n",
      "        [ 5.9288e-07,  2.3829e-06],\n",
      "        [ 5.9288e-07, -2.3829e-06],\n",
      "        [-2.2317e-06,  0.0000e+00],\n",
      "        [-1.1136e-06,  1.9206e-06],\n",
      "        [-1.1136e-06, -1.9206e-06],\n",
      "        [ 2.1507e-06,  9.3618e-07],\n",
      "        [ 2.1507e-06, -9.3618e-07],\n",
      "        [-7.5567e-07,  1.8049e-06],\n",
      "        [-7.5567e-07, -1.8049e-06],\n",
      "        [ 1.8972e-06,  7.9723e-07],\n",
      "        [ 1.8972e-06, -7.9723e-07],\n",
      "        [ 8.6662e-07,  1.4448e-06],\n",
      "        [ 8.6662e-07, -1.4448e-06],\n",
      "        [-1.4091e-06,  6.8888e-07],\n",
      "        [-1.4091e-06, -6.8888e-07],\n",
      "        [ 6.8964e-08,  1.5032e-06],\n",
      "        [ 6.8964e-08, -1.5032e-06],\n",
      "        [ 1.5357e-06,  0.0000e+00],\n",
      "        [-1.3073e-06,  0.0000e+00],\n",
      "        [-3.5776e-07,  9.3592e-07],\n",
      "        [-3.5776e-07, -9.3592e-07],\n",
      "        [ 2.2974e-07,  1.0161e-06],\n",
      "        [ 2.2974e-07, -1.0161e-06],\n",
      "        [ 1.1196e-06,  3.8387e-07],\n",
      "        [ 1.1196e-06, -3.8387e-07],\n",
      "        [-9.9370e-07,  0.0000e+00],\n",
      "        [-9.9452e-08,  7.6558e-07],\n",
      "        [-9.9452e-08, -7.6558e-07],\n",
      "        [ 9.4046e-07,  0.0000e+00],\n",
      "        [-7.1786e-07,  2.9329e-07],\n",
      "        [-7.1786e-07, -2.9329e-07],\n",
      "        [-3.8580e-07,  5.1509e-07],\n",
      "        [-3.8580e-07, -5.1509e-07],\n",
      "        [ 5.7245e-07,  3.3570e-07],\n",
      "        [ 5.7245e-07, -3.3570e-07],\n",
      "        [ 3.5303e-07,  5.0829e-07],\n",
      "        [ 3.5303e-07, -5.0829e-07],\n",
      "        [ 1.7866e-07,  5.2846e-07],\n",
      "        [ 1.7866e-07, -5.2846e-07],\n",
      "        [ 6.4276e-07,  9.5464e-08],\n",
      "        [ 6.4276e-07, -9.5464e-08],\n",
      "        [-7.0574e-07,  0.0000e+00],\n",
      "        [-6.0209e-07,  2.0381e-07],\n",
      "        [-6.0209e-07, -2.0381e-07],\n",
      "        [-5.4873e-07,  0.0000e+00],\n",
      "        [-3.3439e-07,  2.2803e-07],\n",
      "        [-3.3439e-07, -2.2803e-07],\n",
      "        [ 1.5818e-08,  3.1133e-07],\n",
      "        [ 1.5818e-08, -3.1133e-07],\n",
      "        [-3.7616e-07,  0.0000e+00],\n",
      "        [ 3.8692e-07,  0.0000e+00],\n",
      "        [ 2.9624e-07,  2.4828e-07],\n",
      "        [ 2.9624e-07, -2.4828e-07],\n",
      "        [-4.1684e-08,  4.9950e-08],\n",
      "        [-4.1684e-08, -4.9950e-08]], grad_fn=<EigBackward>)\n",
      "tensor([[ 1.2930,  0.9109,  1.2904,  ...,  0.1672, -0.5734,  0.1454],\n",
      "        [ 0.9109,  6.5925,  0.9105,  ..., -2.3518,  0.1454, -2.2468],\n",
      "        [ 1.2904,  0.9105,  1.2930,  ...,  0.1891, -0.5763,  0.1672],\n",
      "        ...,\n",
      "        [ 0.1672, -2.3518,  0.1891,  ...,  6.5925,  0.9105,  6.5725],\n",
      "        [-0.5734,  0.1454, -0.5763,  ...,  0.9105,  1.2930,  0.9109],\n",
      "        [ 0.1454, -2.2468,  0.1672,  ...,  6.5725,  0.9109,  6.5925]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 1.4263e+02,  0.0000e+00],\n",
      "        [ 1.1949e+02,  0.0000e+00],\n",
      "        [ 3.0639e+01,  0.0000e+00],\n",
      "        [ 1.9893e+01,  0.0000e+00],\n",
      "        [ 8.5468e+00,  0.0000e+00],\n",
      "        [-3.7086e+00,  0.0000e+00],\n",
      "        [ 3.6097e+00,  0.0000e+00],\n",
      "        [ 6.7354e-01,  0.0000e+00],\n",
      "        [ 5.0246e-01,  0.0000e+00],\n",
      "        [ 9.0506e-02,  0.0000e+00],\n",
      "        [ 1.9797e-02,  0.0000e+00],\n",
      "        [ 3.9570e-03,  0.0000e+00],\n",
      "        [ 1.3042e-03,  0.0000e+00],\n",
      "        [ 2.9498e-04,  0.0000e+00],\n",
      "        [ 4.3500e-05,  0.0000e+00],\n",
      "        [ 8.6791e-06,  0.0000e+00],\n",
      "        [ 4.4991e-06,  3.9618e-06],\n",
      "        [ 4.4991e-06, -3.9618e-06],\n",
      "        [ 1.9738e-07,  4.8755e-06],\n",
      "        [ 1.9738e-07, -4.8755e-06],\n",
      "        [-4.6790e-06,  2.1772e-06],\n",
      "        [-4.6790e-06, -2.1772e-06],\n",
      "        [-4.9911e-06,  0.0000e+00],\n",
      "        [-1.4577e-06,  4.2317e-06],\n",
      "        [-1.4577e-06, -4.2317e-06],\n",
      "        [ 4.3133e-06,  8.7047e-07],\n",
      "        [ 4.3133e-06, -8.7047e-07],\n",
      "        [ 3.9189e-06,  0.0000e+00],\n",
      "        [-3.0084e-06,  2.2323e-06],\n",
      "        [-3.0084e-06, -2.2323e-06],\n",
      "        [ 2.1337e-06,  2.9311e-06],\n",
      "        [ 2.1337e-06, -2.9311e-06],\n",
      "        [ 3.3478e-06,  8.3733e-07],\n",
      "        [ 3.3478e-06, -8.3733e-07],\n",
      "        [ 1.7246e-06,  2.1422e-06],\n",
      "        [ 1.7246e-06, -2.1422e-06],\n",
      "        [-2.5866e-06,  7.6292e-07],\n",
      "        [-2.5866e-06, -7.6292e-07],\n",
      "        [-2.6055e-06,  0.0000e+00],\n",
      "        [ 2.7536e-06,  7.3593e-07],\n",
      "        [ 2.7536e-06, -7.3593e-07],\n",
      "        [-2.1066e-07,  2.4367e-06],\n",
      "        [-2.1066e-07, -2.4367e-06],\n",
      "        [ 6.5654e-08,  2.3650e-06],\n",
      "        [ 6.5654e-08, -2.3650e-06],\n",
      "        [-2.2009e-06,  4.0903e-07],\n",
      "        [-2.2009e-06, -4.0903e-07],\n",
      "        [-9.1771e-07,  1.9629e-06],\n",
      "        [-9.1771e-07, -1.9629e-06],\n",
      "        [ 2.1054e-06,  0.0000e+00],\n",
      "        [ 2.1133e-06,  3.0946e-07],\n",
      "        [ 2.1133e-06, -3.0946e-07],\n",
      "        [ 1.9637e-06,  6.5352e-07],\n",
      "        [ 1.9637e-06, -6.5352e-07],\n",
      "        [-1.2546e-06,  1.2032e-06],\n",
      "        [-1.2546e-06, -1.2032e-06],\n",
      "        [-1.4298e-06,  7.5680e-07],\n",
      "        [-1.4298e-06, -7.5680e-07],\n",
      "        [ 6.9902e-07,  1.2850e-06],\n",
      "        [ 6.9902e-07, -1.2850e-06],\n",
      "        [ 1.2718e-06,  4.6613e-07],\n",
      "        [ 1.2718e-06, -4.6613e-07],\n",
      "        [ 1.1654e-06,  2.8933e-07],\n",
      "        [ 1.1654e-06, -2.8933e-07],\n",
      "        [-5.4767e-07,  8.6888e-07],\n",
      "        [-5.4767e-07, -8.6888e-07],\n",
      "        [-9.8637e-07,  2.4987e-07],\n",
      "        [-9.8637e-07, -2.4987e-07],\n",
      "        [-2.5804e-07,  9.1396e-07],\n",
      "        [-2.5804e-07, -9.1396e-07],\n",
      "        [ 2.4747e-07,  8.7625e-07],\n",
      "        [ 2.4747e-07, -8.7625e-07],\n",
      "        [ 5.5902e-07,  5.6141e-07],\n",
      "        [ 5.5902e-07, -5.6141e-07],\n",
      "        [-6.8543e-07,  1.1389e-07],\n",
      "        [-6.8543e-07, -1.1389e-07],\n",
      "        [-5.3087e-07,  3.2984e-07],\n",
      "        [-5.3087e-07, -3.2984e-07],\n",
      "        [ 1.4595e-09,  5.4266e-07],\n",
      "        [ 1.4595e-09, -5.4266e-07],\n",
      "        [-1.8262e-07,  4.3779e-07],\n",
      "        [-1.8262e-07, -4.3779e-07],\n",
      "        [ 5.1443e-07,  1.9827e-07],\n",
      "        [ 5.1443e-07, -1.9827e-07],\n",
      "        [ 4.7442e-07,  2.5277e-07],\n",
      "        [ 4.7442e-07, -2.5277e-07],\n",
      "        [ 2.6701e-07,  3.9569e-07],\n",
      "        [ 2.6701e-07, -3.9569e-07],\n",
      "        [-4.5194e-07,  0.0000e+00],\n",
      "        [-2.2413e-07,  2.0713e-07],\n",
      "        [-2.2413e-07, -2.0713e-07],\n",
      "        [ 3.3049e-07,  0.0000e+00],\n",
      "        [ 5.9030e-08,  2.5403e-07],\n",
      "        [ 5.9030e-08, -2.5403e-07],\n",
      "        [-1.0998e-07,  1.5832e-07],\n",
      "        [-1.0998e-07, -1.5832e-07],\n",
      "        [-1.0085e-07,  0.0000e+00],\n",
      "        [ 8.9803e-08,  7.1903e-08],\n",
      "        [ 8.9803e-08, -7.1903e-08],\n",
      "        [ 1.9879e-07,  0.0000e+00]], grad_fn=<EigBackward>)\n",
      "tensor([[ 0.9442,  1.0479,  0.9416,  ...,  0.1398, -0.3512,  0.1142],\n",
      "        [ 1.0479,  5.5037,  1.0473,  ..., -2.2117,  0.1142, -2.1440],\n",
      "        [ 0.9416,  1.0473,  0.9442,  ...,  0.1657, -0.3643,  0.1398],\n",
      "        ...,\n",
      "        [ 0.1398, -2.2117,  0.1657,  ...,  5.5037,  1.0473,  5.4891],\n",
      "        [-0.3512,  0.1142, -0.3643,  ...,  1.0473,  0.9442,  1.0479],\n",
      "        [ 0.1142, -2.1440,  0.1398,  ...,  5.4891,  1.0479,  5.5037]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "ename": "NotPSDError",
     "evalue": "Matrix not positive definite after repeatedly adding jitter up to 1.0e-04. Original error on first attempt: cholesky_cpu: U(77,77) is zero, singular U.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cholesky_cpu: U(77,77) is zero, singular U.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotPSDError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-83c011692335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Calc loss and backprop gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/distributions/multitask_multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1238\u001b[0m                     \u001b[0mwill_need_cholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwill_need_cholesky\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                 \u001b[0mcholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCholLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTriangularLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mLazyTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mCholesky\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtriangular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlower\u001b[0m \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m\"upper\"\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \"\"\"\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transpose_nonbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# contiguous call is necessary here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mcholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTriangularLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36mpsd_safe_cholesky\u001b[0;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mwith\u001b[0m \u001b[0msuccessively\u001b[0m \u001b[0mincreasing\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmake\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mraising\u001b[0m \u001b[0man\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_psd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             raise NotPSDError(\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;34mf\"Matrix not positive definite after repeatedly adding jitter up to {jitter_new:.1e}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;34mf\"Original error on first attempt: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotPSDError\u001b[0m: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04. Original error on first attempt: cholesky_cpu: U(77,77) is zero, singular U."
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(20)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    for parameter in model.named_parameters():\n",
    "        print(parameter)\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75730997",
   "metadata": {},
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.9034, -0.9089], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.9070], requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.0.var', Parameter containing:\n",
      "tensor(0.1058, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.0.length', Parameter containing:\n",
      "tensor(0.4735, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.1.var', Parameter containing:\n",
      "tensor(0.1058, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.1.length', Parameter containing:\n",
      "tensor(0.4735, requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.0.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.0.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.1.var', Parameter containing:\n",
      "tensor(1.2556, requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.1.length', Parameter containing:\n",
      "tensor(1.0946, requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.0.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.0.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.1.var', Parameter containing:\n",
      "tensor(1.3007, requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.1.length', Parameter containing:\n",
      "tensor(0.4861, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(50)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(0), float(2), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(3)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-3, 8])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-3, 8])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b432934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, -3*e^(-2)], [0, 1, 0], [-3*e^(-2), 0, 1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = SE.diff(x2).diff(x1)(int(v1), int(v2), lengthscale, variance)\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1\n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc25ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, row, col):\n",
    "    len_M = M.number_of_arguments()\n",
    "    temp = None\n",
    "    for j in range(int(sqrt(len_M))):\n",
    "        if temp == None:\n",
    "            import itertools\n",
    "            #M_tr = list(map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "            #[M_tr[j].diff(left_poly=L[row][k], right_poly=R.transpose()[col][j]) for k in range(L.number_of_arguments())]\n",
    "            temp = L[row]*M.transpose()[j]*R.transpose()[col][j]\n",
    "        else:\n",
    "            temp += L[row]*M.transpose()[j]*R.transpose()[col][j]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(self, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(self.matrix)[1])] for j in range(np.shape(self.matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = self.calc_cell_diff(l, self.matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(self.matrix)[0])][\n",
    "                    int(i % np.shape(self.matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-sigma^2*(x1 - x2)*e^(-1/2*(x1 - x2)^2/l^2)/l^2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), 0], [0, sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "SEKernelMatrix[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Diff_SE_kernel()\n",
    "kernel3 = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "\n",
    "l = [[kernel, kernel3], [kernel3, kernel2]]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
