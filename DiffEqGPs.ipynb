{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06280d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Nochmal durchlaufen lassen\n",
    "def get_prepared_SNF(input_matrix, left_var=var('dx1'), right_var=var('dx2')):\n",
    "    d, u, v = input_matrix.smith_form()\n",
    "    (r, c) = np.shape(d)\n",
    "    if r > c:\n",
    "        assert \"More rows than columns in diagonal matrix D\"\n",
    "    if not d == u*input_matrix*v:\n",
    "        assert \"The calculation of the Smith form failed or is not possible\"\n",
    "    V_left_transpose = matrix([[e.substitute(left_var) for e in row] for row in v.transpose()])\n",
    "    V_right = matrix([[e.substitute(right_var) for e in row] for row in v])\n",
    "    row = [None] * c\n",
    "    pre_diff_kernel_matrix = []\n",
    "    for i in range(c):\n",
    "        temp = copy(row)\n",
    "        if i < r and d[i][i] == 0 or i >= r:\n",
    "            temp[i] = Diff_SE_kernel(var=0, length=0)\n",
    "        pre_diff_kernel_matrix.append(temp)\n",
    "    return pre_diff_kernel_matrix, V_left_transpose, V_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336fecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-2-996a60d0925e>\u001b[0m(5)\u001b[0;36mget_prepared_SNF\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmith_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "[      x^2 - x        -x + 1 x^2 - 2*x + 1]\n",
      "[    x^2 - 2*x             x         x - 1]\n",
      "[[None, None, None], [None, None, None], [None, None, Diff_SE_kernel()]]\n",
      "[            2             1             0]\n",
      "[          3/2  -1/2*dx1 + 2            -1]\n",
      "[     -dx1 - 1 dx1^2 - 3*dx1         2*dx1]\n",
      "[            2           3/2      -dx2 - 1]\n",
      "[            1  -1/2*dx2 + 2 dx2^2 - 3*dx2]\n",
      "[            0            -1         2*dx2]\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\n",
       "[            1             0             0]\n",
       "[            0 x^2 - 2*x + 1             0],\n",
       "\n",
       "                                   [         2        3/2     -x - 1]\n",
       "[              1              -1]  [         1 -1/2*x + 2  x^2 - 3*x]\n",
       "[   -2*x^2 + 3*x 2*x^2 - 3*x + 1], [         0         -1        2*x]\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "R.<x> = QQ[]\n",
    "m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "\n",
    "\n",
    "dx1 = var('dx1')\n",
    "dx2 = var('dx2')\n",
    "#L = [[2, 1, 0], [3/2, -1/2*dx1 + 2, -1], [-dx1 - 1, dx1^2 - 3*dx1, 2*dx1]]\n",
    "#R = [[2, 3/2, -dx2 - 1], [1, -1/2*dx2 + 2, dx2^2 - 3*dx2], [0, -1, 2*dx2]]\n",
    "#L = matrix(L)\n",
    "#R = matrix(R)\n",
    "\n",
    "T, L, R = get_prepared_SNF(m, dx1, dx2)\n",
    "print(m)\n",
    "print(T)\n",
    "print(L)\n",
    "print(R)\n",
    "print(\"---\")\n",
    "m.smith_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3d2f8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'R'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0d1d5c9fbdda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiff_SE_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpre_diff_kernel_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'R'"
     ]
    }
   ],
   "source": [
    "c = 3\n",
    "row = [None] * c\n",
    "for i in range(c):\n",
    "    temp = copy(row)\n",
    "    if i < r and d[i][i] == 0:\n",
    "        temp[i] = Diff_SE_kernel(var=0, length=0)\n",
    "    pre_diff_kernel_matrix.append(temp)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d750964e",
   "metadata": {},
   "source": [
    "R.<x> = QQ[]\n",
    "m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "#dx1 = var('dx1')\n",
    "#m[0, 0].substitute(dx1)\n",
    "get_prepared_SNF(m)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d56d1013",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def test_get_prepared_SNF():\n",
    "    m = matrix(2,2,(1,0,1,0))\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [1][1]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0.],[0., 1.]], \"Test 1 failed\"\n",
    "    \n",
    "    R.<x> = QQ[]\n",
    "    m=x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [2][2]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0., 0.],[0., 0., 0.],[0., 0., 1.]], \"Test 2 failed\"\n",
    "    \n",
    "test_get_cov_fkt_from_SNF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(-2), float(2), int(75))\n",
    "# The original sin/cos data\n",
    "#one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(3)*torch.pow(train_x, int(2)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(6)*train_x + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(5)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(60)*torch.pow(train_x, int(2)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "one = torch.exp(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = torch.exp(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "three = torch.exp(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "\n",
    "# Combined poly + sin/cos\n",
    "#one = torch.mul(torch.sin(train_x), train_x)+ torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.mul(torch.cos(train_x), train_x) + torch.sin(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# only sin/cos\n",
    "#one = torch.mul(torch.sin(train_x), torch.cos(train_x)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.mul(torch.cos(train_x), torch.cos(train_x)) - torch.mul(torch.sin(train_x), torch.sin(train_x)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "train_y = torch.stack([one, two, three], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385213ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x)\n",
    "print(train_y)\n",
    "print(np.shape(train_y))\n",
    "\n",
    "# = torch.Tensor([[float(-0.3), float(0.99)],[float(-0.07), float(1.01)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5884c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(train_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37706537",
   "metadata": {},
   "source": [
    "In Reihenfolge:\n",
    "- Mal ohne Ableitung durchlaufen lassen\n",
    "- Mal mit 1-en auf der Diagonale\n",
    "- Mal mit der Ableitungsdiagonale drehen\n",
    "- Gradienten ausgeben lassen\n",
    "- Mal den Datenvektor mit L multiplizieren und als neuen \"Ersteller\" für die Daten nehmen\n",
    "- Lasse L und R nicht quadratisch sein\n",
    "- Einfach -> L (2x3)\n",
    "- Schwer -> L (3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361022cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec0044",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & dx_1 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "R =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 0\\\\\n",
    "dx_2 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "\\hat{k} =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "SE_1 & 0\\\\\n",
    "0 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "k =& L*\\hat{k}*R\\\\\n",
    "=& \\left[\n",
    "\\begin{matrix}\n",
    "dx_1 dx_2 SE_2 + SE_1 & dx_1 SE_2\\\\\n",
    "dx_2 SE_2 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx1, dx2, k1, k2, f, g = var('dx1, dx2, k1, k2, f, g')\n",
    "K = matrix(2,2, (k1, 0, 0, 0))\n",
    "L = matrix(2, 2, (1, 0, dx1^2, 1))\n",
    "R = matrix(2, 2, (1, dx2^2, 0, 1))\n",
    "L*K*R\n",
    "# used to see how the data should be created if I \n",
    "# decide to create it exactly as I create the kernel\n",
    "#K = matrix(2,1, (f, g))\n",
    "#L*L*K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b285d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=3\n",
    "        )\n",
    "        kernel = Diff_SE_kernel(var=0, length=0)\n",
    "        kernel2 = Diff_SE_kernel(var=0, length=0)\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        R.<x> = QQ[]\n",
    "        m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "        T, L, R = get_prepared_SNF(m, dx1, dx2)\n",
    "        print(T)\n",
    "#        L = matrix(2, 2, (1/2, 0, dx1^3, 1))\n",
    "#        R = matrix(2, 2, (1, dx2^3, 0, 1))\n",
    "        p = DiffMatrixKernel([[kernel, None, None], [None, None, None], [None, None, None]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        \n",
    "        #kernel0 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel1 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel2 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel0 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel1 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel0 = Diff_SE_kernel(var = 0, length=0)\n",
    "        #kernel1 = Diff_SE_kernel(var = 0, length=0.01)\n",
    "        #kernel2 = Diff_SE_kernel(var = 0, length=0.02)\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel1]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=3)\n",
    "#likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2, has_global_noise=False, has_task_noise=False)\n",
    "likelihood._set_task_noises(torch.Tensor([float(0.0001), float(0.0001), float(0.0001)]))\n",
    "#likelihood._set_noise(torch.tensor(float(0.0001)))\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f583d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(150)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(-4), float(7), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax, y3_ax) = plt.subplots(int(1), int(3), figsize=(int(15), int(4)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "#y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-30, 30])\n",
    "y1_ax.legend(['Mean', 'Confidence'])\n",
    "y1_ax.set_title('Prior')\n",
    "\n",
    "# Plot training data as black stars\n",
    "#y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-30, 30])\n",
    "y2_ax.legend(['Mean', 'Confidence'])\n",
    "y2_ax.set_title('Prior')\n",
    "\n",
    "# Plot training data as black stars\n",
    "#y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y3_ax.plot(test_x.numpy(), mean[:, 2].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y3_ax.fill_between(test_x.numpy(), lower[:, 2].numpy(), upper[:, 2].numpy(), alpha=0.5)\n",
    "y3_ax.set_ylim([-30, 30])\n",
    "y3_ax.legend(['Mean', 'Confidence'])\n",
    "y3_ax.set_title('Prior')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(75)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "param_dict = {p[0]:[] for p in model.named_parameters() if 'covar' in p[0]}\n",
    "param_dict['loss'] = []\n",
    "param_dict['noise'] = []\n",
    "if len(likelihood.task_noises) > 1:\n",
    "    param_dict['task_noises'] = [[] for i in range(len(likelihood.task_noises))]\n",
    "for p in model.named_parameters():\n",
    "    if 'covar' in p[0]:\n",
    "        param_dict[f\"{p[0]}_grad\"] = []\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    param_dict['loss'].append(loss.item())\n",
    "    #pdb.set_trace()\n",
    "    loss.backward()\n",
    "    for parameter in model.named_parameters():\n",
    "        if 'covar' in parameter[0]:\n",
    "            param_dict[parameter[0]].append(parameter[1].item())\n",
    "            #param_dict[f\"{parameter[0]}_grad\"].append(parameter[1].grad.item())\n",
    "    param_dict['noise'].append(likelihood.noise.item())\n",
    "    for l in range(len(likelihood.task_noises)):\n",
    "        param_dict['task_noises'][l].append(likelihood.task_noises[l].item())\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.covar_module)\n",
    "#for covar_fkt in model.covar_module.matrix:\n",
    "#    print(covar_fkt)\n",
    "\n",
    "# -sigma^2*e^(-1/2*(x1 - x2)^2/l^2)/l^2 + sigma^2*(x1 - x2)^2*e^(-1/2*(x1 - x2)^2/l^2)/l^4\n",
    "#[[-1.0, 0.0], \n",
    "# [0.0, -1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeffs(given_n):\n",
    "    # See http://oeis.org/A096713\n",
    "    real_n = int(given_n/2)\n",
    "    m, k = var('m, k')\n",
    "    # even\n",
    "    # T(2*m, k) = (-1)^(m+k)*(2*m)!*2^(k-m)/((m-k)!*(2*k)!), k = 0..m.\n",
    "    if given_n % 2 == 0:\n",
    "        # This notation is only valid in iPython\n",
    "        #T(m,k) = factorial(2*m)*2^(k-m)/(factorial(m-k)*factorial(2*k))\n",
    "        # As an actual Python file I need to use:\n",
    "        T = lambda m, k : (-1)**(m+k)*factorial(2*m)*2**(k-m)/(factorial(m-k)*factorial(2*k))\n",
    "    # odd\n",
    "    # T(2*m+1, k) = (-1)^(m+k)*(2*m+1)!*2^(k-m)/((m-k)!*(2*k+1)!), k = 0..m. (End)\n",
    "    else:\n",
    "        # See above\n",
    "        #T(m,k) = factorial(2*m+1)*2^(k-m)/(factorial(m-k)*factorial(2*k+1))\n",
    "        T = lambda m, k: (-1)**(m+k)*factorial(2*m+1)*2**(k-m)/(factorial(m-k)*factorial(2*k+1))\n",
    "    return [int(T(real_n, k)) for k in range(real_n+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(coeffs(i))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c663e6b9",
   "metadata": {},
   "source": [
    "def dynamic_sage_diff(dx1_num, dx2_num):\n",
    "    SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "    for i in range(dx1_num):\n",
    "        SE = SE.diff(x1)\n",
    "    for j in range(dx2_num):\n",
    "        SE = SE.diff(x2)\n",
    "    return SE\n",
    "\n",
    "for j in range(6):\n",
    "    for i in range(6):\n",
    "        print(f\"dx1: {i}; dx2:{j}\")\n",
    "        print(ascii_art(dynamic_sage_diff(i, j)))\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood\n",
    "#torch.autograd.functional.hessian(likelihood, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0219bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_key in param_dict:\n",
    "    if param_key == 'task_noises':\n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(param_dict[param_key], label=param_key)\n",
    "    \n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d928e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likelihood.noise)\n",
    "print(likelihood.task_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b924f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = matrix(QQ, 4, 4, (2,0,0.6065,0.6065,0,1,-0.6065,0.6065,0.6065,-0.6065,2,0,0.6065,0.6065,0,1))\n",
    "L = A.cholesky()\n",
    "L*L.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(150)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(-4), float(7), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax, y3_ax) = plt.subplots(int(1), int(3), figsize=(int(15), int(4)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-30, 30])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-30, 30])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y3_ax.plot(train_x.detach().numpy(), train_y[:, 2].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y3_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y3_ax.fill_between(test_x.numpy(), lower[:, 2].numpy(), upper[:, 2].numpy(), alpha=0.5)\n",
    "y3_ax.set_ylim([-30, 30])\n",
    "y3_ax.legend(['Mean', 'Confidence'])\n",
    "y3_ax.set_title('Prior')\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = matrix(1, 2, (1, 2))\n",
    "b = matrix(2, 2, (1, 2, 3, 4))\n",
    "a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(float(0), float(1), int(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = float(SE.diff(x2).diff(x2)(int(v1), int(v2), lengthscale, variance))\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29571cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "#print(SE)\n",
    "#print(SE.diff(x1).diff(x2))\n",
    "print(SE.diff(x2).diff(x2))\n",
    "#print(SE.diff(x1).diff(x2).diff(x1).diff(x2).diff(x1))\n",
    "#print(SE.diff(x1).diff(x2).diff(x1).diff(x2))\n",
    "#float(SE.diff(x2).diff(x1)(float(1.), float(1.), 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1^3 \n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "left_poly = dx2\n",
    "right_poly = 1\n",
    "diffed_kernel2 = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate() + diffed_kernel2(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff_sage(L, M, R, context=None):\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "        map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    # Every row in 'M' is combined with each elem of the row given in 'R'\n",
    "    # Or: For each elemtn in row 'R' combine with 'row_M'\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        # Each element in L gets exactly one element in 'row_M' to multiply\n",
    "        # Or: Combine each element in row_M with exactly one element in 'L'\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp = m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp = m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp = m_elem.diff(l_elem)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp += m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp += m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp += m_elem.diff(l_elem)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "    return temp\n",
    "\n",
    "def diff_sage(matrix, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(matrix)[1])] for j in range(np.shape(matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = calc_cell_diff_sage(l, matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(matrix)[0])][\n",
    "                    int(i % np.shape(matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "L = matrix(2, 2, (x1, x1, 0, x1))\n",
    "R = matrix(2, 2, (x2, 0, x2, x2))\n",
    "x1, x2, l, sigma, l2, sigma2 = var('x1, x2, l, sigma, l2, sigma2')\n",
    "lengthscale = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance = 1\n",
    "lengthscale2 = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance2 = 1\n",
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), sigma2^2*exp(-(x1-x2)^2/(2*l2^2))], [sigma2^2*exp(-(x1-x2)^2/(2*l2^2)), sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "#diffed_SE_sage_matrix_kernel = diff_sage(SEKernelMatrix, left_matrix=L, right_matrix=R)\n",
    "#pprint.pprint(diffed_SE_sage_matrix_kernel)\n",
    "cov_matr = [[None for i in range(len(X)*len(SEKernelMatrix))] for j in range(len(X)*len(SEKernelMatrix))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    for row in range(len(SEKernelMatrix)):\n",
    "        for col in range(len(SEKernelMatrix)):\n",
    "            # Blockwise\n",
    "            #cov_matr[int(i/len(X))+row*len(X)][int(i%len(X))+col*len(X)] = SEKernelMatrix[row][col].substitute(x1=int(v1), x2=int(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2)\n",
    "            # Interleaved\n",
    "            text=f\"x-pos: {int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row}\" +\\\n",
    "            f\" y-pos: {int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))}\" + \\\n",
    "            f\" x1, x2: {v1}, {v2}\\n\" +\\\n",
    "            f\"(x1-x2)^2: {(v1-v2)**2}\"+\\\n",
    "            f\" exp((x1-x2)^2): {np.exp((v1-v2)**2)}\\n\"+\\\n",
    "            f\"val: {float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))}\"\n",
    "            print(text)\n",
    "            print(\"---\")\n",
    "            cov_matr[int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row][int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))] = float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))\n",
    "cov_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd554171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(torch.Tensor(cov_matr).eig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7195921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780479da",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(-(-2-0.66)^2/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b359f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "\n",
    "covar_x = covar_module(X)\n",
    "covar_x.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = [[2, 0, -6*e^(-2), 1, e^(-1/2), -e^(-2)],\n",
    " [0, 2, 0, -e^(-1/2), 1, e^(-1/2)],\n",
    " [-6*e^(-2), 0, 2, -5*e^(-2), -e^(-1/2), 1],\n",
    " [1, e^(-1/2), -e^(-2), 1, 0, -3*e^(-2)],\n",
    " [-e^(-1/2), 1, e^(-1/2), 0, 1, 0],\n",
    " [-5*e^(-2), -e^(-1/2), 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = [[2, 0, -6*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 2, 0, 0, 1, 0],\n",
    " [-6*e^(-2), 0, 2, -3*e^(-2), 0, 1],\n",
    " [1, 0, -3*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 1, 0, 0, 1, 0],\n",
    " [-3*e^(-2), 0, 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = torch.Tensor(matr)\n",
    "import pprint\n",
    "pprint.pprint(matr)\n",
    "print(matr[0::3, 0::3])\n",
    "H_x = 3\n",
    "torch.vstack([torch.hstack([matr[k::H_x, l::H_x] for l in range(H_x)]) for k in range(H_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa5cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = var('a, b, c, d')\n",
    "A = matrix(2,2, (a, b, c, d))\n",
    "B = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "C = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "print(A)\n",
    "print(B)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d1b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, x, y, dx1 = var('a, b, c, d, x, y, dx1')\n",
    "poly = (a*(2*(c+b)+a)+a)*y\n",
    "#poly = a*b*dx1**3\n",
    "print(type(poly))\n",
    "#poly = 839840583*x^75\n",
    "print(poly.degree(dx1))\n",
    "print(poly.operands())\n",
    "print([op.is_numeric() for op in poly.operands()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ab94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_list = []\n",
    "l1 = [[42, 17], [128, 256]]\n",
    "for i, l in enumerate(l1):\n",
    "    if i == 0:\n",
    "        func1 = lambda : l[0]*l[1]\n",
    "        return_list.append(func1)\n",
    "    else: \n",
    "        func2 = lambda : l[0]*l[1]\n",
    "        return_list.append(func2)\n",
    "\n",
    "for func in return_list:\n",
    "    print(func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967647fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
