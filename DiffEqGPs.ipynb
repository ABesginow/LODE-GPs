{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "import random\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3fcb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_real_roots(expr, max_iterations=10000):\n",
    "    degr = expr.degree(var('x'))\n",
    "    zeros = []\n",
    "    iteration = 0\n",
    "    for root in expr.roots():\n",
    "        for i in range(root[1]):\n",
    "            zeros.append(root[0])\n",
    "    if not len(zeros) == degr:\n",
    "        while not len(zeros) == degr or iteration >= max_iterations:\n",
    "            iteration += 1\n",
    "            max_search = randrange(sys.maxsize)\n",
    "            min_search = min_search - int(sys.maxsize*0.1)\n",
    "            try:\n",
    "                root = find_root(expr, min_search, max_search)\n",
    "                zeros.append(root)\n",
    "            except:\n",
    "                continue\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06280d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Nochmal durchlaufen lassen\n",
    "def get_prepared_SNF(input_matrix, left_var=var('dx1'), right_var=var('dx2')):\n",
    "    d, u, v = input_matrix.smith_form()\n",
    "    (r, c) = np.shape(d)\n",
    "    if r > c:\n",
    "        assert \"More rows than columns in diagonal matrix D\"\n",
    "    if not d == u*input_matrix*v:\n",
    "        assert \"The calculation of the Smith form failed or is not possible\"\n",
    "    V_left_transpose = matrix([[e.substitute(left_var) for e in row] for row in v.transpose()])\n",
    "    V_right = matrix([[e.substitute(right_var) for e in row] for row in v])\n",
    "    row = [None] * c\n",
    "    pre_diff_kernel_matrix = []\n",
    "    for i in range(c):\n",
    "        temp = copy(row)\n",
    "        if i < r and d[i][i] == 0 or i >= r:\n",
    "            temp[i] = Diff_SE_kernel(var=0, length=0)\n",
    "        #elif i < r and not type(d[i][i]) in [sage.rings.integer.Integer, sage.rings.real_mpfr.RealLiteral]:\n",
    "        #    find_all_real_roots(d[i][i])\n",
    "        pre_diff_kernel_matrix.append(temp)\n",
    "    return pre_diff_kernel_matrix, V_left_transpose, V_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336fecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      x^2 - x        -x + 1 x^2 - 2*x + 1]\n",
      "[    x^2 - 2*x             x         x - 1]\n",
      "[[None, None, None], [None, None, None], [None, None, Diff_SE_kernel()]]\n",
      "[            2             1             0]\n",
      "[          3/2  -1/2*dx1 + 2            -1]\n",
      "[     -dx1 - 1 dx1^2 - 3*dx1         2*dx1]\n",
      "[            2           3/2      -dx2 - 1]\n",
      "[            1  -1/2*dx2 + 2 dx2^2 - 3*dx2]\n",
      "[            0            -1         2*dx2]\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "R.<x> = QQ[]\n",
    "m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "\n",
    "\n",
    "dx1 = var('dx1')\n",
    "dx2 = var('dx2')\n",
    "#L = [[2, 1, 0], [3/2, -1/2*dx1 + 2, -1], [-dx1 - 1, dx1^2 - 3*dx1, 2*dx1]]\n",
    "#R = [[2, 3/2, -dx2 - 1], [1, -1/2*dx2 + 2, dx2^2 - 3*dx2], [0, -1, 2*dx2]]\n",
    "#L = matrix(L)\n",
    "#R = matrix(R)\n",
    "\n",
    "T, L, R = get_prepared_SNF(m, dx1, dx2)\n",
    "print(m)\n",
    "\n",
    "print(T)\n",
    "print(L)\n",
    "print(R)\n",
    "print(\"---\")\n",
    "d, u, v = m.smith_form()\n",
    "d[1][1].roots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3d2f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (-1, 1)]\n"
     ]
    }
   ],
   "source": [
    "a = x^2 - 1\n",
    "print(a.roots())\n",
    "#find_root(a, -2, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfee9772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2837214305325298369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randrange(sys.maxsize)- int(sys.maxsize*0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d750964e",
   "metadata": {},
   "source": [
    "R.<x> = QQ[]\n",
    "m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "#dx1 = var('dx1')\n",
    "#m[0, 0].substitute(dx1)\n",
    "get_prepared_SNF(m)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d56d1013",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def test_get_prepared_SNF():\n",
    "    m = matrix(2,2,(1,0,1,0))\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [1][1]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0.],[0., 1.]], \"Test 1 failed\"\n",
    "    \n",
    "    R.<x> = QQ[]\n",
    "    m=x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [2][2]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0., 0.],[0., 0., 0.],[0., 0., 1.]], \"Test 2 failed\"\n",
    "    \n",
    "test_get_cov_fkt_from_SNF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(0), float(3), int(75))\n",
    "# The original sin/cos data\n",
    "#one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(3)*torch.pow(train_x, int(2)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(6)*train_x + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(5)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(60)*torch.pow(train_x, int(2)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.exp(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.exp(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "#three = torch.exp(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "\n",
    "noise = float(0)\n",
    "# ODE_GP_Example.mw\n",
    "one = torch.div(torch.cos(train_x) - torch.sin(train_x), int(2)) - torch.div(torch.exp(train_x), int(10)) + torch.randn(train_x.size()) * float(noise)\n",
    "two = torch.cos(train_x) + torch.randn(train_x.size()) * float(noise)\n",
    "three = torch.div(- torch.cos(train_x) - torch.sin(train_x), int(2)) - torch.div(torch.exp(train_x), int(10)) + torch.randn(train_x.size()) * float(noise)\n",
    "\n",
    "\n",
    "\n",
    "train_y = torch.stack([one, two, three], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385213ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0405, 0.0811, 0.1216, 0.1622, 0.2027, 0.2432, 0.2838, 0.3243,\n",
      "        0.3649, 0.4054, 0.4459, 0.4865, 0.5270, 0.5676, 0.6081, 0.6486, 0.6892,\n",
      "        0.7297, 0.7703, 0.8108, 0.8514, 0.8919, 0.9324, 0.9730, 1.0135, 1.0541,\n",
      "        1.0946, 1.1351, 1.1757, 1.2162, 1.2568, 1.2973, 1.3378, 1.3784, 1.4189,\n",
      "        1.4595, 1.5000, 1.5405, 1.5811, 1.6216, 1.6622, 1.7027, 1.7432, 1.7838,\n",
      "        1.8243, 1.8649, 1.9054, 1.9459, 1.9865, 2.0270, 2.0676, 2.1081, 2.1486,\n",
      "        2.1892, 2.2297, 2.2703, 2.3108, 2.3514, 2.3919, 2.4324, 2.4730, 2.5135,\n",
      "        2.5541, 2.5946, 2.6351, 2.6757, 2.7162, 2.7568, 2.7973, 2.8378, 2.8784,\n",
      "        2.9189, 2.9595, 3.0000])\n",
      "tensor([[ 0.4000,  1.0000, -0.6000],\n",
      "        [ 0.3752,  0.9992, -0.6240],\n",
      "        [ 0.3494,  0.9967, -0.6473],\n",
      "        [ 0.3227,  0.9926, -0.6699],\n",
      "        [ 0.2951,  0.9869, -0.6918],\n",
      "        [ 0.2666,  0.9795, -0.7129],\n",
      "        [ 0.2373,  0.9706, -0.7332],\n",
      "        [ 0.2072,  0.9600, -0.7528],\n",
      "        [ 0.1763,  0.9479, -0.7716],\n",
      "        [ 0.1446,  0.9342, -0.7895],\n",
      "        [ 0.1123,  0.9189, -0.8067],\n",
      "        [ 0.0792,  0.9022, -0.8230],\n",
      "        [ 0.0456,  0.8840, -0.8384],\n",
      "        [ 0.0113,  0.8643, -0.8530],\n",
      "        [-0.0236,  0.8432, -0.8668],\n",
      "        [-0.0590,  0.8207, -0.8797],\n",
      "        [-0.0949,  0.7969, -0.8918],\n",
      "        [-0.1313,  0.7718, -0.9030],\n",
      "        [-0.1681,  0.7454, -0.9135],\n",
      "        [-0.2053,  0.7177, -0.9231],\n",
      "        [-0.2429,  0.6889, -0.9319],\n",
      "        [-0.2809,  0.6590, -0.9399],\n",
      "        [-0.3191,  0.6279, -0.9471],\n",
      "        [-0.3577,  0.5959, -0.9535],\n",
      "        [-0.3964,  0.5628, -0.9593],\n",
      "        [-0.4354,  0.5289, -0.9643],\n",
      "        [-0.4746,  0.4941, -0.9687],\n",
      "        [-0.5140,  0.4584, -0.9724],\n",
      "        [-0.5534,  0.4220, -0.9755],\n",
      "        [-0.5930,  0.3849, -0.9780],\n",
      "        [-0.6327,  0.3472, -0.9799],\n",
      "        [-0.6725,  0.3089, -0.9814],\n",
      "        [-0.7123,  0.2701, -0.9824],\n",
      "        [-0.7521,  0.2309, -0.9830],\n",
      "        [-0.7920,  0.1912, -0.9832],\n",
      "        [-0.8319,  0.1513, -0.9832],\n",
      "        [-0.8717,  0.1111, -0.9828],\n",
      "        [-0.9115,  0.0707, -0.9823],\n",
      "        [-0.9514,  0.0303, -0.9816],\n",
      "        [-0.9911, -0.0103, -0.9809],\n",
      "        [-1.0309, -0.0508, -0.9801],\n",
      "        [-1.0706, -0.0912, -0.9794],\n",
      "        [-1.1103, -0.1315, -0.9788],\n",
      "        [-1.1500, -0.1716, -0.9784],\n",
      "        [-1.1896, -0.2114, -0.9782],\n",
      "        [-1.2293, -0.2508, -0.9785],\n",
      "        [-1.2690, -0.2898, -0.9791],\n",
      "        [-1.3087, -0.3284, -0.9803],\n",
      "        [-1.3485, -0.3664, -0.9820],\n",
      "        [-1.3883, -0.4038, -0.9845],\n",
      "        [-1.4283, -0.4406, -0.9877],\n",
      "        [-1.4684, -0.4766, -0.9918],\n",
      "        [-1.5087, -0.5118, -0.9969],\n",
      "        [-1.5493, -0.5462, -1.0030],\n",
      "        [-1.5901, -0.5797, -1.0103],\n",
      "        [-1.6312, -0.6123, -1.0189],\n",
      "        [-1.6727, -0.6438, -1.0289],\n",
      "        [-1.7146, -0.6743, -1.0403],\n",
      "        [-1.7571, -0.7037, -1.0534],\n",
      "        [-1.8001, -0.7319, -1.0682],\n",
      "        [-1.8437, -0.7589, -1.0848],\n",
      "        [-1.8881, -0.7847, -1.1034],\n",
      "        [-1.9332, -0.8092, -1.1240],\n",
      "        [-1.9792, -0.8323, -1.1469],\n",
      "        [-2.0262, -0.8541, -1.1721],\n",
      "        [-2.0743, -0.8745, -1.1998],\n",
      "        [-2.1235, -0.8934, -1.2301],\n",
      "        [-2.1741, -0.9109, -1.2632],\n",
      "        [-2.2260, -0.9269, -1.2991],\n",
      "        [-2.2794, -0.9413, -1.3381],\n",
      "        [-2.3345, -0.9542, -1.3803],\n",
      "        [-2.3914, -0.9656, -1.4259],\n",
      "        [-2.4502, -0.9753, -1.4749],\n",
      "        [-2.5110, -0.9835, -1.5276],\n",
      "        [-2.5741, -0.9900, -1.5841]])\n",
      "torch.Size([75, 3])\n"
     ]
    }
   ],
   "source": [
    "print(train_x)\n",
    "print(train_y)\n",
    "print(np.shape(train_y))\n",
    "\n",
    "# = torch.Tensor([[float(-0.3), float(0.99)],[float(-0.07), float(1.01)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c5884c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(train_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37706537",
   "metadata": {},
   "source": [
    "In Reihenfolge:\n",
    "- Mal ohne Ableitung durchlaufen lassen\n",
    "- Mal mit 1-en auf der Diagonale\n",
    "- Mal mit der Ableitungsdiagonale drehen\n",
    "- Gradienten ausgeben lassen\n",
    "- Mal den Datenvektor mit L multiplizieren und als neuen \"Ersteller\" für die Daten nehmen\n",
    "- Lasse L und R nicht quadratisch sein\n",
    "- Einfach -> L (2x3)\n",
    "- Schwer -> L (3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D object at 0x30c35a1f0>,\n",
       " <matplotlib.lines.Line2D object at 0x30c35a220>,\n",
       " <matplotlib.lines.Line2D object at 0x30c35a2b0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec0044",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & dx_1 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "R =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 0\\\\\n",
    "dx_2 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "\\hat{k} =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "SE_1 & 0\\\\\n",
    "0 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "k =& L*\\hat{k}*R\\\\\n",
    "=& \\left[\n",
    "\\begin{matrix}\n",
    "dx_1 dx_2 SE_2 + SE_1 & dx_1 SE_2\\\\\n",
    "dx_2 SE_2 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            k1       dx2^2*k1]\n",
       "[      dx1^2*k1 dx1^2*dx2^2*k1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx1, dx2, k1, k2, f, g = var('dx1, dx2, k1, k2, f, g')\n",
    "K = matrix(2,2, (k1, 0, 0, 0))\n",
    "L = matrix(2, 2, (1, 0, dx1^2, 1))\n",
    "R = matrix(2, 2, (1, dx2^2, 0, 1))\n",
    "L*K*R\n",
    "# used to see how the data should be created if I \n",
    "# decide to create it exactly as I create the kernel\n",
    "#K = matrix(2,1, (f, g))\n",
    "#L*L*K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473d2663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, True]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx1, a, b = var('dx1, a, b')\n",
    "p = dx1*a + dx1*b + dx1^2\n",
    "p.operands()\n",
    "[('+' in str(op) or '^' in str(op)) for op in p.operands()]\n",
    "#[not(not op in [sage.rings.integer.Integer, sage.rings.real_mpfr.RealLiteral] and op.has(d_var)) and ('+' in str(op) or '^' in str(op)) for op in p.operands()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66d6fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_var=(dx1)\n",
    "if type(p) in [sage.symbolic.expression.Expression] and any(not(not op in [sage.rings.integer.Integer, sage.rings.real_mpfr.RealLiteral] and op.has(d_var)) and ('+' in str(op) or '^' in str(op)) for op in p.operands()):\n",
    "    print(\"Damn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef5f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                           1/a                              0]\n",
      "[(-1/(a - 1))/(b + a^2/(a - 1))  (a/(a - 1))/(b + a^2/(a - 1))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[                                 1                             -1/a*b ((-a/(a - 1))/(b + a^2/(a - 1)))*x]\n",
       "[                                 0                                  1         ((-1)/(b + a^2/(a - 1)))*x]\n",
       "[                                 0                                  0                                  1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.<a> = FunctionField(QQ)\n",
    "F.<b> = FunctionField(F)\n",
    "#a, b = var('a, b', domain='real')\n",
    "x = var('x')\n",
    "R.<x> = F[]\n",
    "#R2.<a, b> = ZZ[]\n",
    "m1 = matrix(R, 2, 3, [[a, b, x], [1, a+b, x]])\n",
    "S, U, V = m1.smith_form()\n",
    "\n",
    "print(U)\n",
    "V"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdc5f12e",
   "metadata": {},
   "source": [
    "R = ZZ[I] \n",
    "x = var('x')\n",
    "#Gaussian Integers in Number Field in I with defining polynomial x^2 + 1\n",
    "I = R.basis()[1]\n",
    "M=matrix([[2+I,0],[0,1]]) \n",
    "M.parent()\n",
    "#Full MatrixSpace of 2 by 2 dense matrices over Gaussian Integers in Number Field in I with defining polynomial x^2 + 1\n",
    "M.smith_form()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff9fd73e",
   "metadata": {},
   "source": [
    "a, b = var('a, b', domain=RR)\n",
    "q, dx1, dx2, x = var('q, dx1, dx2, x')\n",
    "R.<x> = QQ[]\n",
    "#Gaussian Integers in Number Field in I with defining polynomial x^2 + 1\n",
    "A = matrix(R, 2, 3, [x+a, -a, -1, -b, x+b, 0])\n",
    "A.smith_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d963c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b285d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        1         0         0]\n",
      "[     -1/4         0      -1/4]\n",
      "[2*dx1 + 2         4 2*dx1 - 2]\n",
      "---\n",
      "[        1      -1/4 2*dx2 + 2]\n",
      "[        0         0         4]\n",
      "[        0      -1/4 2*dx2 - 2]\n",
      "---\n",
      "[[None, None, None], [None, None, None], [None, None, Diff_SE_kernel()]]\n",
      "---\n",
      "List of all kernels: [Diff_SE_kernel()]\n",
      "[[diffed_SE_kernel(), diffed_SE_kernel(), diffed_SE_kernel()], [diffed_SE_kernel(), diffed_SE_kernel(), diffed_SE_kernel()], [diffed_SE_kernel(), diffed_SE_kernel(), diffed_SE_kernel()]]\n",
      "[0,0]: Received derivation form: [[[tensor(0.), tensor(0.)], 0, 0]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(0.), tensor(0.)]\n",
      "derivation coefficient:1\n",
      "l exponent:0\n",
      "(x1-x2) exponent:0\n",
      "\n",
      "\n",
      "[0,1]: Received derivation form: [[[tensor(0.), tensor(-0.2500)], 0, 0]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(0.), tensor(-0.2500)]\n",
      "derivation coefficient:1\n",
      "l exponent:0\n",
      "(x1-x2) exponent:0\n",
      "\n",
      "\n",
      "[0,2]: Received derivation form: [[[tensor(0.), tensor(-2.)], 0, 1]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(0.), tensor(-2.)]\n",
      "derivation coefficient:1\n",
      "l exponent:1\n",
      "(x1-x2) exponent:1\n",
      "\n",
      "\n",
      "[1,0]: Received derivation form: [[[tensor(-0.2500), tensor(0.)], 0, 0]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(-0.2500), tensor(0.)]\n",
      "derivation coefficient:1\n",
      "l exponent:0\n",
      "(x1-x2) exponent:0\n",
      "\n",
      "\n",
      "[1,1]: Received derivation form: [[[tensor(-0.2500), tensor(-0.2500)], 0, 0]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(-0.2500), tensor(-0.2500)]\n",
      "derivation coefficient:1\n",
      "l exponent:0\n",
      "(x1-x2) exponent:0\n",
      "\n",
      "\n",
      "[1,2]: Received derivation form: [[[tensor(-0.2500), tensor(-2.)], 0, 1]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(-0.2500), tensor(-2.)]\n",
      "derivation coefficient:1\n",
      "l exponent:1\n",
      "(x1-x2) exponent:1\n",
      "\n",
      "\n",
      "[2,0]: Received derivation form: [[[tensor(-2.), tensor(0.)], 1, 0]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(-2.), tensor(0.)]\n",
      "derivation coefficient:-1\n",
      "l exponent:1\n",
      "(x1-x2) exponent:1\n",
      "\n",
      "\n",
      "[2,1]: Received derivation form: [[[tensor(-2.), tensor(-0.2500)], 1, 0]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(-2.), tensor(-0.2500)]\n",
      "derivation coefficient:-1\n",
      "l exponent:1\n",
      "(x1-x2) exponent:1\n",
      "\n",
      "\n",
      "[2,2]: Received derivation form: [[[tensor(-2.), tensor(-2.)], 1, 1]]\n",
      "Resulting list (including parameters):\n",
      " > Summand 0, entry 0:\n",
      "polynom coefficients:[tensor(-2.), tensor(-2.)]\n",
      "derivation coefficient:1\n",
      "l exponent:1\n",
      "(x1-x2) exponent:0\n",
      " > Summand 0, entry 1:\n",
      "polynom coefficients:[tensor(-2.), tensor(-2.)]\n",
      "derivation coefficient:-1\n",
      "l exponent:2\n",
      "(x1-x2) exponent:2\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=3\n",
    "        )\n",
    "        kernel = Diff_SE_kernel(var=0, length=0)\n",
    "        kernel2 = Diff_SE_kernel(var=0, length=0)\n",
    "        a, b, q, dx1, dx2, x = var('a, b, q, dx1, dx2, x')\n",
    "        R.<x> = QQ[]\n",
    "        #A = matrix(R, 2, 3, [x+a, -a, -1, -b, x+b, 0])\n",
    "        A = matrix(R, 2, 3, [x, -x^2+x-1, x-2, 2-x, x^2-x-1, -x])\n",
    "        \n",
    "        \n",
    "        #m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "        T, L, R = get_prepared_SNF(A, dx1, dx2)\n",
    "        print(L)\n",
    "        print(\"---\")\n",
    "        print(R)\n",
    "        print(\"---\")\n",
    "        print(T)\n",
    "        print(\"---\")\n",
    "#        L = matrix(2, 2, (1/2, 0, dx1^3, 1))\n",
    "#        R = matrix(2, 2, (1, dx2^3, 0, 1))\n",
    "        \n",
    "        #L = matrix(3, 3, (0, 0, dx1+b, 0, 0, b, 0, 0, dx1*a + dx1*b + dx1^2))\n",
    "        #R = matrix(3, 3, (dx2^2+dx2*b+dx2*a, b, dx2+b, 0, 0, 0, 0, 0, 0))\n",
    "        p = DiffMatrixKernel(T)\n",
    "        \n",
    "        #p = DiffMatrixKernel([[None, None, None], [None, None, None], [None, None, kernel]])\n",
    "        #p = DiffMatrixKernel([[kernel, None], [None, None]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        \n",
    "        #kernel0 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel1 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel2 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel0 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel1 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel0 = Diff_SE_kernel(var = 0, length=0)\n",
    "        #kernel1 = Diff_SE_kernel(var = 0, length=0.01)\n",
    "        #kernel2 = Diff_SE_kernel(var = 0, length=0.02)\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel1]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=3)\n",
    "#likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2, has_global_noise=False, has_task_noise=False)\n",
    "likelihood._set_task_noises(torch.Tensor([float(0.0001), float(0.0001), float(0.0001)]))\n",
    "#likelihood._set_noise(torch.tensor(float(0.0001)))\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)\n",
    "print(model.covar_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f583d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(150)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(-4), float(7), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3a45db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Prior')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (y1_ax, y2_ax, y3_ax) = plt.subplots(int(1), int(3), figsize=(int(15), int(4)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "#y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-30, 30])\n",
    "y1_ax.legend(['Mean', 'Confidence'])\n",
    "y1_ax.set_title('Prior')\n",
    "\n",
    "# Plot training data as black stars\n",
    "#y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-30, 30])\n",
    "y2_ax.legend(['Mean', 'Confidence'])\n",
    "y2_ax.set_title('Prior')\n",
    "\n",
    "# Plot training data as black stars\n",
    "#y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y3_ax.plot(test_x.numpy(), mean[:, 2].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y3_ax.fill_between(test_x.numpy(), lower[:, 2].numpy(), upper[:, 2].numpy(), alpha=0.5)\n",
    "y3_ax.set_ylim([-30, 30])\n",
    "y3_ax.legend(['Mean', 'Confidence'])\n",
    "y3_ax.set_title('Prior')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83acb24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-inf, -inf, -inf], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([0.], requires_grad=True))\n",
      "('covar_module.13091777024.var', Parameter containing:\n",
      "tensor(0., requires_grad=True))\n",
      "('covar_module.13091777024.length', Parameter containing:\n",
      "tensor(0., requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for p in model.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-64d45c148784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'covar'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/sage/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/sage/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;32msrc/cysignals/signals.pyx\u001b[0m in \u001b[0;36mcysignals.signals.python_check_interrupt\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(75)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "param_dict = {p[0]:[] for p in model.named_parameters() if 'covar' in p[0]}\n",
    "param_dict['loss'] = []\n",
    "param_dict['noise'] = []\n",
    "if len(likelihood.task_noises) > 1:\n",
    "    param_dict['task_noises'] = [[] for i in range(len(likelihood.task_noises))]\n",
    "for p in model.named_parameters():\n",
    "    if 'covar' in p[0]:\n",
    "        param_dict[f\"{p[0]}_grad\"] = []\n",
    "\n",
    "for i in range(training_iter):\n",
    "\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    param_dict['loss'].append(loss.item())\n",
    "    #pdb.set_trace()\n",
    "    loss.backward()\n",
    "    for parameter in model.named_parameters():\n",
    "        if 'covar' in parameter[0]:\n",
    "            param_dict[parameter[0]].append(parameter[1].item())\n",
    "            #param_dict[f\"{parameter[0]}_grad\"].append(parameter[1].grad.item())\n",
    "    param_dict['noise'].append(likelihood.noise.item())\n",
    "    for l in range(len(likelihood.task_noises)):\n",
    "        param_dict['task_noises'][l].append(likelihood.task_noises[l].item())\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeffs(given_n):\n",
    "    # See http://oeis.org/A096713\n",
    "    real_n = int(given_n/2)\n",
    "    m, k = var('m, k')\n",
    "    # even\n",
    "    # T(2*m, k) = (-1)^(m+k)*(2*m)!*2^(k-m)/((m-k)!*(2*k)!), k = 0..m.\n",
    "    if given_n % 2 == 0:\n",
    "        # This notation is only valid in iPython\n",
    "        #T(m,k) = factorial(2*m)*2^(k-m)/(factorial(m-k)*factorial(2*k))\n",
    "        # As an actual Python file I need to use:\n",
    "        T = lambda m, k : (-1)**(m+k)*factorial(2*m)*2**(k-m)/(factorial(m-k)*factorial(2*k))\n",
    "    # odd\n",
    "    # T(2*m+1, k) = (-1)^(m+k)*(2*m+1)!*2^(k-m)/((m-k)!*(2*k+1)!), k = 0..m. (End)\n",
    "    else:\n",
    "        # See above\n",
    "        #T(m,k) = factorial(2*m+1)*2^(k-m)/(factorial(m-k)*factorial(2*k+1))\n",
    "        T = lambda m, k: (-1)**(m+k)*factorial(2*m+1)*2**(k-m)/(factorial(m-k)*factorial(2*k+1))\n",
    "    return [int(T(real_n, k)) for k in range(real_n+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(coeffs(i))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c663e6b9",
   "metadata": {},
   "source": [
    "def dynamic_sage_diff(dx1_num, dx2_num):\n",
    "    SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "    for i in range(dx1_num):\n",
    "        SE = SE.diff(x1)\n",
    "    for j in range(dx2_num):\n",
    "        SE = SE.diff(x2)\n",
    "    return SE\n",
    "\n",
    "for j in range(6):\n",
    "    for i in range(6):\n",
    "        print(f\"dx1: {i}; dx2:{j}\")\n",
    "        print(ascii_art(dynamic_sage_diff(i, j)))\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood\n",
    "#torch.autograd.functional.hessian(likelihood, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0219bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_key in param_dict:\n",
    "    if param_key == 'task_noises':\n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(param_dict[param_key], label=param_key)\n",
    "    \n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d928e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likelihood.noise)\n",
    "print(likelihood.task_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b924f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = matrix(QQ, 4, 4, (2,0,0.6065,0.6065,0,1,-0.6065,0.6065,0.6065,-0.6065,2,0,0.6065,0.6065,0,1))\n",
    "L = A.cholesky()\n",
    "L*L.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(150)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(-1), float(4), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax, y3_ax) = plt.subplots(int(1), int(3), figsize=(int(15), int(4)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-30, 30])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-30, 30])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y3_ax.plot(train_x.detach().numpy(), train_y[:, 2].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y3_ax.plot(test_x.numpy(), mean[:, 2].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y3_ax.fill_between(test_x.numpy(), lower[:, 2].numpy(), upper[:, 2].numpy(), alpha=0.5)\n",
    "y3_ax.set_ylim([-30, 30])\n",
    "y3_ax.legend(['Mean', 'Confidence'])\n",
    "y3_ax.set_title('Prior')\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = matrix(1, 2, (1, 2))\n",
    "b = matrix(2, 2, (1, 2, 3, 4))\n",
    "a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(float(0), float(1), int(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = float(SE.diff(x2).diff(x2)(int(v1), int(v2), lengthscale, variance))\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29571cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "#print(SE)\n",
    "#print(SE.diff(x1).diff(x2))\n",
    "print(SE.diff(x2).diff(x2))\n",
    "#print(SE.diff(x1).diff(x2).diff(x1).diff(x2).diff(x1))\n",
    "#print(SE.diff(x1).diff(x2).diff(x1).diff(x2))\n",
    "#float(SE.diff(x2).diff(x1)(float(1.), float(1.), 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1^3 \n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "left_poly = dx2\n",
    "right_poly = 1\n",
    "diffed_kernel2 = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate() + diffed_kernel2(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff_sage(L, M, R, context=None):\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "        map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    # Every row in 'M' is combined with each elem of the row given in 'R'\n",
    "    # Or: For each elemtn in row 'R' combine with 'row_M'\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        # Each element in L gets exactly one element in 'row_M' to multiply\n",
    "        # Or: Combine each element in row_M with exactly one element in 'L'\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp = m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp = m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp = m_elem.diff(l_elem)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp += m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp += m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp += m_elem.diff(l_elem)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "    return temp\n",
    "\n",
    "def diff_sage(matrix, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(matrix)[1])] for j in range(np.shape(matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = calc_cell_diff_sage(l, matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(matrix)[0])][\n",
    "                    int(i % np.shape(matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "L = matrix(2, 2, (x1, x1, 0, x1))\n",
    "R = matrix(2, 2, (x2, 0, x2, x2))\n",
    "x1, x2, l, sigma, l2, sigma2 = var('x1, x2, l, sigma, l2, sigma2')\n",
    "lengthscale = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance = 1\n",
    "lengthscale2 = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance2 = 1\n",
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), sigma2^2*exp(-(x1-x2)^2/(2*l2^2))], [sigma2^2*exp(-(x1-x2)^2/(2*l2^2)), sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "#diffed_SE_sage_matrix_kernel = diff_sage(SEKernelMatrix, left_matrix=L, right_matrix=R)\n",
    "#pprint.pprint(diffed_SE_sage_matrix_kernel)\n",
    "cov_matr = [[None for i in range(len(X)*len(SEKernelMatrix))] for j in range(len(X)*len(SEKernelMatrix))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    for row in range(len(SEKernelMatrix)):\n",
    "        for col in range(len(SEKernelMatrix)):\n",
    "            # Blockwise\n",
    "            #cov_matr[int(i/len(X))+row*len(X)][int(i%len(X))+col*len(X)] = SEKernelMatrix[row][col].substitute(x1=int(v1), x2=int(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2)\n",
    "            # Interleaved\n",
    "            text=f\"x-pos: {int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row}\" +\\\n",
    "            f\" y-pos: {int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))}\" + \\\n",
    "            f\" x1, x2: {v1}, {v2}\\n\" +\\\n",
    "            f\"(x1-x2)^2: {(v1-v2)**2}\"+\\\n",
    "            f\" exp((x1-x2)^2): {np.exp((v1-v2)**2)}\\n\"+\\\n",
    "            f\"val: {float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))}\"\n",
    "            print(text)\n",
    "            print(\"---\")\n",
    "            cov_matr[int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row][int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))] = float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))\n",
    "cov_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd554171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(torch.Tensor(cov_matr).eig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7195921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780479da",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(-(-2-0.66)^2/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b359f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "\n",
    "covar_x = covar_module(X)\n",
    "covar_x.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = [[2, 0, -6*e^(-2), 1, e^(-1/2), -e^(-2)],\n",
    " [0, 2, 0, -e^(-1/2), 1, e^(-1/2)],\n",
    " [-6*e^(-2), 0, 2, -5*e^(-2), -e^(-1/2), 1],\n",
    " [1, e^(-1/2), -e^(-2), 1, 0, -3*e^(-2)],\n",
    " [-e^(-1/2), 1, e^(-1/2), 0, 1, 0],\n",
    " [-5*e^(-2), -e^(-1/2), 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = [[2, 0, -6*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 2, 0, 0, 1, 0],\n",
    " [-6*e^(-2), 0, 2, -3*e^(-2), 0, 1],\n",
    " [1, 0, -3*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 1, 0, 0, 1, 0],\n",
    " [-3*e^(-2), 0, 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = torch.Tensor(matr)\n",
    "import pprint\n",
    "pprint.pprint(matr)\n",
    "print(matr[0::3, 0::3])\n",
    "H_x = 3\n",
    "torch.vstack([torch.hstack([matr[k::H_x, l::H_x] for l in range(H_x)]) for k in range(H_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa5cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = var('a, b, c, d')\n",
    "A = matrix(2,2, (a, b, c, d))\n",
    "B = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "C = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "print(A)\n",
    "print(B)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d1b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "d0bd8764",
   "metadata": {},
   "source": [
    "a, b, c, d, x, y, dx1 = var('a, b, c, d, x, y, dx1')\n",
    "poly = x*x\n",
    "#poly = a*b*dx1**3\n",
    "print(type(poly))\n",
    "#poly = 839840583*x^75\n",
    "print(poly.degree(dx1))\n",
    "print(poly.operands())\n",
    "print([op.is_numeric() for op in poly.operands()])\n",
    "poly.is_polynomial(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac5ab94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def big_func(a, b, c):\n",
    "    print(a)\n",
    "    print(b)\n",
    "    return c*4\n",
    "a = lambda x: big_func(1, 2, x)\n",
    "\n",
    "a(42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.4",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
