{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99ad177f",
   "metadata": {},
   "source": [
    "def replace_mat_variables(m, original:str = 'x', replace:str = None):\n",
    "    m = copy(m)\n",
    "    x = var(original)\n",
    "    if not replace is None:\n",
    "        x1 = var(replace)\n",
    "        for i, row in enumerate(m):\n",
    "            for j, entry in enumerate(row):\n",
    "                m[i, j] = entry.substitute(x1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85d84a63",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# TODO Nochmal durchlaufen lassen\n",
    "def get_prepared_SNF(matrix, left_var=var('dx1'), right_var=var('dx2')):\n",
    "    d, u, v = matrix.smith_form()\n",
    "    (r, c) = np.shape(d)\n",
    "    if r > c:\n",
    "        assert \"More rows than columns in diagonal matrix D\"\n",
    "    dim = max(r,c)\n",
    "    cov_fkt_matr = [[0 for i in range(dim)] for j in range(dim)]\n",
    "    if not d == u*matrix*v:\n",
    "        assert \"The calculation of the Smith form failed or is not possible\"\n",
    "    V_left_transpose = replace_mat_variables(v.transpose(), replace='dx1')\n",
    "    V_right = replace_mat_variables(v, replace='dx2')\n",
    "    \n",
    "    return V_left_transpose, V_right"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d750964e",
   "metadata": {},
   "source": [
    "R.<x> = QQ[]\n",
    "m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "#dx1 = var('dx1')\n",
    "#m[0, 0].substitute(dx1)\n",
    "get_prepared_SNF(m)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d56d1013",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def test_get_prepared_SNF():\n",
    "    m = matrix(2,2,(1,0,1,0))\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [1][1]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0.],[0., 1.]], \"Test 1 failed\"\n",
    "    \n",
    "    R.<x> = QQ[]\n",
    "    m=x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [2][2]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0., 0.],[0., 0., 0.],[0., 0., 1.]], \"Test 2 failed\"\n",
    "    \n",
    "test_get_cov_fkt_from_SNF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(-2), float(2), int(50))\n",
    "# The original sin/cos data\n",
    "#one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.02)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(3)*torch.pow(train_x, int(2)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = int(6)*train_x + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "\n",
    "# Combined poly + sin/cos\n",
    "#one = torch.mul(torch.sin(train_x), train_x)+ torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.mul(torch.cos(train_x), train_x) + torch.sin(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# only sin/cos\n",
    "#one = torch.mul(torch.sin(train_x), torch.cos(train_x)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.mul(torch.cos(train_x), torch.cos(train_x)) - torch.mul(torch.sin(train_x), torch.sin(train_x)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "\n",
    "train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385213ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.0891e+00, -1.1744e+01],\n",
       "        [-6.7664e+00, -1.1647e+01],\n",
       "        [-6.1774e+00, -1.0786e+01],\n",
       "        [-5.4050e+00, -1.0263e+01],\n",
       "        [-4.9407e+00, -9.8478e+00],\n",
       "        [-4.0468e+00, -9.2743e+00],\n",
       "        [-3.2921e+00, -8.8840e+00],\n",
       "        [-3.1151e+00, -8.3252e+00],\n",
       "        [-2.4939e+00, -8.4482e+00],\n",
       "        [-2.1460e+00, -7.8908e+00],\n",
       "        [-1.3666e+00, -7.2849e+00],\n",
       "        [-1.2748e+00, -6.5090e+00],\n",
       "        [-1.1243e+00, -6.0883e+00],\n",
       "        [-5.8232e-01, -5.6721e+00],\n",
       "        [-4.9622e-01, -5.0474e+00],\n",
       "        [-3.7222e-01, -4.8279e+00],\n",
       "        [-3.7064e-01, -4.2901e+00],\n",
       "        [-5.4062e-01, -3.6160e+00],\n",
       "        [-1.6802e-01, -3.1362e+00],\n",
       "        [-2.5164e-01, -2.7227e+00],\n",
       "        [-4.3856e-01, -1.9908e+00],\n",
       "        [-1.2010e-02, -1.8786e+00],\n",
       "        [-2.7534e-01, -9.5332e-01],\n",
       "        [ 2.1155e-01, -7.2433e-01],\n",
       "        [-1.6599e-01, -1.3423e-01],\n",
       "        [-1.0616e-01,  2.2032e-01],\n",
       "        [ 6.0965e-02,  6.9742e-01],\n",
       "        [ 6.4834e-02,  1.3826e+00],\n",
       "        [-8.5154e-02,  1.7430e+00],\n",
       "        [ 7.7795e-02,  2.2423e+00],\n",
       "        [ 3.1850e-01,  2.7173e+00],\n",
       "        [ 4.2583e-01,  2.7834e+00],\n",
       "        [ 1.0453e-01,  3.9491e+00],\n",
       "        [-2.5363e-02,  4.0653e+00],\n",
       "        [ 4.8696e-01,  4.7997e+00],\n",
       "        [ 2.2250e-01,  5.2115e+00],\n",
       "        [ 1.0891e+00,  5.4481e+00],\n",
       "        [ 9.9125e-01,  6.3791e+00],\n",
       "        [ 1.6715e+00,  6.4615e+00],\n",
       "        [ 1.4286e+00,  7.2828e+00],\n",
       "        [ 1.8242e+00,  7.3155e+00],\n",
       "        [ 2.2687e+00,  7.6468e+00],\n",
       "        [ 3.0866e+00,  8.5315e+00],\n",
       "        [ 3.8763e+00,  9.0558e+00],\n",
       "        [ 4.1540e+00,  9.3744e+00],\n",
       "        [ 4.5538e+00,  9.8183e+00],\n",
       "        [ 5.5008e+00,  1.0162e+01],\n",
       "        [ 5.8806e+00,  1.1089e+01],\n",
       "        [ 6.8252e+00,  1.1352e+01],\n",
       "        [ 7.7858e+00,  1.2080e+01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y\n",
    "# = torch.Tensor([[float(-0.3), float(0.99)],[float(-0.07), float(1.01)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5884c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(train_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37706537",
   "metadata": {},
   "source": [
    "In Reihenfolge:\n",
    "- Mal ohne Ableitung durchlaufen lassen\n",
    "- Mal mit 1-en auf der Diagonale\n",
    "- Mal mit der Ableitungsdiagonale drehen\n",
    "- Gradienten ausgeben lassen\n",
    "- Mal den Datenvektor mit L multiplizieren und als neuen \"Ersteller\" fÃ¼r die Daten nehmen\n",
    "- Lasse L und R nicht quadratisch sein\n",
    "- Einfach -> L (2x3)\n",
    "- Schwer -> L (3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D object at 0x252b36ac0>,\n",
       " <matplotlib.lines.Line2D object at 0x252b36af0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec0044",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & dx_1 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "R =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 0\\\\\n",
    "dx_2 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "\\hat{k} =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "SE_1 & 0\\\\\n",
    "0 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "k =& L*\\hat{k}*R\\\\\n",
    "=& \\left[\n",
    "\\begin{matrix}\n",
    "dx_1 dx_2 SE_2 + SE_1 & dx_1 SE_2\\\\\n",
    "dx_2 SE_2 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            k1       dx2^2*k1]\n",
       "[      dx1^2*k1 dx1^2*dx2^2*k1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx1, dx2, k1, k2, f, g = var('dx1, dx2, k1, k2, f, g')\n",
    "K = matrix(2,2, (k1, 0, 0, 0))\n",
    "L = matrix(2, 2, (1, 0, dx1^2, 1))\n",
    "R = matrix(2, 2, (1, dx2^2, 0, 1))\n",
    "L*K*R\n",
    "# used to see how the data should be created if I \n",
    "# decide to create it exactly as I create the kernel\n",
    "#K = matrix(2,1, (f, g))\n",
    "#L*L*K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d5dedb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all kernels: [Diff_SE_kernel()]\n",
      "[[diffed_SE_kernel(), diffed_SE_kernel()], [diffed_SE_kernel(), diffed_SE_kernel()]]\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel(var=0, length=0)\n",
    "        kernel2 = Diff_SE_kernel(var=0, length=0)\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        L = matrix(2, 2, (1, 0, dx1^2, 1))\n",
    "        R = matrix(2, 2, (1, dx2^2, 0, 1))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, None]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        \n",
    "        #kernel0 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel1 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel2 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel0 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel1 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel0 = Diff_SE_kernel(var = 0, length=0)\n",
    "        #kernel1 = Diff_SE_kernel(var = 0, length=0.01)\n",
    "        #kernel2 = Diff_SE_kernel(var = 0, length=0.02)\n",
    "        #self.covar_module = MatrixKernel([[kernel0, kernel2], [None, kernel1]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "#likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2, has_global_noise=False, has_task_noise=False)\n",
    "likelihood._set_task_noises(torch.Tensor([float(0.0001),float(0.0001)]))\n",
    "#likelihood._set_noise(torch.tensor(float(0.0001)))\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  2.0000e+00,  9.9667e-01,  ..., -8.8908e-04,\n",
      "          3.3546e-04, -6.7093e-04],\n",
      "        [ 2.0000e+00, -2.0000e+00,  2.0747e+00,  ...,  1.5120e-02,\n",
      "          2.0128e-03,  1.1406e-02],\n",
      "        [ 9.9667e-01,  2.0747e+00,  1.0000e+00,  ..., -1.1682e-03,\n",
      "          4.6345e-04, -8.8908e-04],\n",
      "        ...,\n",
      "        [-8.8908e-04,  1.5120e-02, -1.1682e-03,  ..., -2.0000e+00,\n",
      "          2.0747e+00, -1.8987e+00],\n",
      "        [ 3.3546e-04,  2.0128e-03,  4.6345e-04,  ...,  2.0747e+00,\n",
      "          1.0000e+00,  2.0000e+00],\n",
      "        [-6.7093e-04,  1.1406e-02, -8.8908e-04,  ..., -1.8987e+00,\n",
      "          2.0000e+00, -2.0000e+00]], grad_fn=<CatBackward>)\n",
      "torch.return_types.eig(\n",
      "eigenvalues=tensor([[ 6.8196e+01,  0.0000e+00],\n",
      "        [ 3.3308e+01,  0.0000e+00],\n",
      "        [-4.8751e+01,  0.0000e+00],\n",
      "        [-4.5633e+01,  0.0000e+00],\n",
      "        [-3.3621e+01,  0.0000e+00],\n",
      "        [-1.9948e+01,  0.0000e+00],\n",
      "        [ 1.2112e+01,  0.0000e+00],\n",
      "        [-8.3901e+00,  0.0000e+00],\n",
      "        [ 3.4631e+00,  0.0000e+00],\n",
      "        [-3.3606e+00,  0.0000e+00],\n",
      "        [-1.6344e+00,  0.0000e+00],\n",
      "        [-1.0365e+00,  0.0000e+00],\n",
      "        [ 7.8287e-01,  0.0000e+00],\n",
      "        [-7.5206e-01,  0.0000e+00],\n",
      "        [-5.7833e-01,  0.0000e+00],\n",
      "        [-4.6155e-01,  0.0000e+00],\n",
      "        [-3.7840e-01,  0.0000e+00],\n",
      "        [-3.1691e-01,  0.0000e+00],\n",
      "        [-2.7003e-01,  0.0000e+00],\n",
      "        [ 1.4172e-01,  0.0000e+00],\n",
      "        [-2.3340e-01,  0.0000e+00],\n",
      "        [-2.0425e-01,  0.0000e+00],\n",
      "        [-1.8061e-01,  0.0000e+00],\n",
      "        [-1.6123e-01,  0.0000e+00],\n",
      "        [-1.4508e-01,  0.0000e+00],\n",
      "        [-1.3154e-01,  0.0000e+00],\n",
      "        [-1.2003e-01,  0.0000e+00],\n",
      "        [-1.1021e-01,  0.0000e+00],\n",
      "        [-1.0173e-01,  0.0000e+00],\n",
      "        [-9.4396e-02,  0.0000e+00],\n",
      "        [-8.7990e-02,  0.0000e+00],\n",
      "        [-8.2387e-02,  0.0000e+00],\n",
      "        [-7.7447e-02,  0.0000e+00],\n",
      "        [-7.3089e-02,  0.0000e+00],\n",
      "        [ 2.1263e-02,  0.0000e+00],\n",
      "        [-6.9219e-02,  0.0000e+00],\n",
      "        [-6.5781e-02,  0.0000e+00],\n",
      "        [-6.2713e-02,  0.0000e+00],\n",
      "        [-5.9976e-02,  0.0000e+00],\n",
      "        [-5.7523e-02,  0.0000e+00],\n",
      "        [-5.5329e-02,  0.0000e+00],\n",
      "        [-5.3361e-02,  0.0000e+00],\n",
      "        [-5.1600e-02,  0.0000e+00],\n",
      "        [-5.0020e-02,  0.0000e+00],\n",
      "        [-4.8609e-02,  0.0000e+00],\n",
      "        [-4.7349e-02,  0.0000e+00],\n",
      "        [-4.6229e-02,  0.0000e+00],\n",
      "        [-4.5237e-02,  0.0000e+00],\n",
      "        [-4.4363e-02,  0.0000e+00],\n",
      "        [-4.3601e-02,  0.0000e+00],\n",
      "        [-4.2943e-02,  0.0000e+00],\n",
      "        [-4.2383e-02,  0.0000e+00],\n",
      "        [-4.0925e-02,  0.0000e+00],\n",
      "        [-4.1918e-02,  0.0000e+00],\n",
      "        [-4.1541e-02,  0.0000e+00],\n",
      "        [-4.1047e-02,  0.0000e+00],\n",
      "        [-4.1252e-02,  0.0000e+00],\n",
      "        [ 2.8031e-03,  0.0000e+00],\n",
      "        [ 3.3659e-04,  0.0000e+00],\n",
      "        [ 3.7041e-05,  0.0000e+00],\n",
      "        [ 3.1595e-06,  0.0000e+00],\n",
      "        [ 1.6512e-06,  0.0000e+00],\n",
      "        [-1.2483e-06,  0.0000e+00],\n",
      "        [-1.1515e-06,  0.0000e+00],\n",
      "        [ 7.3624e-07,  7.9524e-07],\n",
      "        [ 7.3624e-07, -7.9524e-07],\n",
      "        [-5.9616e-08,  9.6231e-07],\n",
      "        [-5.9616e-08, -9.6231e-07],\n",
      "        [-4.8479e-07,  5.9386e-07],\n",
      "        [-4.8479e-07, -5.9386e-07],\n",
      "        [-6.3119e-07,  2.5436e-07],\n",
      "        [-6.3119e-07, -2.5436e-07],\n",
      "        [-5.4762e-07,  2.8753e-07],\n",
      "        [-5.4762e-07, -2.8753e-07],\n",
      "        [ 3.0870e-07,  5.9744e-07],\n",
      "        [ 3.0870e-07, -5.9744e-07],\n",
      "        [-6.2705e-07,  0.0000e+00],\n",
      "        [ 1.1893e-07,  6.0167e-07],\n",
      "        [ 1.1893e-07, -6.0167e-07],\n",
      "        [ 6.8734e-07,  4.9126e-08],\n",
      "        [ 6.8734e-07, -4.9126e-08],\n",
      "        [-4.8317e-07,  0.0000e+00],\n",
      "        [-2.4385e-07,  3.7445e-07],\n",
      "        [-2.4385e-07, -3.7445e-07],\n",
      "        [ 2.2847e-07,  4.4519e-07],\n",
      "        [ 2.2847e-07, -4.4519e-07],\n",
      "        [ 4.5353e-07,  0.0000e+00],\n",
      "        [-1.1360e-07,  4.1282e-07],\n",
      "        [-1.1360e-07, -4.1282e-07],\n",
      "        [ 3.5055e-07,  2.9276e-07],\n",
      "        [ 3.5055e-07, -2.9276e-07],\n",
      "        [-2.0947e-07,  1.7475e-07],\n",
      "        [-2.0947e-07, -1.7475e-07],\n",
      "        [-1.6024e-08,  1.4943e-08],\n",
      "        [-1.6024e-08, -1.4943e-08],\n",
      "        [ 3.5783e-07,  6.4014e-08],\n",
      "        [ 3.5783e-07, -6.4014e-08],\n",
      "        [ 1.1465e-07,  2.5409e-07],\n",
      "        [ 1.1465e-07, -2.5409e-07],\n",
      "        [ 9.3478e-08,  0.0000e+00]], grad_fn=<EigBackward>),\n",
      "eigenvectors=tensor([], grad_fn=<EigBackward>))\n"
     ]
    },
    {
     "ename": "NotPSDError",
     "evalue": "Matrix not positive definite after repeatedly adding jitter up to 1.0e-04. Original error on first attempt: cholesky_cpu: U(2,2) is zero, singular U.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cholesky_cpu: U(2,2) is zero, singular U.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotPSDError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0db2c60917fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Calc loss and backprop gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/distributions/multitask_multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                     \u001b[0mwill_need_cholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwill_need_cholesky\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m                 \u001b[0mcholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCholLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTriangularLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mLazyTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mCholesky\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtriangular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlower\u001b[0m \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m\"upper\"\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \"\"\"\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transpose_nonbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# TODO L*L^T does not make A!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# BUT the decomposition is correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mcholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTriangularLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36mpsd_safe_cholesky\u001b[0;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mwith\u001b[0m \u001b[0msuccessively\u001b[0m \u001b[0mincreasing\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmake\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mraising\u001b[0m \u001b[0man\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_psd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             raise NotPSDError(\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;34mf\"Matrix not positive definite after repeatedly adding jitter up to {jitter_new:.1e}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;34mf\"Original error on first attempt: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotPSDError\u001b[0m: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04. Original error on first attempt: cholesky_cpu: U(2,2) is zero, singular U."
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(75)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "param_dict = {p[0]:[] for p in model.named_parameters() if 'covar' in p[0]}\n",
    "param_dict['loss'] = []\n",
    "param_dict['noise'] = []\n",
    "if len(likelihood.task_noises) > 1:\n",
    "    param_dict['task_noises'] = [[] for i in range(len(likelihood.task_noises))]\n",
    "for p in model.named_parameters():\n",
    "    if 'covar' in p[0]:\n",
    "        param_dict[f\"{p[0]}_grad\"] = []\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    param_dict['loss'].append(loss.item())\n",
    "    #pdb.set_trace()\n",
    "    loss.backward()\n",
    "    for parameter in model.named_parameters():\n",
    "        if 'covar' in parameter[0]:\n",
    "            param_dict[parameter[0]].append(parameter[1].item())\n",
    "            #param_dict[f\"{parameter[0]}_grad\"].append(parameter[1].grad.item())\n",
    "    param_dict['noise'].append(likelihood.noise.item())\n",
    "    for l in range(len(likelihood.task_noises)):\n",
    "        param_dict['task_noises'][l].append(likelihood.task_noises[l].item())\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0219bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_key in param_dict:\n",
    "    if param_key == 'task_noises':\n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(param_dict[param_key], label=param_key)\n",
    "    \n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d928e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likelihood.noise)\n",
    "print(likelihood.task_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b924f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = matrix(QQ, 4, 4, (2,0,0.6065,0.6065,0,1,-0.6065,0.6065,0.6065,-0.6065,2,0,0.6065,0.6065,0,1))\n",
    "L = A.cholesky()\n",
    "L*L.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(120)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(-2), float(7), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(4)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-30, 30])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-30, 30])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = matrix(1, 2, (1, 2))\n",
    "b = matrix(2, 2, (1, 2, 3, 4))\n",
    "a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(float(-2), float(2), int(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = float(SE.diff(x2).diff(x1)(int(v1), int(v2), lengthscale, variance))\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SE.diff(x1))\n",
    "print(SE.diff(x1).diff(x2))\n",
    "float(SE.diff(x2).diff(x1)(float(1.), float(1.), 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1 \n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "left_poly = dx2\n",
    "right_poly = 1\n",
    "diffed_kernel2 = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate() + diffed_kernel2(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff_sage(L, M, R, context=None):\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "        map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    # Every row in 'M' is combined with each elem of the row given in 'R'\n",
    "    # Or: For each elemtn in row 'R' combine with 'row_M'\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        # Each element in L gets exactly one element in 'row_M' to multiply\n",
    "        # Or: Combine each element in row_M with exactly one element in 'L'\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp = m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp = m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp = m_elem.diff(l_elem)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp += m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp += m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp += m_elem.diff(l_elem)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "    return temp\n",
    "\n",
    "def diff_sage(matrix, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(matrix)[1])] for j in range(np.shape(matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = calc_cell_diff_sage(l, matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(matrix)[0])][\n",
    "                    int(i % np.shape(matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "L = matrix(2, 2, (x1, x1, 0, x1))\n",
    "R = matrix(2, 2, (x2, 0, x2, x2))\n",
    "x1, x2, l, sigma, l2, sigma2 = var('x1, x2, l, sigma, l2, sigma2')\n",
    "lengthscale = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance = 1\n",
    "lengthscale2 = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance2 = 1\n",
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), sigma2^2*exp(-(x1-x2)^2/(2*l2^2))], [sigma2^2*exp(-(x1-x2)^2/(2*l2^2)), sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "#diffed_SE_sage_matrix_kernel = diff_sage(SEKernelMatrix, left_matrix=L, right_matrix=R)\n",
    "#pprint.pprint(diffed_SE_sage_matrix_kernel)\n",
    "cov_matr = [[None for i in range(len(X)*len(SEKernelMatrix))] for j in range(len(X)*len(SEKernelMatrix))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    for row in range(len(SEKernelMatrix)):\n",
    "        for col in range(len(SEKernelMatrix)):\n",
    "            # Blockwise\n",
    "            #cov_matr[int(i/len(X))+row*len(X)][int(i%len(X))+col*len(X)] = SEKernelMatrix[row][col].substitute(x1=int(v1), x2=int(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2)\n",
    "            # Interleaved\n",
    "            text=f\"x-pos: {int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row}\" +\\\n",
    "            f\" y-pos: {int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))}\" + \\\n",
    "            f\" x1, x2: {v1}, {v2}\\n\" +\\\n",
    "            f\"(x1-x2)^2: {(v1-v2)**2}\"+\\\n",
    "            f\" exp((x1-x2)^2): {np.exp((v1-v2)**2)}\\n\"+\\\n",
    "            f\"val: {float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))}\"\n",
    "            print(text)\n",
    "            print(\"---\")\n",
    "            cov_matr[int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row][int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))] = float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))\n",
    "cov_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd554171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(torch.Tensor(cov_matr).eig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7195921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780479da",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(-(-2-0.66)^2/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b359f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "\n",
    "covar_x = covar_module(X)\n",
    "covar_x.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = [[2, 0, -6*e^(-2), 1, e^(-1/2), -e^(-2)],\n",
    " [0, 2, 0, -e^(-1/2), 1, e^(-1/2)],\n",
    " [-6*e^(-2), 0, 2, -5*e^(-2), -e^(-1/2), 1],\n",
    " [1, e^(-1/2), -e^(-2), 1, 0, -3*e^(-2)],\n",
    " [-e^(-1/2), 1, e^(-1/2), 0, 1, 0],\n",
    " [-5*e^(-2), -e^(-1/2), 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = [[2, 0, -6*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 2, 0, 0, 1, 0],\n",
    " [-6*e^(-2), 0, 2, -3*e^(-2), 0, 1],\n",
    " [1, 0, -3*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 1, 0, 0, 1, 0],\n",
    " [-3*e^(-2), 0, 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = torch.Tensor(matr)\n",
    "import pprint\n",
    "pprint.pprint(matr)\n",
    "print(matr[0::3, 0::3])\n",
    "H_x = 3\n",
    "torch.vstack([torch.hstack([matr[k::H_x, l::H_x] for l in range(H_x)]) for k in range(H_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa5cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = var('a, b, c, d')\n",
    "A = matrix(2,2, (a, b, c, d))\n",
    "B = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "C = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "print(A)\n",
    "print(B)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d1b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['a', 'b', 'c']\n",
    "y = x                 # x and y reference the same object\n",
    "z = ['a', 'b', 'c']   # x and z reference different objects\n",
    "#z\n",
    "\n",
    "\n",
    "print(x is z)\n",
    "z = x\n",
    "print(x is z)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
