{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(0), float(1), int(50))\n",
    "one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361022cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8734672a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "de84d184",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5dedb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(354)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    352 \u001b[0;31m                    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    353 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 354 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    355 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    356 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(354)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    352 \u001b[0;31m                    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    353 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 354 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    355 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    356 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(354)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    352 \u001b[0;31m                    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    353 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 354 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    355 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    356 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(354)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    352 \u001b[0;31m                    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    353 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 354 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    355 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    356 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel()\n",
    "        kernel2 = Diff_SE_kernel()\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        # TODO test what happens with \n",
    "        #L = matrix(2, 2, (dx1, q, 0, dx1))\n",
    "        # -> does it learn q as a parameter?\n",
    "        #AND\n",
    "        #L = matrix(2, 2, (q*dx1, q, 0, dx1))\n",
    "        # -> does it learn multiple separate q?\n",
    "        L = matrix(2, 2, (q*dx1, 0, 0, dx1))\n",
    "        R = matrix(2, 2, (dx2, 0, 0, dx2))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        #kernel0 = Diff_SE_kernel()\n",
    "        #kernel1 = Diff_SE_kernel()\n",
    "        #kernel2 = Diff_SE_kernel()\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel2]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9994, 0.9975,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [0.9994, 1.0000, 0.9994,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [0.9975, 0.9994, 1.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.4938, 1.4927, 1.4892,  ..., 0.1341, 0.1139, 0.0939],\n",
      "        [1.4927, 1.4938, 1.4927,  ..., 0.1544, 0.1341, 0.1139],\n",
      "        [1.4892, 1.4927, 1.4938,  ..., 0.1749, 0.1544, 0.1341],\n",
      "        ...,\n",
      "        [0.1219, 0.1404, 0.1590,  ..., 1.3580, 1.3570, 1.3538],\n",
      "        [0.1035, 0.1219, 0.1404,  ..., 1.3570, 1.3580, 1.3570],\n",
      "        [0.0854, 0.1035, 0.1219,  ..., 1.3538, 1.3570, 1.3580]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.6953, 1.6938, 1.6893,  ..., 0.1504, 0.1348, 0.1193],\n",
      "        [1.6938, 1.6953, 1.6938,  ..., 0.1660, 0.1504, 0.1348],\n",
      "        [1.6893, 1.6938, 1.6953,  ..., 0.1818, 0.1660, 0.1504],\n",
      "        ...,\n",
      "        [0.1421, 0.1569, 0.1717,  ..., 1.7673, 1.7657, 1.7607],\n",
      "        [0.1274, 0.1421, 0.1569,  ..., 1.7657, 1.7673, 1.7657],\n",
      "        [0.1128, 0.1274, 0.1421,  ..., 1.7607, 1.7657, 1.7673]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.7722, 1.7705, 1.7653,  ..., 0.1471, 0.1348, 0.1225],\n",
      "        [1.7705, 1.7722, 1.7705,  ..., 0.1594, 0.1471, 0.1348],\n",
      "        [1.7653, 1.7705, 1.7722,  ..., 0.1718, 0.1594, 0.1471],\n",
      "        ...,\n",
      "        [0.1482, 0.1607, 0.1731,  ..., 2.3396, 2.3369, 2.3288],\n",
      "        [0.1359, 0.1482, 0.1607,  ..., 2.3369, 2.3396, 2.3369],\n",
      "        [0.1236, 0.1359, 0.1482,  ..., 2.3288, 2.3369, 2.3396]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.7818, 1.7799, 1.7742,  ..., 0.1363, 0.1265, 0.1167],\n",
      "        [1.7799, 1.7818, 1.7799,  ..., 0.1461, 0.1363, 0.1265],\n",
      "        [1.7742, 1.7799, 1.7818,  ..., 0.1559, 0.1461, 0.1363],\n",
      "        ...,\n",
      "        [0.1488, 0.1595, 0.1702,  ..., 3.1857, 3.1810, 3.1669],\n",
      "        [0.1381, 0.1488, 0.1595,  ..., 3.1810, 3.1857, 3.1810],\n",
      "        [0.1274, 0.1381, 0.1488,  ..., 3.1669, 3.1810, 3.1857]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.7631, 1.7610, 1.7548,  ..., 0.1227, 0.1148, 0.1069],\n",
      "        [1.7610, 1.7631, 1.7610,  ..., 0.1306, 0.1227, 0.1148],\n",
      "        [1.7548, 1.7610, 1.7631,  ..., 0.1385, 0.1306, 0.1227],\n",
      "        ...,\n",
      "        [0.1471, 0.1565, 0.1660,  ..., 4.4338, 4.4252, 4.3994],\n",
      "        [0.1376, 0.1471, 0.1565,  ..., 4.4252, 4.4338, 4.4252],\n",
      "        [0.1281, 0.1376, 0.1471,  ..., 4.3994, 4.4252, 4.4338]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.7489, 1.7466, 1.7397,  ..., 0.1085, 0.1021, 0.0957],\n",
      "        [1.7466, 1.7489, 1.7466,  ..., 0.1149, 0.1085, 0.1021],\n",
      "        [1.7397, 1.7466, 1.7489,  ..., 0.1213, 0.1149, 0.1085],\n",
      "        ...,\n",
      "        [0.1445, 0.1530, 0.1615,  ..., 6.1706, 6.1546, 6.1066],\n",
      "        [0.1360, 0.1445, 0.1530,  ..., 6.1546, 6.1706, 6.1546],\n",
      "        [0.1275, 0.1360, 0.1445,  ..., 6.1066, 6.1546, 6.1706]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.7728, 1.7701, 1.7620,  ..., 0.0948, 0.0896, 0.0844],\n",
      "        [1.7701, 1.7728, 1.7701,  ..., 0.1000, 0.0948, 0.0896],\n",
      "        [1.7620, 1.7701, 1.7728,  ..., 0.1052, 0.1000, 0.0948],\n",
      "        ...,\n",
      "        [0.1417, 0.1494, 0.1572,  ..., 8.2774, 8.2492, 8.1647],\n",
      "        [0.1339, 0.1417, 0.1494,  ..., 8.2492, 8.2774, 8.2492],\n",
      "        [0.1261, 0.1339, 0.1417,  ..., 8.1647, 8.2492, 8.2774]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.8693, 1.8658, 1.8554,  ..., 0.0823, 0.0781, 0.0738],\n",
      "        [1.8658, 1.8693, 1.8658,  ..., 0.0866, 0.0823, 0.0781],\n",
      "        [1.8554, 1.8658, 1.8693,  ..., 0.0908, 0.0866, 0.0823],\n",
      "        ...,\n",
      "        [0.1390, 0.1461, 0.1533,  ..., 9.7810, 9.7417, 9.6241],\n",
      "        [0.1318, 0.1390, 0.1461,  ..., 9.7417, 9.7810, 9.7417],\n",
      "        [0.1246, 0.1318, 0.1390,  ..., 9.6241, 9.7417, 9.7810]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0802, 2.0753, 2.0604,  ..., 0.0713, 0.0678, 0.0643],\n",
      "        [2.0753, 2.0802, 2.0753,  ..., 0.0748, 0.0713, 0.0678],\n",
      "        [2.0604, 2.0753, 2.0802,  ..., 0.0783, 0.0748, 0.0713],\n",
      "        ...,\n",
      "        [0.1364, 0.1431, 0.1498,  ..., 9.6514, 9.6126, 9.4967],\n",
      "        [0.1297, 0.1364, 0.1431,  ..., 9.6126, 9.6514, 9.6126],\n",
      "        [0.1230, 0.1297, 0.1364,  ..., 9.4967, 9.6126, 9.6514]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.3692, 2.3616, 2.3386,  ..., 0.0600, 0.0572, 0.0543],\n",
      "        [2.3616, 2.3692, 2.3616,  ..., 0.0628, 0.0600, 0.0572],\n",
      "        [2.3386, 2.3616, 2.3692,  ..., 0.0656, 0.0628, 0.0600],\n",
      "        ...,\n",
      "        [0.1341, 0.1404, 0.1467,  ..., 8.3241, 8.2945, 8.2061],\n",
      "        [0.1278, 0.1341, 0.1404,  ..., 8.2945, 8.3241, 8.2945],\n",
      "        [0.1215, 0.1278, 0.1341,  ..., 8.2061, 8.2945, 8.3241]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.4811, 2.4706, 2.4391,  ..., 0.0487, 0.0465, 0.0443],\n",
      "        [2.4706, 2.4811, 2.4706,  ..., 0.0509, 0.0487, 0.0465],\n",
      "        [2.4391, 2.4706, 2.4811,  ..., 0.0531, 0.0509, 0.0487],\n",
      "        ...,\n",
      "        [0.1322, 0.1382, 0.1441,  ..., 6.6431, 6.6236, 6.5653],\n",
      "        [0.1262, 0.1322, 0.1382,  ..., 6.6236, 6.6431, 6.6236],\n",
      "        [0.1202, 0.1262, 0.1322,  ..., 6.5653, 6.6236, 6.6431]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[3.8478, 3.8264, 3.7624,  ..., 0.0565, 0.0540, 0.0515],\n",
      "        [3.8264, 3.8478, 3.8264,  ..., 0.0590, 0.0565, 0.0540],\n",
      "        [3.7624, 3.8264, 3.8478,  ..., 0.0614, 0.0590, 0.0565],\n",
      "        ...,\n",
      "        [0.1402, 0.1463, 0.1524,  ..., 8.4959, 8.4650, 8.3726],\n",
      "        [0.1340, 0.1402, 0.1463,  ..., 8.4650, 8.4959, 8.4650],\n",
      "        [0.1278, 0.1340, 0.1402,  ..., 8.3726, 8.4650, 8.4959]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 5.8172,  5.7744,  5.6471,  ...,  0.0637,  0.0609,  0.0582],\n",
      "        [ 5.7744,  5.8172,  5.7744,  ...,  0.0664,  0.0637,  0.0609],\n",
      "        [ 5.6471,  5.7744,  5.8172,  ...,  0.0691,  0.0664,  0.0637],\n",
      "        ...,\n",
      "        [ 0.1474,  0.1537,  0.1600,  ..., 10.7859, 10.7374, 10.5926],\n",
      "        [ 0.1411,  0.1474,  0.1537,  ..., 10.7374, 10.7859, 10.7374],\n",
      "        [ 0.1347,  0.1411,  0.1474,  ..., 10.5926, 10.7374, 10.7859]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[ 8.6431,  8.5586,  8.3080,  ...,  0.0703,  0.0673,  0.0644],\n",
      "        [ 8.5586,  8.6431,  8.5586,  ...,  0.0732,  0.0703,  0.0673],\n",
      "        [ 8.3080,  8.5586,  8.6431,  ...,  0.0761,  0.0732,  0.0703],\n",
      "        ...,\n",
      "        [ 0.1540,  0.1604,  0.1669,  ..., 13.5883, 13.5130, 13.2886],\n",
      "        [ 0.1475,  0.1540,  0.1604,  ..., 13.5130, 13.5883, 13.5130],\n",
      "        [ 0.1410,  0.1475,  0.1540,  ..., 13.2886, 13.5130, 13.5883]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[12.6777, 12.5122, 12.0229,  ...,  0.0763,  0.0732,  0.0701],\n",
      "        [12.5122, 12.6777, 12.5122,  ...,  0.0794,  0.0763,  0.0732],\n",
      "        [12.0229, 12.5122, 12.6777,  ...,  0.0825,  0.0794,  0.0763],\n",
      "        ...,\n",
      "        [ 0.1600,  0.1666,  0.1731,  ..., 16.9663, 16.8512, 16.5084],\n",
      "        [ 0.1534,  0.1600,  0.1666,  ..., 16.8512, 16.9663, 16.8512],\n",
      "        [ 0.1468,  0.1534,  0.1600,  ..., 16.5084, 16.8512, 16.9663]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[18.3846, 18.0627, 17.1157,  ...,  0.0818,  0.0785,  0.0752],\n",
      "        [18.0627, 18.3846, 18.0627,  ...,  0.0851,  0.0818,  0.0785],\n",
      "        [17.1157, 18.0627, 18.3846,  ...,  0.0883,  0.0851,  0.0818],\n",
      "        ...,\n",
      "        [ 0.1655,  0.1722,  0.1788,  ..., 20.9477, 20.7750, 20.2616],\n",
      "        [ 0.1588,  0.1655,  0.1722,  ..., 20.7750, 20.9477, 20.7750],\n",
      "        [ 0.1520,  0.1588,  0.1655,  ..., 20.2616, 20.7750, 20.9477]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[26.2881, 25.6718, 23.8706,  ...,  0.0868,  0.0834,  0.0799],\n",
      "        [25.6718, 26.2881, 25.6718,  ...,  0.0902,  0.0868,  0.0834],\n",
      "        [23.8706, 25.6718, 26.2881,  ...,  0.0936,  0.0902,  0.0868],\n",
      "        ...,\n",
      "        [ 0.1705,  0.1773,  0.1840,  ..., 25.4861, 25.2338, 24.4853],\n",
      "        [ 0.1637,  0.1705,  0.1773,  ..., 25.2338, 25.4861, 25.2338],\n",
      "        [ 0.1568,  0.1637,  0.1705,  ..., 24.4853, 25.2338, 25.4861]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[36.7435, 35.6039, 32.3019,  ...,  0.0912,  0.0877,  0.0841],\n",
      "        [35.6039, 36.7435, 35.6039,  ...,  0.0948,  0.0912,  0.0877],\n",
      "        [32.3019, 35.6039, 36.7435,  ...,  0.0983,  0.0948,  0.0912],\n",
      "        ...,\n",
      "        [ 0.1750,  0.1819,  0.1887,  ..., 30.4141, 30.0586, 29.0060],\n",
      "        [ 0.1681,  0.1750,  0.1819,  ..., 30.0586, 30.4141, 30.0586],\n",
      "        [ 0.1612,  0.1681,  0.1750,  ..., 29.0060, 30.0586, 30.4141]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49.3830, 47.4162, 41.7749,  ...,  0.0952,  0.0915,  0.0879],\n",
      "        [47.4162, 49.3830, 47.4162,  ...,  0.0988,  0.0952,  0.0915],\n",
      "        [41.7749, 47.4162, 49.3830,  ...,  0.1024,  0.0988,  0.0952],\n",
      "        ...,\n",
      "        [ 0.1792,  0.1862,  0.1931,  ..., 35.4041, 34.9264, 33.5148],\n",
      "        [ 0.1723,  0.1792,  0.1862,  ..., 34.9264, 35.4041, 34.9264],\n",
      "        [ 0.1652,  0.1723,  0.1792,  ..., 33.5148, 34.9264, 35.4041]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(20)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75730997",
   "metadata": {},
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.8505, -0.8565], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.8546], requires_grad=True))\n",
      "('covar_module.q', Parameter containing:\n",
      "tensor(0.6379, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.0.var', Parameter containing:\n",
      "tensor(1.2430, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.0.length', Parameter containing:\n",
      "tensor(0.1129, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.1.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.1.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.2.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.2.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.3.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.3.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.0.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.0.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.1.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.1.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.2.var', Parameter containing:\n",
      "tensor(0.7224, requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.2.length', Parameter containing:\n",
      "tensor(1.5047, requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.3.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.3.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.0.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.0.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.1.var', Parameter containing:\n",
      "tensor(0.8546, requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.1.length', Parameter containing:\n",
      "tensor(1.4960, requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.2.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.2.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.3.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.3.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.0.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.0.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.1.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.1.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.2.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.2.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.3.var', Parameter containing:\n",
      "tensor(1.6424, requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.3.length', Parameter containing:\n",
      "tensor(0.2027, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "('covar_module.kernel_01.kernels.0.var', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_01.kernels.0.length', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_01.kernels.1.var', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_01.kernels.1.length', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_01.kernels.2.var', Parameter containing:\n",
    "tensor(0.7224, requires_grad=True))\n",
    "('covar_module.kernel_01.kernels.2.length', Parameter containing:\n",
    "tensor(1.5047, requires_grad=True))\n",
    "('covar_module.kernel_01.kernels.3.var', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_01.kernels.3.length', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "\n",
    "('covar_module.kernel_10.kernels.0.var', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_10.kernels.0.length', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_10.kernels.1.var', Parameter containing:\n",
    "tensor(0.8546, requires_grad=True))\n",
    "('covar_module.kernel_10.kernels.1.length', Parameter containing:\n",
    "tensor(1.4960, requires_grad=True))\n",
    "('covar_module.kernel_10.kernels.2.var', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_10.kernels.2.length', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_10.kernels.3.var', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n",
    "('covar_module.kernel_10.kernels.3.length', Parameter containing:\n",
    "tensor(1., requires_grad=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(50)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(0), float(2), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(3)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-3, 8])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-3, 8])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = SE.diff(x2).diff(x1)(int(v1), int(v2), lengthscale, variance)\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1\n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc25ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, row, col):\n",
    "    len_M = M.number_of_arguments()\n",
    "    temp = None\n",
    "    for j in range(int(sqrt(len_M))):\n",
    "        if temp == None:\n",
    "            import itertools\n",
    "            #M_tr = list(map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "            #[M_tr[j].diff(left_poly=L[row][k], right_poly=R.transpose()[col][j]) for k in range(L.number_of_arguments())]\n",
    "            temp = L[row]*M.transpose()[j]*R.transpose()[col][j]\n",
    "        else:\n",
    "            temp += L[row]*M.transpose()[j]*R.transpose()[col][j]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732ed50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dimension = 2\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 1\n",
    "col = 0\n",
    "print((L*M*R)[row][col])\n",
    "\n",
    "calc_cell_diff(L, M, R, row, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "for p in product(L.rows(),R.columns()):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(x1, x2, sigma, l) = matrix(2,2, (sigma^2*exp(-(x1-x2)^2/(2*l^2)), 0, 0, sigma^2*exp(-(x1-x2)^2/(2*l^2))))\n",
    "dx1 = matrix(2,2,(dx1, 0, 0, dx1))\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Diff_SE_kernel()\n",
    "kernel3 = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "\n",
    "l = [[kernel, kernel3], [kernel3, kernel2]]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(1), int(2), int(3)], [int(1), int(2), int(3)]])\n",
    "a[0][1] = int(42)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
