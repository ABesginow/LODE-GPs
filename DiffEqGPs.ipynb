{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(0), float(1), int(50))\n",
    "one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361022cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8734672a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "de84d184",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5dedb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(333)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    331 \u001b[0;31m                    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    332 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 333 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(334)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    332 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    333 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\u001b[0;32m    336 \u001b[0;31m                                requires_grad=True))\n",
      "\u001b[0m\n",
      "ipdb> context\n",
      "*** The 'context' command requires a positive integer argument.\n",
      "ipdb> p context\n",
      "MatrixKernel()\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(335)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    333 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m--> 335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\u001b[0;32m    336 \u001b[0;31m                                requires_grad=True))\n",
      "\u001b[0m\u001b[0;32m    337 \u001b[0;31m                    \u001b[0mcoeff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(336)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\u001b[0;32m--> 336 \u001b[0;31m                                requires_grad=True))\n",
      "\u001b[0m\u001b[0;32m    337 \u001b[0;31m                    \u001b[0mcoeff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    338 \u001b[0;31m                \u001b[0;31m# if coefficient is constant, float() it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(335)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    333 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m--> 335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\u001b[0;32m    336 \u001b[0;31m                                requires_grad=True))\n",
      "\u001b[0m\u001b[0;32m    337 \u001b[0;31m                    \u001b[0mcoeff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(334)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    332 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    333 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\u001b[0;32m    336 \u001b[0;31m                                requires_grad=True))\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(337)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\u001b[0;32m    336 \u001b[0;31m                                requires_grad=True))\n",
      "\u001b[0m\u001b[0;32m--> 337 \u001b[0;31m                    \u001b[0mcoeff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    338 \u001b[0;31m                \u001b[0;31m# if coefficient is constant, float() it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    339 \u001b[0;31m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(324)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    322 \u001b[0;31m        \u001b[0;31m# It's of the form a*b*...*x^n or a*b*...*x extract the coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    323 \u001b[0;31m        \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 324 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    325 \u001b[0;31m                \u001b[0;31m# Check if power or d_var is in item and skip that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    326 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0;34m'^'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p [k for k in context.named_parameters()]\n",
      "[('q', Parameter containing:\n",
      "tensor(1., requires_grad=True))]\n",
      "ipdb> c\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(333)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    331 \u001b[0;31m                    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    332 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 333 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(333)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    331 \u001b[0;31m                    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    332 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 333 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> c\n",
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(333)\u001b[0;36msingle_term_extract\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    331 \u001b[0;31m                    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    332 \u001b[0;31m                    \u001b[0;31m# If it doesn't exist, a trainable parameter with initial value 1 is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 333 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    334 \u001b[0;31m                        setattr(context,  str(item),\n",
      "\u001b[0m\u001b[0;32m    335 \u001b[0;31m                                torch.nn.Parameter(torch.tensor(float(1.)),\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel()\n",
    "        kernel2 = Diff_SE_kernel()\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        # TODO test what happens with \n",
    "        #L = matrix(2, 2, (dx1, q, 0, dx1))\n",
    "        # -> does it learn q as a parameter?\n",
    "        #AND\n",
    "        #L = matrix(2, 2, (q*dx1, q, 0, dx1))\n",
    "        # -> does it learn multiple separate q?\n",
    "        L = matrix(2, 2, (q*dx1, 0, 0, dx1))\n",
    "        R = matrix(2, 2, (dx2, 0, 0, dx2))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        #kernel0 = Diff_SE_kernel()\n",
    "        #kernel1 = Diff_SE_kernel()\n",
    "        #kernel2 = Diff_SE_kernel()\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel2]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9994, 0.9975,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [0.9994, 1.0000, 0.9994,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [0.9975, 0.9994, 1.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.4938, 1.4927, 1.4892,  ..., 0.1341, 0.1139, 0.0939],\n",
      "        [1.4927, 1.4938, 1.4927,  ..., 0.1544, 0.1341, 0.1139],\n",
      "        [1.4892, 1.4927, 1.4938,  ..., 0.1749, 0.1544, 0.1341],\n",
      "        ...,\n",
      "        [0.1219, 0.1404, 0.1590,  ..., 1.3580, 1.3570, 1.3538],\n",
      "        [0.1035, 0.1219, 0.1404,  ..., 1.3570, 1.3580, 1.3570],\n",
      "        [0.0854, 0.1035, 0.1219,  ..., 1.3538, 1.3570, 1.3580]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.7805, 1.7789, 1.7741,  ..., 0.1529, 0.1371, 0.1215],\n",
      "        [1.7789, 1.7805, 1.7789,  ..., 0.1688, 0.1529, 0.1371],\n",
      "        [1.7741, 1.7789, 1.7805,  ..., 0.1847, 0.1688, 0.1529],\n",
      "        ...,\n",
      "        [0.1416, 0.1563, 0.1710,  ..., 1.7314, 1.7298, 1.7250],\n",
      "        [0.1270, 0.1416, 0.1563,  ..., 1.7298, 1.7314, 1.7298],\n",
      "        [0.1125, 0.1270, 0.1416,  ..., 1.7250, 1.7298, 1.7314]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.9558, 1.9538, 1.9480,  ..., 0.1512, 0.1386, 0.1261],\n",
      "        [1.9538, 1.9558, 1.9538,  ..., 0.1637, 0.1512, 0.1386],\n",
      "        [1.9480, 1.9538, 1.9558,  ..., 0.1763, 0.1637, 0.1512],\n",
      "        ...,\n",
      "        [0.1471, 0.1594, 0.1716,  ..., 2.1984, 2.1959, 2.1886],\n",
      "        [0.1350, 0.1471, 0.1594,  ..., 2.1959, 2.1984, 2.1959],\n",
      "        [0.1228, 0.1350, 0.1471,  ..., 2.1886, 2.1959, 2.1984]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0605, 2.0582, 2.0514,  ..., 0.1414, 0.1313, 0.1213],\n",
      "        [2.0582, 2.0605, 2.0582,  ..., 0.1515, 0.1414, 0.1313],\n",
      "        [2.0514, 2.0582, 2.0605,  ..., 0.1616, 0.1515, 0.1414],\n",
      "        ...,\n",
      "        [0.1472, 0.1577, 0.1682,  ..., 2.8303, 2.8264, 2.8148],\n",
      "        [0.1367, 0.1472, 0.1577,  ..., 2.8264, 2.8303, 2.8264],\n",
      "        [0.1262, 0.1367, 0.1472,  ..., 2.8148, 2.8264, 2.8303]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.1292, 2.1266, 2.1188,  ..., 0.1286, 0.1204, 0.1122],\n",
      "        [2.1266, 2.1292, 2.1266,  ..., 0.1368, 0.1286, 0.1204],\n",
      "        [2.1188, 2.1266, 2.1292,  ..., 0.1450, 0.1368, 0.1286],\n",
      "        ...,\n",
      "        [0.1449, 0.1541, 0.1633,  ..., 3.7024, 3.6961, 3.6771],\n",
      "        [0.1357, 0.1449, 0.1541,  ..., 3.6961, 3.7024, 3.6961],\n",
      "        [0.1265, 0.1357, 0.1449,  ..., 3.6771, 3.6961, 3.7024]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.2005, 2.1975, 2.1885,  ..., 0.1152, 0.1085, 0.1018],\n",
      "        [2.1975, 2.2005, 2.1975,  ..., 0.1219, 0.1152, 0.1085],\n",
      "        [2.1885, 2.1975, 2.2005,  ..., 0.1286, 0.1219, 0.1152],\n",
      "        ...,\n",
      "        [0.1416, 0.1499, 0.1581,  ..., 4.8842, 4.8735, 4.8414],\n",
      "        [0.1334, 0.1416, 0.1499,  ..., 4.8735, 4.8842, 4.8735],\n",
      "        [0.1251, 0.1334, 0.1416,  ..., 4.8414, 4.8735, 4.8842]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.3252, 2.3215, 2.3106,  ..., 0.1027, 0.0971, 0.0915],\n",
      "        [2.3215, 2.3252, 2.3215,  ..., 0.1082, 0.1027, 0.0971],\n",
      "        [2.3106, 2.3215, 2.3252,  ..., 0.1138, 0.1082, 0.1027],\n",
      "        ...,\n",
      "        [0.1381, 0.1455, 0.1530,  ..., 6.4188, 6.4007, 6.3467],\n",
      "        [0.1306, 0.1381, 0.1455,  ..., 6.4007, 6.4188, 6.4007],\n",
      "        [0.1231, 0.1306, 0.1381,  ..., 6.3467, 6.4007, 6.4188]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.5605, 2.5557, 2.5413,  ..., 0.0919, 0.0872, 0.0825],\n",
      "        [2.5557, 2.5605, 2.5557,  ..., 0.0966, 0.0919, 0.0872],\n",
      "        [2.5413, 2.5557, 2.5605,  ..., 0.1012, 0.0966, 0.0919],\n",
      "        ...,\n",
      "        [0.1345, 0.1413, 0.1481,  ..., 8.1637, 8.1348, 8.0486],\n",
      "        [0.1276, 0.1345, 0.1413,  ..., 8.1348, 8.1637, 8.1348],\n",
      "        [0.1208, 0.1276, 0.1345,  ..., 8.0486, 8.1348, 8.1637]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.9225, 2.9157, 2.8953,  ..., 0.0821, 0.0781, 0.0742],\n",
      "        [2.9157, 2.9225, 2.9157,  ..., 0.0861, 0.0821, 0.0781],\n",
      "        [2.8953, 2.9157, 2.9225,  ..., 0.0901, 0.0861, 0.0821],\n",
      "        ...,\n",
      "        [0.1311, 0.1374, 0.1437,  ..., 9.2758, 9.2386, 9.1276],\n",
      "        [0.1247, 0.1311, 0.1374,  ..., 9.2386, 9.2758, 9.2386],\n",
      "        [0.1184, 0.1247, 0.1311,  ..., 9.1276, 9.2386, 9.2758]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[3.3236, 3.3138, 3.2843,  ..., 0.0715, 0.0682, 0.0649],\n",
      "        [3.3138, 3.3236, 3.3138,  ..., 0.0748, 0.0715, 0.0682],\n",
      "        [3.2843, 3.3138, 3.3236,  ..., 0.0781, 0.0748, 0.0715],\n",
      "        ...,\n",
      "        [0.1279, 0.1338, 0.1396,  ..., 9.0789, 9.0430, 8.9358],\n",
      "        [0.1219, 0.1279, 0.1338,  ..., 9.0430, 9.0789, 9.0430],\n",
      "        [0.1160, 0.1219, 0.1279,  ..., 8.9358, 9.0430, 9.0789]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[3.5623, 3.5491, 3.5099,  ..., 0.0604, 0.0577, 0.0550],\n",
      "        [3.5491, 3.5623, 3.5491,  ..., 0.0630, 0.0604, 0.0577],\n",
      "        [3.5099, 3.5491, 3.5623,  ..., 0.0657, 0.0630, 0.0604],\n",
      "        ...,\n",
      "        [0.1249, 0.1304, 0.1360,  ..., 7.9444, 7.9165, 7.8330],\n",
      "        [0.1193, 0.1249, 0.1304,  ..., 7.9165, 7.9444, 7.9165],\n",
      "        [0.1137, 0.1193, 0.1249,  ..., 7.8330, 7.9165, 7.9444]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[3.3284, 3.3145, 3.2728,  ..., 0.0492, 0.0471, 0.0450],\n",
      "        [3.3145, 3.3284, 3.3145,  ..., 0.0514, 0.0492, 0.0471],\n",
      "        [3.2728, 3.3145, 3.3284,  ..., 0.0535, 0.0514, 0.0492],\n",
      "        ...,\n",
      "        [0.1222, 0.1275, 0.1327,  ..., 6.5286, 6.5093, 6.4515],\n",
      "        [0.1169, 0.1222, 0.1275,  ..., 6.5093, 6.5286, 6.5093],\n",
      "        [0.1116, 0.1169, 0.1222,  ..., 6.4515, 6.5093, 6.5286]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.5822, 2.5714, 2.5390,  ..., 0.0381, 0.0365, 0.0349],\n",
      "        [2.5714, 2.5822, 2.5714,  ..., 0.0397, 0.0381, 0.0365],\n",
      "        [2.5390, 2.5714, 2.5822,  ..., 0.0413, 0.0397, 0.0381],\n",
      "        ...,\n",
      "        [0.1198, 0.1248, 0.1298,  ..., 5.2200, 5.2073, 5.1692],\n",
      "        [0.1148, 0.1198, 0.1248,  ..., 5.2073, 5.2200, 5.2073],\n",
      "        [0.1097, 0.1148, 0.1198,  ..., 5.1692, 5.2073, 5.2200]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "ename": "NotPSDError",
     "evalue": "Matrix not positive definite after repeatedly adding jitter up to 1.0e-04. Original error on first attempt: cholesky_cpu: U(75,75) is zero, singular U.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cholesky_cpu: U(75,75) is zero, singular U.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotPSDError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-83c011692335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Calc loss and backprop gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/distributions/multitask_multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1238\u001b[0m                     \u001b[0mwill_need_cholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwill_need_cholesky\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                 \u001b[0mcholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCholLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTriangularLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mLazyTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mCholesky\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtriangular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlower\u001b[0m \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m\"upper\"\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \"\"\"\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transpose_nonbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# contiguous call is necessary here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mcholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTriangularLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36mpsd_safe_cholesky\u001b[0;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mwith\u001b[0m \u001b[0msuccessively\u001b[0m \u001b[0mincreasing\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmake\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mraising\u001b[0m \u001b[0man\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_psd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/container_storage/sage/DiffEqGPs/gpytorch/utils/cholesky.py\u001b[0m in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             raise NotPSDError(\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;34mf\"Matrix not positive definite after repeatedly adding jitter up to {jitter_new:.1e}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;34mf\"Original error on first attempt: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotPSDError\u001b[0m: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04. Original error on first attempt: cholesky_cpu: U(75,75) is zero, singular U."
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(20)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75730997",
   "metadata": {},
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.3144, -1.3185], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.3172], requires_grad=True))\n",
      "('covar_module.q', Parameter containing:\n",
      "tensor(0.3190, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.0.var', Parameter containing:\n",
      "tensor(1.2027, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.0.length', Parameter containing:\n",
      "tensor(0.3855, requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.1.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.1.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.2.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.2.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.3.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_00.kernels.3.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.0.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.0.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.1.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.1.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.2.var', Parameter containing:\n",
      "tensor(0.5556, requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.2.length', Parameter containing:\n",
      "tensor(1.4560, requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.3.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_01.kernels.3.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.0.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.0.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.1.var', Parameter containing:\n",
      "tensor(0.5575, requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.1.length', Parameter containing:\n",
      "tensor(1.4563, requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.2.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.2.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.3.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_10.kernels.3.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.0.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.0.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.1.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.1.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.2.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.2.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.3.var', Parameter containing:\n",
      "tensor(1.3365, requires_grad=True))\n",
      "('covar_module.kernel_11.kernels.3.length', Parameter containing:\n",
      "tensor(0.5060, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(50)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(0), float(2), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(3)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-3, 8])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-3, 8])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = SE.diff(x2).diff(x1)(int(v1), int(v2), lengthscale, variance)\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1\n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc25ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, row, col):\n",
    "    len_M = M.number_of_arguments()\n",
    "    temp = None\n",
    "    for j in range(int(sqrt(len_M))):\n",
    "        if temp == None:\n",
    "            import itertools\n",
    "            #M_tr = list(map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "            #[M_tr[j].diff(left_poly=L[row][k], right_poly=R.transpose()[col][j]) for k in range(L.number_of_arguments())]\n",
    "            temp = L[row]*M.transpose()[j]*R.transpose()[col][j]\n",
    "        else:\n",
    "            temp += L[row]*M.transpose()[j]*R.transpose()[col][j]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732ed50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dimension = 2\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 1\n",
    "col = 0\n",
    "print((L*M*R)[row][col])\n",
    "\n",
    "calc_cell_diff(L, M, R, row, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "for p in product(L.rows(),R.columns()):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(x1, x2, sigma, l) = matrix(2,2, (sigma^2*exp(-(x1-x2)^2/(2*l^2)), 0, 0, sigma^2*exp(-(x1-x2)^2/(2*l^2))))\n",
    "dx1 = matrix(2,2,(dx1, 0, 0, dx1))\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
