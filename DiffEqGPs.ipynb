{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99ad177f",
   "metadata": {},
   "source": [
    "def replace_mat_variables(m, original:str = 'x', replace:str = None):\n",
    "    m = copy(m)\n",
    "    x = var(original)\n",
    "    if not replace is None:\n",
    "        x1 = var(replace)\n",
    "        for i, row in enumerate(m):\n",
    "            for j, entry in enumerate(row):\n",
    "                m[i, j] = entry.substitute(x1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85d84a63",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# TODO Nochmal durchlaufen lassen\n",
    "def get_prepared_SNF(matrix, left_var=var('dx1'), right_var=var('dx2')):\n",
    "    d, u, v = matrix.smith_form()\n",
    "    (r, c) = np.shape(d)\n",
    "    if r > c:\n",
    "        assert \"More rows than columns in diagonal matrix D\"\n",
    "    dim = max(r,c)\n",
    "    cov_fkt_matr = [[0 for i in range(dim)] for j in range(dim)]\n",
    "    if not d == u*matrix*v:\n",
    "        assert \"The calculation of the Smith form failed or is not possible\"\n",
    "    V_left_transpose = replace_mat_variables(v.transpose(), replace='dx1')\n",
    "    V_right = replace_mat_variables(v, replace='dx2')\n",
    "    \n",
    "    return V_left_transpose, V_right"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d750964e",
   "metadata": {},
   "source": [
    "R.<x> = QQ[]\n",
    "m = x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "#dx1 = var('dx1')\n",
    "#m[0, 0].substitute(dx1)\n",
    "get_prepared_SNF(m)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d56d1013",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def test_get_prepared_SNF():\n",
    "    m = matrix(2,2,(1,0,1,0))\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [1][1]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0.],[0., 1.]], \"Test 1 failed\"\n",
    "    \n",
    "    R.<x> = QQ[]\n",
    "    m=x^2*matrix(R, 2,3,[1, 0, 1, 1, 0, 0]) +x* matrix(R, 2,3,[-1, -1, -2, -2, 1, 1]) + matrix(R, 2,3,[0, 1, 1, 0, 0, -1])\n",
    "    v1 = vector((1,2,3,4))\n",
    "    v2 = vector((1,2,3,4))\n",
    "    # Standard SE Kernel on the [2][2]-Entry\n",
    "    assert get_cov_fkt_from_SNF(m)(v1, v2).tolist() == [[0., 0., 0.],[0., 0., 0.],[0., 0., 1.]], \"Test 2 failed\"\n",
    "    \n",
    "test_get_cov_fkt_from_SNF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(-2), float(2), int(50))\n",
    "# The original sin/cos data\n",
    "#one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.02)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "#one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = int(3)*torch.pow(train_x, int(2)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Polynomials + diff(poly) data\n",
    "one = torch.pow(train_x, int(3)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = int(3)*train_x**int(2) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# Combined poly + sin/cos\n",
    "#one = torch.mul(torch.sin(train_x), train_x)+ torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.mul(torch.cos(train_x), train_x) + torch.sin(train_x) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "# only sin/cos\n",
    "#one = torch.mul(torch.sin(train_x), torch.cos(train_x)) + torch.randn(train_x.size()) * float(0.2)\n",
    "#two = torch.mul(torch.cos(train_x), torch.cos(train_x)) - torch.mul(torch.sin(train_x), torch.sin(train_x)) + torch.randn(train_x.size()) * float(0.2)\n",
    "\n",
    "train_y = torch.stack([one,two], int(-1))\n",
    "#train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385213ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0000, -1.9184, -1.8367, -1.7551, -1.6735, -1.5918, -1.5102, -1.4286,\n",
      "        -1.3469, -1.2653, -1.1837, -1.1020, -1.0204, -0.9388, -0.8571, -0.7755,\n",
      "        -0.6939, -0.6122, -0.5306, -0.4490, -0.3673, -0.2857, -0.2041, -0.1224,\n",
      "        -0.0408,  0.0408,  0.1224,  0.2041,  0.2857,  0.3673,  0.4490,  0.5306,\n",
      "         0.6122,  0.6939,  0.7755,  0.8571,  0.9388,  1.0204,  1.1020,  1.1837,\n",
      "         1.2653,  1.3469,  1.4286,  1.5102,  1.5918,  1.6735,  1.7551,  1.8367,\n",
      "         1.9184,  2.0000])\n",
      "tensor([[-8.2014, 12.1304],\n",
      "        [-7.2099, 10.9811],\n",
      "        [-6.2234, 10.4967],\n",
      "        [-5.4289,  9.2914],\n",
      "        [-4.5481,  8.5680],\n",
      "        [-4.5544,  7.5172],\n",
      "        [-3.5582,  6.7833],\n",
      "        [-3.0590,  5.8217],\n",
      "        [-2.5354,  5.8872],\n",
      "        [-2.1702,  4.8824],\n",
      "        [-1.5940,  4.4708],\n",
      "        [-1.3810,  3.7173],\n",
      "        [-0.7010,  3.2143],\n",
      "        [-0.5191,  2.7443],\n",
      "        [-0.6744,  2.1337],\n",
      "        [-0.4665,  1.9113],\n",
      "        [-0.5824,  1.7400],\n",
      "        [-0.1725,  0.9707],\n",
      "        [-0.1887,  0.7254],\n",
      "        [ 0.0941,  0.5895],\n",
      "        [-0.0677,  0.1574],\n",
      "        [-0.0872,  0.1084],\n",
      "        [-0.0499,  0.2624],\n",
      "        [ 0.1802, -0.0375],\n",
      "        [-0.0289, -0.0858],\n",
      "        [-0.2278,  0.1262],\n",
      "        [ 0.1294, -0.0750],\n",
      "        [-0.3962,  0.2640],\n",
      "        [-0.0428,  0.0715],\n",
      "        [ 0.5038,  0.4519],\n",
      "        [ 0.0888,  0.7162],\n",
      "        [ 0.2666,  0.9702],\n",
      "        [ 0.1058,  1.6256],\n",
      "        [-0.1833,  1.2203],\n",
      "        [ 0.2861,  1.8208],\n",
      "        [ 0.6318,  2.5622],\n",
      "        [ 0.7361,  2.4427],\n",
      "        [ 1.0195,  3.1253],\n",
      "        [ 1.0915,  3.2577],\n",
      "        [ 1.5775,  4.7340],\n",
      "        [ 1.9484,  4.6492],\n",
      "        [ 2.3330,  5.7662],\n",
      "        [ 2.9787,  5.9038],\n",
      "        [ 3.8569,  6.5387],\n",
      "        [ 3.8028,  7.4882],\n",
      "        [ 4.8877,  8.2443],\n",
      "        [ 5.5152,  9.1610],\n",
      "        [ 6.1418,  9.8942],\n",
      "        [ 7.1886, 11.4493],\n",
      "        [ 7.9768, 11.7200]])\n",
      "torch.Size([50, 2])\n"
     ]
    }
   ],
   "source": [
    "print(train_x)\n",
    "print(train_y)\n",
    "print(np.shape(train_y))\n",
    "\n",
    "# = torch.Tensor([[float(-0.3), float(0.99)],[float(-0.07), float(1.01)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5884c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(train_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37706537",
   "metadata": {},
   "source": [
    "In Reihenfolge:\n",
    "- Mal ohne Ableitung durchlaufen lassen\n",
    "- Mal mit 1-en auf der Diagonale\n",
    "- Mal mit der Ableitungsdiagonale drehen\n",
    "- Gradienten ausgeben lassen\n",
    "- Mal den Datenvektor mit L multiplizieren und als neuen \"Ersteller\" fÃ¼r die Daten nehmen\n",
    "- Lasse L und R nicht quadratisch sein\n",
    "- Einfach -> L (2x3)\n",
    "- Schwer -> L (3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D object at 0x26c737a90>,\n",
       " <matplotlib.lines.Line2D object at 0x26c72a910>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec0044",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & dx_1 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "R =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 0\\\\\n",
    "dx_2 & 1\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "\\hat{k} =& \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "SE_1 & 0\\\\\n",
    "0 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\\\\\n",
    "k =& L*\\hat{k}*R\\\\\n",
    "=& \\left[\n",
    "\\begin{matrix}\n",
    "dx_1 dx_2 SE_2 + SE_1 & dx_1 SE_2\\\\\n",
    "dx_2 SE_2 & SE_2\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            k1       dx2^2*k1]\n",
       "[      dx1^2*k1 dx1^2*dx2^2*k1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx1, dx2, k1, k2, f, g = var('dx1, dx2, k1, k2, f, g')\n",
    "K = matrix(2,2, (k1, 0, 0, 0))\n",
    "L = matrix(2, 2, (1, 0, dx1^2, 1))\n",
    "R = matrix(2, 2, (1, dx2^2, 0, 1))\n",
    "L*K*R\n",
    "# used to see how the data should be created if I \n",
    "# decide to create it exactly as I create the kernel\n",
    "#K = matrix(2,1, (f, g))\n",
    "#L*L*K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2591b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all kernels: [Diff_SE_kernel()]\n",
      "[[diffed_SE_kernel(), diffed_SE_kernel()], [diffed_SE_kernel(), diffed_SE_kernel()]]\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel(var=0, length=0)\n",
    "        kernel2 = Diff_SE_kernel(var=0, length=0)\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        L = matrix(2, 2, (1, 0, dx1, 1))\n",
    "        R = matrix(2, 2, (1, dx2, 0, 1))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, None]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        \n",
    "        #kernel0 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel1 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel2 = gpytorch.kernels.RBFKernel()\n",
    "        #kernel0 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel1 = gpytorch.kernels.PeriodicKernel()\n",
    "        #kernel0 = Diff_SE_kernel(var = 0, length=0)\n",
    "        #kernel1 = Diff_SE_kernel(var = 0, length=0.01)\n",
    "        #kernel2 = Diff_SE_kernel(var = 0, length=0.02)\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel1]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "#likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2, has_global_noise=False, has_task_noise=False)\n",
    "likelihood._set_task_noises(torch.Tensor([float(0.0001),float(0.0001)]))\n",
    "#likelihood._set_noise(torch.tensor(float(0.0001)))\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/andreas/Documents/container_storage/sage/DiffEqGPs/kernels.py\u001b[0m(378)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    376 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    377 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 378 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0msummand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    379 \u001b[0;31m                    \u001b[0mK_0_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    380 \u001b[0;31m                    \u001b[0ml_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> term\n",
      "[[[tensor(1.), tensor(1.)], 1, 0.0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(75)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "param_dict = {p[0]:[] for p in model.named_parameters() if 'covar' in p[0]}\n",
    "param_dict['loss'] = []\n",
    "param_dict['noise'] = []\n",
    "if len(likelihood.task_noises) > 1:\n",
    "    param_dict['task_noises'] = [[] for i in range(len(likelihood.task_noises))]\n",
    "for p in model.named_parameters():\n",
    "    if 'covar' in p[0]:\n",
    "        param_dict[f\"{p[0]}_grad\"] = []\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    param_dict['loss'].append(loss.item())\n",
    "    #pdb.set_trace()\n",
    "    loss.backward()\n",
    "    for parameter in model.named_parameters():\n",
    "        if 'covar' in parameter[0]:\n",
    "            param_dict[parameter[0]].append(parameter[1].item())\n",
    "            #param_dict[f\"{parameter[0]}_grad\"].append(parameter[1].grad.item())\n",
    "    param_dict['noise'].append(likelihood.noise.item())\n",
    "    for l in range(len(likelihood.task_noises)):\n",
    "        param_dict['task_noises'][l].append(likelihood.task_noises[l].item())\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood\n",
    "#torch.autograd.functional.hessian(likelihood, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0219bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_key in param_dict:\n",
    "    if param_key == 'task_noises':\n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(param_dict[param_key], label=param_key)\n",
    "    \n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d928e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likelihood.noise)\n",
    "print(likelihood.task_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b924f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = matrix(QQ, 4, 4, (2,0,0.6065,0.6065,0,1,-0.6065,0.6065,0.6065,-0.6065,2,0,0.6065,0.6065,0,1))\n",
    "L = A.cholesky()\n",
    "L*L.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(120)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(-2), float(7), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(4)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-30, 30])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-30, 30])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = matrix(1, 2, (1, 2))\n",
    "b = matrix(2, 2, (1, 2, 3, 4))\n",
    "a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(float(-2), float(2), int(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = float(SE.diff(x2).diff(x1).diff(x1).diff(x2)(int(v1), int(v2), lengthscale, variance))\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SE)\n",
    "print(SE.diff(x2))\n",
    "#print(SE.diff(x1).diff(x2))\n",
    "#print(SE.diff(x1).diff(x2).diff(x1))\n",
    "#print(SE.diff(x1).diff(x2).diff(x1).diff(x2))\n",
    "#float(SE.diff(x2).diff(x1)(float(1.), float(1.), 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1^3 \n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "left_poly = dx2\n",
    "right_poly = 1\n",
    "diffed_kernel2 = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate() + diffed_kernel2(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff_sage(L, M, R, context=None):\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "        map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    # Every row in 'M' is combined with each elem of the row given in 'R'\n",
    "    # Or: For each elemtn in row 'R' combine with 'row_M'\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        # Each element in L gets exactly one element in 'row_M' to multiply\n",
    "        # Or: Combine each element in row_M with exactly one element in 'L'\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp = m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp = m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp = m_elem.diff(l_elem)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp += m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp += m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp += m_elem.diff(l_elem)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "    return temp\n",
    "\n",
    "def diff_sage(matrix, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(matrix)[1])] for j in range(np.shape(matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = calc_cell_diff_sage(l, matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(matrix)[0])][\n",
    "                    int(i % np.shape(matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "L = matrix(2, 2, (x1, x1, 0, x1))\n",
    "R = matrix(2, 2, (x2, 0, x2, x2))\n",
    "x1, x2, l, sigma, l2, sigma2 = var('x1, x2, l, sigma, l2, sigma2')\n",
    "lengthscale = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance = 1\n",
    "lengthscale2 = torch.nn.functional.softplus(torch.tensor(float(0.0)))\n",
    "variance2 = 1\n",
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), sigma2^2*exp(-(x1-x2)^2/(2*l2^2))], [sigma2^2*exp(-(x1-x2)^2/(2*l2^2)), sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "#diffed_SE_sage_matrix_kernel = diff_sage(SEKernelMatrix, left_matrix=L, right_matrix=R)\n",
    "#pprint.pprint(diffed_SE_sage_matrix_kernel)\n",
    "cov_matr = [[None for i in range(len(X)*len(SEKernelMatrix))] for j in range(len(X)*len(SEKernelMatrix))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    for row in range(len(SEKernelMatrix)):\n",
    "        for col in range(len(SEKernelMatrix)):\n",
    "            # Blockwise\n",
    "            #cov_matr[int(i/len(X))+row*len(X)][int(i%len(X))+col*len(X)] = SEKernelMatrix[row][col].substitute(x1=int(v1), x2=int(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2)\n",
    "            # Interleaved\n",
    "            text=f\"x-pos: {int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row}\" +\\\n",
    "            f\" y-pos: {int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))}\" + \\\n",
    "            f\" x1, x2: {v1}, {v2}\\n\" +\\\n",
    "            f\"(x1-x2)^2: {(v1-v2)**2}\"+\\\n",
    "            f\" exp((x1-x2)^2): {np.exp((v1-v2)**2)}\\n\"+\\\n",
    "            f\"val: {float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))}\"\n",
    "            print(text)\n",
    "            print(\"---\")\n",
    "            cov_matr[int(((i*len(SEKernelMatrix))+row)/(len(X)*len(SEKernelMatrix)))*2+row][int((i*len(SEKernelMatrix))+col)%(len(X)*len(SEKernelMatrix))] = float(SEKernelMatrix[row][col].substitute(x1=float(v1), x2=float(v2), l=float(lengthscale), sigma=variance, l2=float(lengthscale2), sigma2=variance2))\n",
    "cov_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd554171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(torch.Tensor(cov_matr).eig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7195921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780479da",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(-(-2-0.66)^2/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b359f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "\n",
    "covar_x = covar_module(X)\n",
    "covar_x.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = [[2, 0, -6*e^(-2), 1, e^(-1/2), -e^(-2)],\n",
    " [0, 2, 0, -e^(-1/2), 1, e^(-1/2)],\n",
    " [-6*e^(-2), 0, 2, -5*e^(-2), -e^(-1/2), 1],\n",
    " [1, e^(-1/2), -e^(-2), 1, 0, -3*e^(-2)],\n",
    " [-e^(-1/2), 1, e^(-1/2), 0, 1, 0],\n",
    " [-5*e^(-2), -e^(-1/2), 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = [[2, 0, -6*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 2, 0, 0, 1, 0],\n",
    " [-6*e^(-2), 0, 2, -3*e^(-2), 0, 1],\n",
    " [1, 0, -3*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 1, 0, 0, 1, 0],\n",
    " [-3*e^(-2), 0, 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = torch.Tensor(matr)\n",
    "import pprint\n",
    "pprint.pprint(matr)\n",
    "print(matr[0::3, 0::3])\n",
    "H_x = 3\n",
    "torch.vstack([torch.hstack([matr[k::H_x, l::H_x] for l in range(H_x)]) for k in range(H_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa5cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = var('a, b, c, d')\n",
    "A = matrix(2,2, (a, b, c, d))\n",
    "B = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "C = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "print(A)\n",
    "print(B)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d1b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, x, y, dx1 = var('a, b, c, d, x, y, dx1')\n",
    "poly = (a*(2*(c+b)+a)+a)*y\n",
    "#poly = a*b*dx1**3\n",
    "print(type(poly))\n",
    "#poly = 839840583*x^75\n",
    "print(poly.degree(dx1))\n",
    "print(poly.operands())\n",
    "print([op.is_numeric() for op in poly.operands()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_list = []\n",
    "l1 = [[42, 17], [128, 256]]\n",
    "for i, l in enumerate(l1):\n",
    "    if i == 0:\n",
    "        func1 = lambda : l[0]*l[1]\n",
    "        return_list.append(func1)\n",
    "    else: \n",
    "        func2 = lambda : l[0]*l[1]\n",
    "        return_list.append(func2)\n",
    "\n",
    "for func in return_list:\n",
    "    print(func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967647fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
