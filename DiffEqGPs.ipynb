{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(0), float(1), int(50))\n",
    "one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361022cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8734672a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "de84d184",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5dedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel()\n",
    "        kernel2 = Diff_SE_kernel()\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        # TODO test what happens with \n",
    "        #L = matrix(2, 2, (dx1, q, 0, dx1))\n",
    "        # -> does it learn q as a parameter?\n",
    "        #AND\n",
    "        #L = matrix(2, 2, (q*dx1, q, 0, dx1))\n",
    "        # -> does it learn multiple separate q?\n",
    "        L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "        R = matrix(2, 2, (dx2, 0, 0, dx2))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "        #self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        kernel0 = Diff_SE_kernel()\n",
    "        kernel1 = Diff_SE_kernel()\n",
    "        kernel2 = Diff_SE_kernel()\n",
    "        self.covar_module = MatrixKernel([[kernel0, None], [None, kernel2]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0001, 0.9998, 0.9992,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9998, 1.0001, 0.9998,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9992, 0.9998, 1.0001,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0001, 0.9998, 0.9992],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9998, 1.0001, 0.9998],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9992, 0.9998, 1.0001]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.1001, 1.0997, 1.0989,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0997, 1.1001, 1.0997,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0989, 1.0997, 1.1001,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9001, 0.8998, 0.8991],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8998, 0.9001, 0.8998],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8991, 0.8998, 0.9001]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.1588, 1.1583, 1.1572,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1583, 1.1588, 1.1583,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1572, 1.1583, 1.1588,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8464, 0.8460, 0.8452],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8460, 0.8464, 0.8460],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8452, 0.8460, 0.8464]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.1438, 1.1433, 1.1418,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1433, 1.1438, 1.1433,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1418, 1.1433, 1.1438,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8881, 0.8876, 0.8865],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8876, 0.8881, 0.8876],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8865, 0.8876, 0.8881]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.0912, 1.0904, 1.0885,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0904, 1.0912, 1.0904,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0885, 1.0904, 1.0912,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9552, 0.9546, 0.9530],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9546, 0.9552, 0.9546],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9530, 0.9546, 0.9552]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.0211, 1.0202, 1.0176,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0202, 1.0211, 1.0202,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0176, 1.0202, 1.0211,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0330, 1.0321, 1.0297],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0321, 1.0330, 1.0321],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0297, 1.0321, 1.0330]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.9419, 0.9406, 0.9371,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9406, 0.9419, 0.9406,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9371, 0.9406, 0.9419,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.1179, 1.1165, 1.1128],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.1165, 1.1179, 1.1165],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.1128, 1.1165, 1.1179]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.8588, 0.8568, 0.8514,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8568, 0.8588, 0.8568,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.8514, 0.8568, 0.8588,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2056, 1.2033, 1.1966],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2033, 1.2056, 1.2033],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.1966, 1.2033, 1.2056]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.7704, 0.7670, 0.7570,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7670, 0.7704, 0.7670,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.7570, 0.7670, 0.7704,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2850, 1.2803, 1.2666],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2803, 1.2850, 1.2803],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2666, 1.2803, 1.2850]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.6908, 0.6855, 0.6700,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.6855, 0.6908, 0.6855,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.6700, 0.6855, 0.6908,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3413, 1.3318, 1.3039],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3318, 1.3413, 1.3318],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3039, 1.3318, 1.3413]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.6096, 0.6051, 0.5924,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.6051, 0.6096, 0.6051,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5924, 0.6051, 0.6096,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3677, 1.3551, 1.3183],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3551, 1.3677, 1.3551],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3183, 1.3551, 1.3677]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.5225, 0.5197, 0.5118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5197, 0.5225, 0.5197,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5118, 0.5197, 0.5225,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3685, 1.3581, 1.3279],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3581, 1.3685, 1.3581],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3279, 1.3581, 1.3685]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.4320, 0.4303, 0.4257,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4303, 0.4320, 0.4303,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4257, 0.4303, 0.4320,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3516, 1.3446, 1.3242],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3446, 1.3516, 1.3446],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3242, 1.3446, 1.3516]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.3527, 0.3516, 0.3486,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3516, 0.3527, 0.3516,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3486, 0.3516, 0.3527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3238, 1.3192, 1.3057],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3192, 1.3238, 1.3192],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.3057, 1.3192, 1.3238]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.3179, 0.3169, 0.3143,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3169, 0.3179, 0.3169,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3143, 0.3169, 0.3179,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2902, 1.2870, 1.2777],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2870, 1.2902, 1.2870],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2777, 1.2870, 1.2902]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.3248, 0.3237, 0.3207,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3237, 0.3248, 0.3237,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3207, 0.3237, 0.3248,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2561, 1.2537, 1.2468],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2537, 1.2561, 1.2537],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2468, 1.2537, 1.2561]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.3536, 0.3521, 0.3478,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3521, 0.3536, 0.3521,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3478, 0.3521, 0.3536,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2275, 1.2255, 1.2199],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2255, 1.2275, 1.2255],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2199, 1.2255, 1.2275]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.3885, 0.3862, 0.3798,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3862, 0.3885, 0.3862,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3798, 0.3862, 0.3885,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2096, 1.2078, 1.2027],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2078, 1.2096, 1.2078],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2027, 1.2078, 1.2096]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.4165, 0.4135, 0.4052,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4135, 0.4165, 0.4135,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4052, 0.4135, 0.4165,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2048, 1.2030, 1.1980],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2030, 1.2048, 1.2030],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.1980, 1.2030, 1.2048]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.4311, 0.4282, 0.4197,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4282, 0.4311, 0.4282,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4197, 0.4282, 0.4311,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2122, 1.2103, 1.2049],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2103, 1.2122, 1.2103],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2049, 1.2103, 1.2122]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(20)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75730997",
   "metadata": {},
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-2.0351, -2.0553], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-2.0463], requires_grad=True))\n",
      "('covar_module.kernel_00.var', Parameter containing:\n",
      "tensor(0.4333, requires_grad=True))\n",
      "('covar_module.kernel_00.length', Parameter containing:\n",
      "tensor(0.1958, requires_grad=True))\n",
      "('covar_module.kernel_11.var', Parameter containing:\n",
      "tensor(1.2282, requires_grad=True))\n",
      "('covar_module.kernel_11.length', Parameter containing:\n",
      "tensor(0.3502, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(50)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(0), float(2), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a03a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(3)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-3, 8])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-3, 8])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = SE.diff(x2).diff(x1)(int(v1), int(v2), lengthscale, variance)\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1\n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22088bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, row, col):\n",
    "    len_M = M.number_of_arguments()\n",
    "    temp = None\n",
    "    for j in range(int(sqrt(len_M))):\n",
    "        if temp == None:\n",
    "            import itertools\n",
    "            #M_tr = list(map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "            #[M_tr[j].diff(left_poly=L[row][k], right_poly=R.transpose()[col][j]) for k in range(L.number_of_arguments())]\n",
    "            temp = L[row]*M.transpose()[j]*R.transpose()[col][j]\n",
    "        else:\n",
    "            temp += L[row]*M.transpose()[j]*R.transpose()[col][j]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732ed50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dimension = 2\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 1\n",
    "col = 0\n",
    "print((L*M*R)[row][col])\n",
    "\n",
    "calc_cell_diff(L, M, R, row, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335005b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "for p in product(L.rows(),R.columns()):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5100bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(x1, x2, sigma, l) = matrix(2,2, (sigma^2*exp(-(x1-x2)^2/(2*l^2)), 0, 0, sigma^2*exp(-(x1-x2)^2/(2*l^2))))\n",
    "dx1 = matrix(2,2,(dx1, 0, 0, dx1))\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0bddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7317ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e98beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
