{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(0), float(1), int(50))\n",
    "one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8734672a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5dedb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all kernels: [Diff_SE_kernel()]\n",
      "[[AdditiveKernel(\n",
      "  (kernels): ModuleList(\n",
      "    (0): diffed_SE_kernel()\n",
      "    (1): diffed_SE_kernel()\n",
      "  )\n",
      "), AdditiveKernel(\n",
      "  (kernels): ModuleList(\n",
      "    (0): diffed_SE_kernel()\n",
      "    (1): diffed_SE_kernel()\n",
      "  )\n",
      ")], [AdditiveKernel(\n",
      "  (kernels): ModuleList(\n",
      "    (0): diffed_SE_kernel()\n",
      "    (1): diffed_SE_kernel()\n",
      "  )\n",
      "), AdditiveKernel(\n",
      "  (kernels): ModuleList(\n",
      "    (0): diffed_SE_kernel()\n",
      "    (1): diffed_SE_kernel()\n",
      "  )\n",
      ")]]\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel()\n",
    "        kernel2 = Diff_SE_kernel()\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        L = matrix(2, 2, (1, dx1, 0, 1))\n",
    "        R = matrix(2, 2, (1, 0, dx2, 2))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, kernel]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        #kernel0 = Diff_SE_kernel()\n",
    "        #kernel1 = Diff_SE_kernel()\n",
    "        #kernel2 = Diff_SE_kernel()\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel2]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([0., 0.], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([0.], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(1., requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9996, 1.9983,  ..., 1.2625, 1.2378, 1.2131],\n",
      "        [1.9996, 2.0000, 1.9996,  ..., 1.2872, 1.2625, 1.2378],\n",
      "        [1.9983, 1.9996, 2.0000,  ..., 1.3119, 1.2872, 1.2625],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.0000, 1.9996, 1.9983],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.9996, 2.0000, 1.9996],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.9983, 1.9996, 2.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9996, 1.9983,  ..., 1.2625, 1.2378, 1.2131],\n",
      "        [1.9996, 2.0000, 1.9996,  ..., 1.2872, 1.2625, 1.2378],\n",
      "        [1.9983, 1.9996, 2.0000,  ..., 1.3119, 1.2872, 1.2625],\n",
      "        ...,\n",
      "        [1.2625, 1.2872, 1.3119,  ..., 2.0000, 1.9996, 1.9983],\n",
      "        [1.2378, 1.2625, 1.2872,  ..., 1.9996, 2.0000, 1.9996],\n",
      "        [1.2131, 1.2378, 1.2625,  ..., 1.9983, 1.9996, 2.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 2.0000, 1.9996,  ..., 1.2378, 1.2131, 1.2131],\n",
      "        [2.0000, 2.0000, 1.9996,  ..., 1.2378, 1.2131, 1.2131],\n",
      "        [1.9996, 1.9996, 2.0000,  ..., 1.2625, 1.2378, 1.2378],\n",
      "        ...,\n",
      "        [1.2378, 1.2378, 1.2625,  ..., 2.0000, 1.9996, 1.9996],\n",
      "        [1.2131, 1.2131, 1.2378,  ..., 1.9996, 2.0000, 2.0000],\n",
      "        [1.2131, 1.2131, 1.2378,  ..., 1.9996, 2.0000, 2.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 2.0000, 1.9996,  ..., 1.2378, 1.2131, 1.2131],\n",
      "        [2.0000, 2.0000, 1.9996,  ..., 1.2378, 1.2131, 1.2131],\n",
      "        [1.9996, 1.9996, 2.0000,  ..., 1.2625, 1.2378, 1.2378],\n",
      "        ...,\n",
      "        [1.2378, 1.2378, 1.2625,  ..., 2.0000, 1.9996, 1.9996],\n",
      "        [1.2131, 1.2131, 1.2378,  ..., 1.9996, 2.0000, 2.0000],\n",
      "        [1.2131, 1.2131, 1.2378,  ..., 1.9996, 2.0000, 2.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.1000, -0.1000], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.1000], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.9000, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.9000, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.8000, 1.7995, 1.7982,  ..., 1.0201, 0.9955, 0.9709],\n",
      "        [1.7995, 1.8000, 1.7995,  ..., 1.0447, 1.0201, 0.9955],\n",
      "        [1.7982, 1.7995, 1.8000,  ..., 1.0695, 1.0447, 1.0201],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.8000, 1.7995, 1.7982],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.7995, 1.8000, 1.7995],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.7982, 1.7995, 1.8000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.8000, 1.7995, 1.7982,  ..., 1.0201, 0.9955, 0.9709],\n",
      "        [1.7995, 1.8000, 1.7995,  ..., 1.0447, 1.0201, 0.9955],\n",
      "        [1.7982, 1.7995, 1.8000,  ..., 1.0695, 1.0447, 1.0201],\n",
      "        ...,\n",
      "        [1.0201, 1.0447, 1.0695,  ..., 1.8000, 1.7995, 1.7982],\n",
      "        [0.9955, 1.0201, 1.0447,  ..., 1.7995, 1.8000, 1.7995],\n",
      "        [0.9709, 0.9955, 1.0201,  ..., 1.7982, 1.7995, 1.8000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.8000, 1.8000, 1.7995,  ..., 0.9955, 0.9709, 0.9709],\n",
      "        [1.8000, 1.8000, 1.7995,  ..., 0.9955, 0.9709, 0.9709],\n",
      "        [1.7995, 1.7995, 1.8000,  ..., 1.0201, 0.9955, 0.9955],\n",
      "        ...,\n",
      "        [0.9955, 0.9955, 1.0201,  ..., 1.8000, 1.7995, 1.7995],\n",
      "        [0.9709, 0.9709, 0.9955,  ..., 1.7995, 1.8000, 1.8000],\n",
      "        [0.9709, 0.9709, 0.9955,  ..., 1.7995, 1.8000, 1.8000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.8000, 1.8000, 1.7995,  ..., 0.9955, 0.9709, 0.9709],\n",
      "        [1.8000, 1.8000, 1.7995,  ..., 0.9955, 0.9709, 0.9709],\n",
      "        [1.7995, 1.7995, 1.8000,  ..., 1.0201, 0.9955, 0.9955],\n",
      "        ...,\n",
      "        [0.9955, 0.9955, 1.0201,  ..., 1.8000, 1.7995, 1.7995],\n",
      "        [0.9709, 0.9709, 0.9955,  ..., 1.7995, 1.8000, 1.8000],\n",
      "        [0.9709, 0.9709, 0.9955,  ..., 1.7995, 1.8000, 1.8000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.2000, -0.2000], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.2000], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.9210, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.8005, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.8420, 1.8414, 1.8396,  ..., 0.8986, 0.8713, 0.8442],\n",
      "        [1.8414, 1.8420, 1.8414,  ..., 0.9261, 0.8986, 0.8713],\n",
      "        [1.8396, 1.8414, 1.8420,  ..., 0.9539, 0.9261, 0.8986],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.8420, 1.8414, 1.8396],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.8414, 1.8420, 1.8414],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.8396, 1.8414, 1.8420]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.8420, 1.8414, 1.8396,  ..., 0.8986, 0.8713, 0.8442],\n",
      "        [1.8414, 1.8420, 1.8414,  ..., 0.9261, 0.8986, 0.8713],\n",
      "        [1.8396, 1.8414, 1.8420,  ..., 0.9539, 0.9261, 0.8986],\n",
      "        ...,\n",
      "        [0.8986, 0.9261, 0.9539,  ..., 1.8420, 1.8414, 1.8396],\n",
      "        [0.8713, 0.8986, 0.9261,  ..., 1.8414, 1.8420, 1.8414],\n",
      "        [0.8442, 0.8713, 0.8986,  ..., 1.8396, 1.8414, 1.8420]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.8420, 1.8420, 1.8414,  ..., 0.8713, 0.8442, 0.8442],\n",
      "        [1.8420, 1.8420, 1.8414,  ..., 0.8713, 0.8442, 0.8442],\n",
      "        [1.8414, 1.8414, 1.8420,  ..., 0.8986, 0.8713, 0.8713],\n",
      "        ...,\n",
      "        [0.8713, 0.8713, 0.8986,  ..., 1.8420, 1.8414, 1.8414],\n",
      "        [0.8442, 0.8442, 0.8713,  ..., 1.8414, 1.8420, 1.8420],\n",
      "        [0.8442, 0.8442, 0.8713,  ..., 1.8414, 1.8420, 1.8420]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.8420, 1.8420, 1.8414,  ..., 0.8713, 0.8442, 0.8442],\n",
      "        [1.8420, 1.8420, 1.8414,  ..., 0.8713, 0.8442, 0.8442],\n",
      "        [1.8414, 1.8414, 1.8420,  ..., 0.8986, 0.8713, 0.8713],\n",
      "        ...,\n",
      "        [0.8713, 0.8713, 0.8986,  ..., 1.8420, 1.8414, 1.8414],\n",
      "        [0.8442, 0.8442, 0.8713,  ..., 1.8414, 1.8420, 1.8420],\n",
      "        [0.8442, 0.8442, 0.8713,  ..., 1.8414, 1.8420, 1.8420]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.2999, -0.3002], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.3001], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.9849, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.7015, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.9698, 1.9689, 1.9664,  ..., 0.7734, 0.7429, 0.7130],\n",
      "        [1.9689, 1.9698, 1.9689,  ..., 0.8044, 0.7734, 0.7429],\n",
      "        [1.9664, 1.9689, 1.9698,  ..., 0.8360, 0.8044, 0.7734],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.9698, 1.9689, 1.9664],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.9689, 1.9698, 1.9689],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.9664, 1.9689, 1.9698]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.9698, 1.9689, 1.9664,  ..., 0.7734, 0.7429, 0.7130],\n",
      "        [1.9689, 1.9698, 1.9689,  ..., 0.8044, 0.7734, 0.7429],\n",
      "        [1.9664, 1.9689, 1.9698,  ..., 0.8360, 0.8044, 0.7734],\n",
      "        ...,\n",
      "        [0.7734, 0.8044, 0.8360,  ..., 1.9698, 1.9689, 1.9664],\n",
      "        [0.7429, 0.7734, 0.8044,  ..., 1.9689, 1.9698, 1.9689],\n",
      "        [0.7130, 0.7429, 0.7734,  ..., 1.9664, 1.9689, 1.9698]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.9698, 1.9698, 1.9689,  ..., 0.7429, 0.7130, 0.7130],\n",
      "        [1.9698, 1.9698, 1.9689,  ..., 0.7429, 0.7130, 0.7130],\n",
      "        [1.9689, 1.9689, 1.9698,  ..., 0.7734, 0.7429, 0.7429],\n",
      "        ...,\n",
      "        [0.7429, 0.7429, 0.7734,  ..., 1.9698, 1.9689, 1.9689],\n",
      "        [0.7130, 0.7130, 0.7429,  ..., 1.9689, 1.9698, 1.9698],\n",
      "        [0.7130, 0.7130, 0.7429,  ..., 1.9689, 1.9698, 1.9698]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.9698, 1.9698, 1.9689,  ..., 0.7429, 0.7130, 0.7130],\n",
      "        [1.9698, 1.9698, 1.9689,  ..., 0.7429, 0.7130, 0.7130],\n",
      "        [1.9689, 1.9689, 1.9698,  ..., 0.7734, 0.7429, 0.7429],\n",
      "        ...,\n",
      "        [0.7429, 0.7429, 0.7734,  ..., 1.9698, 1.9689, 1.9689],\n",
      "        [0.7130, 0.7130, 0.7429,  ..., 1.9689, 1.9698, 1.9698],\n",
      "        [0.7130, 0.7130, 0.7429,  ..., 1.9689, 1.9698, 1.9698]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.3997, -0.4005], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.4001], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(1.0600, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.6020, requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.1200, 2.1188, 2.1151,  ..., 0.5958, 0.5642, 0.5336],\n",
      "        [2.1188, 2.1200, 2.1188,  ..., 0.6285, 0.5958, 0.5642],\n",
      "        [2.1151, 2.1188, 2.1200,  ..., 0.6622, 0.6285, 0.5958],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.1200, 2.1188, 2.1151],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.1188, 2.1200, 2.1188],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.1151, 2.1188, 2.1200]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.1200, 2.1188, 2.1151,  ..., 0.5958, 0.5642, 0.5336],\n",
      "        [2.1188, 2.1200, 2.1188,  ..., 0.6285, 0.5958, 0.5642],\n",
      "        [2.1151, 2.1188, 2.1200,  ..., 0.6622, 0.6285, 0.5958],\n",
      "        ...,\n",
      "        [0.5958, 0.6285, 0.6622,  ..., 2.1200, 2.1188, 2.1151],\n",
      "        [0.5642, 0.5958, 0.6285,  ..., 2.1188, 2.1200, 2.1188],\n",
      "        [0.5336, 0.5642, 0.5958,  ..., 2.1151, 2.1188, 2.1200]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.1200, 2.1200, 2.1188,  ..., 0.5642, 0.5336, 0.5336],\n",
      "        [2.1200, 2.1200, 2.1188,  ..., 0.5642, 0.5336, 0.5336],\n",
      "        [2.1188, 2.1188, 2.1200,  ..., 0.5958, 0.5642, 0.5642],\n",
      "        ...,\n",
      "        [0.5642, 0.5642, 0.5958,  ..., 2.1200, 2.1188, 2.1188],\n",
      "        [0.5336, 0.5336, 0.5642,  ..., 2.1188, 2.1200, 2.1200],\n",
      "        [0.5336, 0.5336, 0.5642,  ..., 2.1188, 2.1200, 2.1200]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.1200, 2.1200, 2.1188,  ..., 0.5642, 0.5336, 0.5336],\n",
      "        [2.1200, 2.1200, 2.1188,  ..., 0.5642, 0.5336, 0.5336],\n",
      "        [2.1188, 2.1188, 2.1200,  ..., 0.5958, 0.5642, 0.5642],\n",
      "        ...,\n",
      "        [0.5642, 0.5642, 0.5958,  ..., 2.1200, 2.1188, 2.1188],\n",
      "        [0.5336, 0.5336, 0.5642,  ..., 2.1188, 2.1200, 2.1200],\n",
      "        [0.5336, 0.5336, 0.5642,  ..., 2.1188, 2.1200, 2.1200]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.4993, -0.5011], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.5003], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(1.1075, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.5018, requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.2151, 2.2132, 2.2077,  ..., 0.3565, 0.3295, 0.3041],\n",
      "        [2.2132, 2.2151, 2.2132,  ..., 0.3850, 0.3565, 0.3295],\n",
      "        [2.2077, 2.2132, 2.2151,  ..., 0.4151, 0.3850, 0.3565],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.2151, 2.2132, 2.2077],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.2132, 2.2151, 2.2132],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.2077, 2.2132, 2.2151]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.2151, 2.2132, 2.2077,  ..., 0.3565, 0.3295, 0.3041],\n",
      "        [2.2132, 2.2151, 2.2132,  ..., 0.3850, 0.3565, 0.3295],\n",
      "        [2.2077, 2.2132, 2.2151,  ..., 0.4151, 0.3850, 0.3565],\n",
      "        ...,\n",
      "        [0.3565, 0.3850, 0.4151,  ..., 2.2151, 2.2132, 2.2077],\n",
      "        [0.3295, 0.3565, 0.3850,  ..., 2.2132, 2.2151, 2.2132],\n",
      "        [0.3041, 0.3295, 0.3565,  ..., 2.2077, 2.2132, 2.2151]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.2151, 2.2151, 2.2132,  ..., 0.3295, 0.3041, 0.3041],\n",
      "        [2.2151, 2.2151, 2.2132,  ..., 0.3295, 0.3041, 0.3041],\n",
      "        [2.2132, 2.2132, 2.2151,  ..., 0.3565, 0.3295, 0.3295],\n",
      "        ...,\n",
      "        [0.3295, 0.3295, 0.3565,  ..., 2.2151, 2.2132, 2.2132],\n",
      "        [0.3041, 0.3041, 0.3295,  ..., 2.2132, 2.2151, 2.2151],\n",
      "        [0.3041, 0.3041, 0.3295,  ..., 2.2132, 2.2151, 2.2151]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.2151, 2.2151, 2.2132,  ..., 0.3295, 0.3041, 0.3041],\n",
      "        [2.2151, 2.2151, 2.2132,  ..., 0.3295, 0.3041, 0.3041],\n",
      "        [2.2132, 2.2132, 2.2151,  ..., 0.3565, 0.3295, 0.3295],\n",
      "        ...,\n",
      "        [0.3295, 0.3295, 0.3565,  ..., 2.2151, 2.2132, 2.2132],\n",
      "        [0.3041, 0.3041, 0.3295,  ..., 2.2132, 2.2151, 2.2151],\n",
      "        [0.3041, 0.3041, 0.3295,  ..., 2.2132, 2.2151, 2.2151]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.5987, -0.6019], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.6004], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(1.0915, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.4015, requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.1830, 2.1802, 2.1717,  ..., 0.1259, 0.1113, 0.0982],\n",
      "        [2.1802, 2.1830, 2.1802,  ..., 0.1419, 0.1259, 0.1113],\n",
      "        [2.1717, 2.1802, 2.1830,  ..., 0.1596, 0.1419, 0.1259],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.1830, 2.1802, 2.1717],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.1802, 2.1830, 2.1802],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.1717, 2.1802, 2.1830]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.1830, 2.1802, 2.1717,  ..., 0.1259, 0.1113, 0.0982],\n",
      "        [2.1802, 2.1830, 2.1802,  ..., 0.1419, 0.1259, 0.1113],\n",
      "        [2.1717, 2.1802, 2.1830,  ..., 0.1596, 0.1419, 0.1259],\n",
      "        ...,\n",
      "        [0.1259, 0.1419, 0.1596,  ..., 2.1830, 2.1802, 2.1717],\n",
      "        [0.1113, 0.1259, 0.1419,  ..., 2.1802, 2.1830, 2.1802],\n",
      "        [0.0982, 0.1113, 0.1259,  ..., 2.1717, 2.1802, 2.1830]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.1830, 2.1830, 2.1802,  ..., 0.1113, 0.0982, 0.0982],\n",
      "        [2.1830, 2.1830, 2.1802,  ..., 0.1113, 0.0982, 0.0982],\n",
      "        [2.1802, 2.1802, 2.1830,  ..., 0.1259, 0.1113, 0.1113],\n",
      "        ...,\n",
      "        [0.1113, 0.1113, 0.1259,  ..., 2.1830, 2.1802, 2.1802],\n",
      "        [0.0982, 0.0982, 0.1113,  ..., 2.1802, 2.1830, 2.1830],\n",
      "        [0.0982, 0.0982, 0.1113,  ..., 2.1802, 2.1830, 2.1830]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.1830, 2.1830, 2.1802,  ..., 0.1113, 0.0982, 0.0982],\n",
      "        [2.1830, 2.1830, 2.1802,  ..., 0.1113, 0.0982, 0.0982],\n",
      "        [2.1802, 2.1802, 2.1830,  ..., 0.1259, 0.1113, 0.1113],\n",
      "        ...,\n",
      "        [0.1113, 0.1113, 0.1259,  ..., 2.1830, 2.1802, 2.1802],\n",
      "        [0.0982, 0.0982, 0.1113,  ..., 2.1802, 2.1830, 2.1830],\n",
      "        [0.0982, 0.0982, 0.1113,  ..., 2.1802, 2.1830, 2.1830]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.6979, -0.7028], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.7006], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(1.0404, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.3133, requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0807, 2.0763, 2.0631,  ..., 0.0192, 0.0157, 0.0128],\n",
      "        [2.0763, 2.0807, 2.0763,  ..., 0.0234, 0.0192, 0.0157],\n",
      "        [2.0631, 2.0763, 2.0807,  ..., 0.0284, 0.0234, 0.0192],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.0807, 2.0763, 2.0631],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.0763, 2.0807, 2.0763],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.0631, 2.0763, 2.0807]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0807, 2.0763, 2.0631,  ..., 0.0192, 0.0157, 0.0128],\n",
      "        [2.0763, 2.0807, 2.0763,  ..., 0.0234, 0.0192, 0.0157],\n",
      "        [2.0631, 2.0763, 2.0807,  ..., 0.0284, 0.0234, 0.0192],\n",
      "        ...,\n",
      "        [0.0192, 0.0234, 0.0284,  ..., 2.0807, 2.0763, 2.0631],\n",
      "        [0.0157, 0.0192, 0.0234,  ..., 2.0763, 2.0807, 2.0763],\n",
      "        [0.0128, 0.0157, 0.0192,  ..., 2.0631, 2.0763, 2.0807]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0807, 2.0807, 2.0763,  ..., 0.0157, 0.0128, 0.0128],\n",
      "        [2.0807, 2.0807, 2.0763,  ..., 0.0157, 0.0128, 0.0128],\n",
      "        [2.0763, 2.0763, 2.0807,  ..., 0.0192, 0.0157, 0.0157],\n",
      "        ...,\n",
      "        [0.0157, 0.0157, 0.0192,  ..., 2.0807, 2.0763, 2.0763],\n",
      "        [0.0128, 0.0128, 0.0157,  ..., 2.0763, 2.0807, 2.0807],\n",
      "        [0.0128, 0.0128, 0.0157,  ..., 2.0763, 2.0807, 2.0807]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0807, 2.0807, 2.0763,  ..., 0.0157, 0.0128, 0.0128],\n",
      "        [2.0807, 2.0807, 2.0763,  ..., 0.0157, 0.0128, 0.0128],\n",
      "        [2.0763, 2.0763, 2.0807,  ..., 0.0192, 0.0157, 0.0157],\n",
      "        ...,\n",
      "        [0.0157, 0.0157, 0.0192,  ..., 2.0807, 2.0763, 2.0763],\n",
      "        [0.0128, 0.0128, 0.0157,  ..., 2.0763, 2.0807, 2.0807],\n",
      "        [0.0128, 0.0128, 0.0157,  ..., 2.0763, 2.0807, 2.0807]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.7969, -0.8034], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.8004], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.9742, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.2828, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.9485, 1.9434, 1.9283,  ..., 0.0062, 0.0048, 0.0037],\n",
      "        [1.9434, 1.9485, 1.9434,  ..., 0.0079, 0.0062, 0.0048],\n",
      "        [1.9283, 1.9434, 1.9485,  ..., 0.0100, 0.0079, 0.0062],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.9485, 1.9434, 1.9283],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.9434, 1.9485, 1.9434],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.9283, 1.9434, 1.9485]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.9485, 1.9434, 1.9283,  ..., 0.0062, 0.0048, 0.0037],\n",
      "        [1.9434, 1.9485, 1.9434,  ..., 0.0079, 0.0062, 0.0048],\n",
      "        [1.9283, 1.9434, 1.9485,  ..., 0.0100, 0.0079, 0.0062],\n",
      "        ...,\n",
      "        [0.0062, 0.0079, 0.0100,  ..., 1.9485, 1.9434, 1.9283],\n",
      "        [0.0048, 0.0062, 0.0079,  ..., 1.9434, 1.9485, 1.9434],\n",
      "        [0.0037, 0.0048, 0.0062,  ..., 1.9283, 1.9434, 1.9485]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.9485, 1.9485, 1.9434,  ..., 0.0048, 0.0037, 0.0037],\n",
      "        [1.9485, 1.9485, 1.9434,  ..., 0.0048, 0.0037, 0.0037],\n",
      "        [1.9434, 1.9434, 1.9485,  ..., 0.0062, 0.0048, 0.0048],\n",
      "        ...,\n",
      "        [0.0048, 0.0048, 0.0062,  ..., 1.9485, 1.9434, 1.9434],\n",
      "        [0.0037, 0.0037, 0.0048,  ..., 1.9434, 1.9485, 1.9485],\n",
      "        [0.0037, 0.0037, 0.0048,  ..., 1.9434, 1.9485, 1.9485]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.9485, 1.9485, 1.9434,  ..., 0.0048, 0.0037, 0.0037],\n",
      "        [1.9485, 1.9485, 1.9434,  ..., 0.0048, 0.0037, 0.0037],\n",
      "        [1.9434, 1.9434, 1.9485,  ..., 0.0062, 0.0048, 0.0048],\n",
      "        ...,\n",
      "        [0.0048, 0.0048, 0.0062,  ..., 1.9485, 1.9434, 1.9434],\n",
      "        [0.0037, 0.0037, 0.0048,  ..., 1.9434, 1.9485, 1.9485],\n",
      "        [0.0037, 0.0037, 0.0048,  ..., 1.9434, 1.9485, 1.9485]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.8954, -0.9037], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.8999], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.8982, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.2947, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.7965, 1.7922, 1.7793,  ..., 0.0090, 0.0072, 0.0057],\n",
      "        [1.7922, 1.7965, 1.7922,  ..., 0.0113, 0.0090, 0.0072],\n",
      "        [1.7793, 1.7922, 1.7965,  ..., 0.0140, 0.0113, 0.0090],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.7965, 1.7922, 1.7793],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.7922, 1.7965, 1.7922],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.7793, 1.7922, 1.7965]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.7965, 1.7922, 1.7793,  ..., 0.0090, 0.0072, 0.0057],\n",
      "        [1.7922, 1.7965, 1.7922,  ..., 0.0113, 0.0090, 0.0072],\n",
      "        [1.7793, 1.7922, 1.7965,  ..., 0.0140, 0.0113, 0.0090],\n",
      "        ...,\n",
      "        [0.0090, 0.0113, 0.0140,  ..., 1.7965, 1.7922, 1.7793],\n",
      "        [0.0072, 0.0090, 0.0113,  ..., 1.7922, 1.7965, 1.7922],\n",
      "        [0.0057, 0.0072, 0.0090,  ..., 1.7793, 1.7922, 1.7965]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.7965, 1.7965, 1.7922,  ..., 0.0072, 0.0057, 0.0057],\n",
      "        [1.7965, 1.7965, 1.7922,  ..., 0.0072, 0.0057, 0.0057],\n",
      "        [1.7922, 1.7922, 1.7965,  ..., 0.0090, 0.0072, 0.0072],\n",
      "        ...,\n",
      "        [0.0072, 0.0072, 0.0090,  ..., 1.7965, 1.7922, 1.7922],\n",
      "        [0.0057, 0.0057, 0.0072,  ..., 1.7922, 1.7965, 1.7965],\n",
      "        [0.0057, 0.0057, 0.0072,  ..., 1.7922, 1.7965, 1.7965]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.7965, 1.7965, 1.7922,  ..., 0.0072, 0.0057, 0.0057],\n",
      "        [1.7965, 1.7965, 1.7922,  ..., 0.0072, 0.0057, 0.0057],\n",
      "        [1.7922, 1.7922, 1.7965,  ..., 0.0090, 0.0072, 0.0072],\n",
      "        ...,\n",
      "        [0.0072, 0.0072, 0.0090,  ..., 1.7965, 1.7922, 1.7922],\n",
      "        [0.0057, 0.0057, 0.0072,  ..., 1.7922, 1.7965, 1.7965],\n",
      "        [0.0057, 0.0057, 0.0072,  ..., 1.7922, 1.7965, 1.7965]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.9934, -1.0034], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.9988], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.8149, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.3278, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.6297, 1.6266, 1.6172,  ..., 0.0225, 0.0187, 0.0155],\n",
      "        [1.6266, 1.6297, 1.6266,  ..., 0.0270, 0.0225, 0.0187],\n",
      "        [1.6172, 1.6266, 1.6297,  ..., 0.0322, 0.0270, 0.0225],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.6297, 1.6266, 1.6172],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.6266, 1.6297, 1.6266],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.6172, 1.6266, 1.6297]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.6297, 1.6266, 1.6172,  ..., 0.0225, 0.0187, 0.0155],\n",
      "        [1.6266, 1.6297, 1.6266,  ..., 0.0270, 0.0225, 0.0187],\n",
      "        [1.6172, 1.6266, 1.6297,  ..., 0.0322, 0.0270, 0.0225],\n",
      "        ...,\n",
      "        [0.0225, 0.0270, 0.0322,  ..., 1.6297, 1.6266, 1.6172],\n",
      "        [0.0187, 0.0225, 0.0270,  ..., 1.6266, 1.6297, 1.6266],\n",
      "        [0.0155, 0.0187, 0.0225,  ..., 1.6172, 1.6266, 1.6297]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.6297, 1.6297, 1.6266,  ..., 0.0187, 0.0155, 0.0155],\n",
      "        [1.6297, 1.6297, 1.6266,  ..., 0.0187, 0.0155, 0.0155],\n",
      "        [1.6266, 1.6266, 1.6297,  ..., 0.0225, 0.0187, 0.0187],\n",
      "        ...,\n",
      "        [0.0187, 0.0187, 0.0225,  ..., 1.6297, 1.6266, 1.6266],\n",
      "        [0.0155, 0.0155, 0.0187,  ..., 1.6266, 1.6297, 1.6297],\n",
      "        [0.0155, 0.0155, 0.0187,  ..., 1.6266, 1.6297, 1.6297]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.6297, 1.6297, 1.6266,  ..., 0.0187, 0.0155, 0.0155],\n",
      "        [1.6297, 1.6297, 1.6266,  ..., 0.0187, 0.0155, 0.0155],\n",
      "        [1.6266, 1.6266, 1.6297,  ..., 0.0225, 0.0187, 0.0187],\n",
      "        ...,\n",
      "        [0.0187, 0.0187, 0.0225,  ..., 1.6297, 1.6266, 1.6266],\n",
      "        [0.0155, 0.0155, 0.0187,  ..., 1.6266, 1.6297, 1.6297],\n",
      "        [0.0155, 0.0155, 0.0187,  ..., 1.6266, 1.6297, 1.6297]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.0905, -1.1024], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.0969], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.7264, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.3686, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.4529, 1.4507, 1.4440,  ..., 0.0492, 0.0425, 0.0366],\n",
      "        [1.4507, 1.4529, 1.4507,  ..., 0.0567, 0.0492, 0.0425],\n",
      "        [1.4440, 1.4507, 1.4529,  ..., 0.0652, 0.0567, 0.0492],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.4529, 1.4507, 1.4440],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.4507, 1.4529, 1.4507],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.4440, 1.4507, 1.4529]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.4529, 1.4507, 1.4440,  ..., 0.0492, 0.0425, 0.0366],\n",
      "        [1.4507, 1.4529, 1.4507,  ..., 0.0567, 0.0492, 0.0425],\n",
      "        [1.4440, 1.4507, 1.4529,  ..., 0.0652, 0.0567, 0.0492],\n",
      "        ...,\n",
      "        [0.0492, 0.0567, 0.0652,  ..., 1.4529, 1.4507, 1.4440],\n",
      "        [0.0425, 0.0492, 0.0567,  ..., 1.4507, 1.4529, 1.4507],\n",
      "        [0.0366, 0.0425, 0.0492,  ..., 1.4440, 1.4507, 1.4529]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.4529, 1.4529, 1.4507,  ..., 0.0425, 0.0366, 0.0366],\n",
      "        [1.4529, 1.4529, 1.4507,  ..., 0.0425, 0.0366, 0.0366],\n",
      "        [1.4507, 1.4507, 1.4529,  ..., 0.0492, 0.0425, 0.0425],\n",
      "        ...,\n",
      "        [0.0425, 0.0425, 0.0492,  ..., 1.4529, 1.4507, 1.4507],\n",
      "        [0.0366, 0.0366, 0.0425,  ..., 1.4507, 1.4529, 1.4529],\n",
      "        [0.0366, 0.0366, 0.0425,  ..., 1.4507, 1.4529, 1.4529]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.4529, 1.4529, 1.4507,  ..., 0.0425, 0.0366, 0.0366],\n",
      "        [1.4529, 1.4529, 1.4507,  ..., 0.0425, 0.0366, 0.0366],\n",
      "        [1.4507, 1.4507, 1.4529,  ..., 0.0492, 0.0425, 0.0425],\n",
      "        ...,\n",
      "        [0.0425, 0.0425, 0.0492,  ..., 1.4529, 1.4507, 1.4507],\n",
      "        [0.0366, 0.0366, 0.0425,  ..., 1.4507, 1.4529, 1.4529],\n",
      "        [0.0366, 0.0366, 0.0425,  ..., 1.4507, 1.4529, 1.4529]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.1863, -1.2004], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.1939], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.6361, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.4038, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.2722, 1.2706, 1.2657,  ..., 0.0758, 0.0671, 0.0593],\n",
      "        [1.2706, 1.2722, 1.2706,  ..., 0.0853, 0.0758, 0.0671],\n",
      "        [1.2657, 1.2706, 1.2722,  ..., 0.0958, 0.0853, 0.0758],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2722, 1.2706, 1.2657],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2706, 1.2722, 1.2706],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.2657, 1.2706, 1.2722]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.2722, 1.2706, 1.2657,  ..., 0.0758, 0.0671, 0.0593],\n",
      "        [1.2706, 1.2722, 1.2706,  ..., 0.0853, 0.0758, 0.0671],\n",
      "        [1.2657, 1.2706, 1.2722,  ..., 0.0958, 0.0853, 0.0758],\n",
      "        ...,\n",
      "        [0.0758, 0.0853, 0.0958,  ..., 1.2722, 1.2706, 1.2657],\n",
      "        [0.0671, 0.0758, 0.0853,  ..., 1.2706, 1.2722, 1.2706],\n",
      "        [0.0593, 0.0671, 0.0758,  ..., 1.2657, 1.2706, 1.2722]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.2722, 1.2722, 1.2706,  ..., 0.0671, 0.0593, 0.0593],\n",
      "        [1.2722, 1.2722, 1.2706,  ..., 0.0671, 0.0593, 0.0593],\n",
      "        [1.2706, 1.2706, 1.2722,  ..., 0.0758, 0.0671, 0.0671],\n",
      "        ...,\n",
      "        [0.0671, 0.0671, 0.0758,  ..., 1.2722, 1.2706, 1.2706],\n",
      "        [0.0593, 0.0593, 0.0671,  ..., 1.2706, 1.2722, 1.2722],\n",
      "        [0.0593, 0.0593, 0.0671,  ..., 1.2706, 1.2722, 1.2722]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.2722, 1.2722, 1.2706,  ..., 0.0671, 0.0593, 0.0593],\n",
      "        [1.2722, 1.2722, 1.2706,  ..., 0.0671, 0.0593, 0.0593],\n",
      "        [1.2706, 1.2706, 1.2722,  ..., 0.0758, 0.0671, 0.0671],\n",
      "        ...,\n",
      "        [0.0671, 0.0671, 0.0758,  ..., 1.2722, 1.2706, 1.2706],\n",
      "        [0.0593, 0.0593, 0.0671,  ..., 1.2706, 1.2722, 1.2722],\n",
      "        [0.0593, 0.0593, 0.0671,  ..., 1.2706, 1.2722, 1.2722]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.2806, -1.2972], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.2895], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.5490, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.4215, requires_grad=True))\n",
      "Result:\n",
      "tensor([[1.0980, 1.0967, 1.0929,  ..., 0.0825, 0.0738, 0.0658],\n",
      "        [1.0967, 1.0980, 1.0967,  ..., 0.0920, 0.0825, 0.0738],\n",
      "        [1.0929, 1.0967, 1.0980,  ..., 0.1023, 0.0920, 0.0825],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0980, 1.0967, 1.0929],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0967, 1.0980, 1.0967],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0929, 1.0967, 1.0980]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[1.0980, 1.0967, 1.0929,  ..., 0.0825, 0.0738, 0.0658],\n",
      "        [1.0967, 1.0980, 1.0967,  ..., 0.0920, 0.0825, 0.0738],\n",
      "        [1.0929, 1.0967, 1.0980,  ..., 0.1023, 0.0920, 0.0825],\n",
      "        ...,\n",
      "        [0.0825, 0.0920, 0.1023,  ..., 1.0980, 1.0967, 1.0929],\n",
      "        [0.0738, 0.0825, 0.0920,  ..., 1.0967, 1.0980, 1.0967],\n",
      "        [0.0658, 0.0738, 0.0825,  ..., 1.0929, 1.0967, 1.0980]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[1.0980, 1.0980, 1.0967,  ..., 0.0738, 0.0658, 0.0658],\n",
      "        [1.0980, 1.0980, 1.0967,  ..., 0.0738, 0.0658, 0.0658],\n",
      "        [1.0967, 1.0967, 1.0980,  ..., 0.0825, 0.0738, 0.0738],\n",
      "        ...,\n",
      "        [0.0738, 0.0738, 0.0825,  ..., 1.0980, 1.0967, 1.0967],\n",
      "        [0.0658, 0.0658, 0.0738,  ..., 1.0967, 1.0980, 1.0980],\n",
      "        [0.0658, 0.0658, 0.0738,  ..., 1.0967, 1.0980, 1.0980]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[1.0980, 1.0980, 1.0967,  ..., 0.0738, 0.0658, 0.0658],\n",
      "        [1.0980, 1.0980, 1.0967,  ..., 0.0738, 0.0658, 0.0658],\n",
      "        [1.0967, 1.0967, 1.0980,  ..., 0.0825, 0.0738, 0.0738],\n",
      "        ...,\n",
      "        [0.0738, 0.0738, 0.0825,  ..., 1.0980, 1.0967, 1.0967],\n",
      "        [0.0658, 0.0658, 0.0738,  ..., 1.0967, 1.0980, 1.0980],\n",
      "        [0.0658, 0.0658, 0.0738,  ..., 1.0967, 1.0980, 1.0980]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.3725, -1.3922], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.3830], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.4720, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.4173, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.9440, 0.9429, 0.9395,  ..., 0.0672, 0.0600, 0.0534],\n",
      "        [0.9429, 0.9440, 0.9429,  ..., 0.0751, 0.0672, 0.0600],\n",
      "        [0.9395, 0.9429, 0.9440,  ..., 0.0838, 0.0751, 0.0672],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9440, 0.9429, 0.9395],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9429, 0.9440, 0.9429],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9395, 0.9429, 0.9440]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.9440, 0.9429, 0.9395,  ..., 0.0672, 0.0600, 0.0534],\n",
      "        [0.9429, 0.9440, 0.9429,  ..., 0.0751, 0.0672, 0.0600],\n",
      "        [0.9395, 0.9429, 0.9440,  ..., 0.0838, 0.0751, 0.0672],\n",
      "        ...,\n",
      "        [0.0672, 0.0751, 0.0838,  ..., 0.9440, 0.9429, 0.9395],\n",
      "        [0.0600, 0.0672, 0.0751,  ..., 0.9429, 0.9440, 0.9429],\n",
      "        [0.0534, 0.0600, 0.0672,  ..., 0.9395, 0.9429, 0.9440]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[0.9440, 0.9440, 0.9429,  ..., 0.0600, 0.0534, 0.0534],\n",
      "        [0.9440, 0.9440, 0.9429,  ..., 0.0600, 0.0534, 0.0534],\n",
      "        [0.9429, 0.9429, 0.9440,  ..., 0.0672, 0.0600, 0.0600],\n",
      "        ...,\n",
      "        [0.0600, 0.0600, 0.0672,  ..., 0.9440, 0.9429, 0.9429],\n",
      "        [0.0534, 0.0534, 0.0600,  ..., 0.9429, 0.9440, 0.9440],\n",
      "        [0.0534, 0.0534, 0.0600,  ..., 0.9429, 0.9440, 0.9440]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.9440, 0.9440, 0.9429,  ..., 0.0600, 0.0534, 0.0534],\n",
      "        [0.9440, 0.9440, 0.9429,  ..., 0.0600, 0.0534, 0.0534],\n",
      "        [0.9429, 0.9429, 0.9440,  ..., 0.0672, 0.0600, 0.0600],\n",
      "        ...,\n",
      "        [0.0600, 0.0600, 0.0672,  ..., 0.9440, 0.9429, 0.9429],\n",
      "        [0.0534, 0.0534, 0.0600,  ..., 0.9429, 0.9440, 0.9440],\n",
      "        [0.0534, 0.0534, 0.0600,  ..., 0.9429, 0.9440, 0.9440]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.4616, -1.4850], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.4740], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.4105, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.3933, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.8211, 0.8200, 0.8167,  ..., 0.0419, 0.0369, 0.0324],\n",
      "        [0.8200, 0.8211, 0.8200,  ..., 0.0475, 0.0419, 0.0369],\n",
      "        [0.8167, 0.8200, 0.8211,  ..., 0.0537, 0.0475, 0.0419],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8211, 0.8200, 0.8167],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8200, 0.8211, 0.8200],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.8167, 0.8200, 0.8211]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.8211, 0.8200, 0.8167,  ..., 0.0419, 0.0369, 0.0324],\n",
      "        [0.8200, 0.8211, 0.8200,  ..., 0.0475, 0.0419, 0.0369],\n",
      "        [0.8167, 0.8200, 0.8211,  ..., 0.0537, 0.0475, 0.0419],\n",
      "        ...,\n",
      "        [0.0419, 0.0475, 0.0537,  ..., 0.8211, 0.8200, 0.8167],\n",
      "        [0.0369, 0.0419, 0.0475,  ..., 0.8200, 0.8211, 0.8200],\n",
      "        [0.0324, 0.0369, 0.0419,  ..., 0.8167, 0.8200, 0.8211]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[0.8211, 0.8211, 0.8200,  ..., 0.0369, 0.0324, 0.0324],\n",
      "        [0.8211, 0.8211, 0.8200,  ..., 0.0369, 0.0324, 0.0324],\n",
      "        [0.8200, 0.8200, 0.8211,  ..., 0.0419, 0.0369, 0.0369],\n",
      "        ...,\n",
      "        [0.0369, 0.0369, 0.0419,  ..., 0.8211, 0.8200, 0.8200],\n",
      "        [0.0324, 0.0324, 0.0369,  ..., 0.8200, 0.8211, 0.8211],\n",
      "        [0.0324, 0.0324, 0.0369,  ..., 0.8200, 0.8211, 0.8211]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.8211, 0.8211, 0.8200,  ..., 0.0369, 0.0324, 0.0324],\n",
      "        [0.8211, 0.8211, 0.8200,  ..., 0.0369, 0.0324, 0.0324],\n",
      "        [0.8200, 0.8200, 0.8211,  ..., 0.0419, 0.0369, 0.0369],\n",
      "        ...,\n",
      "        [0.0369, 0.0369, 0.0419,  ..., 0.8211, 0.8200, 0.8200],\n",
      "        [0.0324, 0.0324, 0.0369,  ..., 0.8200, 0.8211, 0.8211],\n",
      "        [0.0324, 0.0324, 0.0369,  ..., 0.8200, 0.8211, 0.8211]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.5473, -1.5749], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.5619], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.3631, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.3547, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.7263, 0.7251, 0.7215,  ..., 0.0188, 0.0160, 0.0137],\n",
      "        [0.7251, 0.7263, 0.7251,  ..., 0.0219, 0.0188, 0.0160],\n",
      "        [0.7215, 0.7251, 0.7263,  ..., 0.0254, 0.0219, 0.0188],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7263, 0.7251, 0.7215],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7251, 0.7263, 0.7251],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7215, 0.7251, 0.7263]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.7263, 0.7251, 0.7215,  ..., 0.0188, 0.0160, 0.0137],\n",
      "        [0.7251, 0.7263, 0.7251,  ..., 0.0219, 0.0188, 0.0160],\n",
      "        [0.7215, 0.7251, 0.7263,  ..., 0.0254, 0.0219, 0.0188],\n",
      "        ...,\n",
      "        [0.0188, 0.0219, 0.0254,  ..., 0.7263, 0.7251, 0.7215],\n",
      "        [0.0160, 0.0188, 0.0219,  ..., 0.7251, 0.7263, 0.7251],\n",
      "        [0.0137, 0.0160, 0.0188,  ..., 0.7215, 0.7251, 0.7263]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[0.7263, 0.7263, 0.7251,  ..., 0.0160, 0.0137, 0.0137],\n",
      "        [0.7263, 0.7263, 0.7251,  ..., 0.0160, 0.0137, 0.0137],\n",
      "        [0.7251, 0.7251, 0.7263,  ..., 0.0188, 0.0160, 0.0160],\n",
      "        ...,\n",
      "        [0.0160, 0.0160, 0.0188,  ..., 0.7263, 0.7251, 0.7251],\n",
      "        [0.0137, 0.0137, 0.0160,  ..., 0.7251, 0.7263, 0.7263],\n",
      "        [0.0137, 0.0137, 0.0160,  ..., 0.7251, 0.7263, 0.7263]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.7263, 0.7263, 0.7251,  ..., 0.0160, 0.0137, 0.0137],\n",
      "        [0.7263, 0.7263, 0.7251,  ..., 0.0160, 0.0137, 0.0137],\n",
      "        [0.7251, 0.7251, 0.7263,  ..., 0.0188, 0.0160, 0.0160],\n",
      "        ...,\n",
      "        [0.0160, 0.0160, 0.0188,  ..., 0.7263, 0.7251, 0.7251],\n",
      "        [0.0137, 0.0137, 0.0160,  ..., 0.7251, 0.7263, 0.7263],\n",
      "        [0.0137, 0.0137, 0.0160,  ..., 0.7251, 0.7263, 0.7263]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.6289, -1.6611], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.6459], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.3189, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.3089, requires_grad=True))\n",
      "Result:\n",
      "tensor([[0.6378, 0.6364, 0.6322,  ..., 0.0051, 0.0042, 0.0034],\n",
      "        [0.6364, 0.6378, 0.6364,  ..., 0.0063, 0.0051, 0.0042],\n",
      "        [0.6322, 0.6364, 0.6378,  ..., 0.0077, 0.0063, 0.0051],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6378, 0.6364, 0.6322],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6364, 0.6378, 0.6364],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6322, 0.6364, 0.6378]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[0.6378, 0.6364, 0.6322,  ..., 0.0051, 0.0042, 0.0034],\n",
      "        [0.6364, 0.6378, 0.6364,  ..., 0.0063, 0.0051, 0.0042],\n",
      "        [0.6322, 0.6364, 0.6378,  ..., 0.0077, 0.0063, 0.0051],\n",
      "        ...,\n",
      "        [0.0051, 0.0063, 0.0077,  ..., 0.6378, 0.6364, 0.6322],\n",
      "        [0.0042, 0.0051, 0.0063,  ..., 0.6364, 0.6378, 0.6364],\n",
      "        [0.0034, 0.0042, 0.0051,  ..., 0.6322, 0.6364, 0.6378]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[0.6378, 0.6378, 0.6364,  ..., 0.0042, 0.0034, 0.0034],\n",
      "        [0.6378, 0.6378, 0.6364,  ..., 0.0042, 0.0034, 0.0034],\n",
      "        [0.6364, 0.6364, 0.6378,  ..., 0.0051, 0.0042, 0.0042],\n",
      "        ...,\n",
      "        [0.0042, 0.0042, 0.0051,  ..., 0.6378, 0.6364, 0.6364],\n",
      "        [0.0034, 0.0034, 0.0042,  ..., 0.6364, 0.6378, 0.6378],\n",
      "        [0.0034, 0.0034, 0.0042,  ..., 0.6364, 0.6378, 0.6378]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.6378, 0.6378, 0.6364,  ..., 0.0042, 0.0034, 0.0034],\n",
      "        [0.6378, 0.6378, 0.6364,  ..., 0.0042, 0.0034, 0.0034],\n",
      "        [0.6364, 0.6364, 0.6378,  ..., 0.0051, 0.0042, 0.0042],\n",
      "        ...,\n",
      "        [0.0042, 0.0042, 0.0051,  ..., 0.6378, 0.6364, 0.6364],\n",
      "        [0.0034, 0.0034, 0.0042,  ..., 0.6364, 0.6378, 0.6378],\n",
      "        [0.0034, 0.0034, 0.0042,  ..., 0.6364, 0.6378, 0.6378]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.7057, -1.7426], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.7251], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.2638, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.2661, requires_grad=True))\n",
      "Result:\n",
      "tensor([[5.2756e-01, 5.2601e-01, 5.2139e-01,  ..., 7.9733e-04, 6.0302e-04,\n",
      "         4.5340e-04],\n",
      "        [5.2601e-01, 5.2756e-01, 5.2601e-01,  ..., 1.0481e-03, 7.9733e-04,\n",
      "         6.0302e-04],\n",
      "        [5.2139e-01, 5.2601e-01, 5.2756e-01,  ..., 1.3696e-03, 1.0481e-03,\n",
      "         7.9733e-04],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.2756e-01, 5.2601e-01,\n",
      "         5.2139e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.2601e-01, 5.2756e-01,\n",
      "         5.2601e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.2139e-01, 5.2601e-01,\n",
      "         5.2756e-01]], grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[5.2756e-01, 5.2601e-01, 5.2139e-01,  ..., 7.9733e-04, 6.0302e-04,\n",
      "         4.5340e-04],\n",
      "        [5.2601e-01, 5.2756e-01, 5.2601e-01,  ..., 1.0481e-03, 7.9733e-04,\n",
      "         6.0302e-04],\n",
      "        [5.2139e-01, 5.2601e-01, 5.2756e-01,  ..., 1.3696e-03, 1.0481e-03,\n",
      "         7.9733e-04],\n",
      "        ...,\n",
      "        [7.9733e-04, 1.0481e-03, 1.3696e-03,  ..., 5.2756e-01, 5.2601e-01,\n",
      "         5.2139e-01],\n",
      "        [6.0302e-04, 7.9733e-04, 1.0481e-03,  ..., 5.2601e-01, 5.2756e-01,\n",
      "         5.2601e-01],\n",
      "        [4.5340e-04, 6.0302e-04, 7.9733e-04,  ..., 5.2139e-01, 5.2601e-01,\n",
      "         5.2756e-01]], grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[5.2756e-01, 5.2756e-01, 5.2601e-01,  ..., 6.0302e-04, 4.5340e-04,\n",
      "         4.5340e-04],\n",
      "        [5.2756e-01, 5.2756e-01, 5.2601e-01,  ..., 6.0302e-04, 4.5340e-04,\n",
      "         4.5340e-04],\n",
      "        [5.2601e-01, 5.2601e-01, 5.2756e-01,  ..., 7.9733e-04, 6.0302e-04,\n",
      "         6.0302e-04],\n",
      "        ...,\n",
      "        [6.0302e-04, 6.0302e-04, 7.9733e-04,  ..., 5.2756e-01, 5.2601e-01,\n",
      "         5.2601e-01],\n",
      "        [4.5340e-04, 4.5340e-04, 6.0302e-04,  ..., 5.2601e-01, 5.2756e-01,\n",
      "         5.2756e-01],\n",
      "        [4.5340e-04, 4.5340e-04, 6.0302e-04,  ..., 5.2601e-01, 5.2756e-01,\n",
      "         5.2756e-01]], grad_fn=<CatBackward>)\n",
      "tensor([[5.2756e-01, 5.2756e-01, 5.2601e-01,  ..., 6.0302e-04, 4.5340e-04,\n",
      "         4.5340e-04],\n",
      "        [5.2756e-01, 5.2756e-01, 5.2601e-01,  ..., 6.0302e-04, 4.5340e-04,\n",
      "         4.5340e-04],\n",
      "        [5.2601e-01, 5.2601e-01, 5.2756e-01,  ..., 7.9733e-04, 6.0302e-04,\n",
      "         6.0302e-04],\n",
      "        ...,\n",
      "        [6.0302e-04, 6.0302e-04, 7.9733e-04,  ..., 5.2756e-01, 5.2601e-01,\n",
      "         5.2601e-01],\n",
      "        [4.5340e-04, 4.5340e-04, 6.0302e-04,  ..., 5.2601e-01, 5.2756e-01,\n",
      "         5.2756e-01],\n",
      "        [4.5340e-04, 4.5340e-04, 6.0302e-04,  ..., 5.2601e-01, 5.2756e-01,\n",
      "         5.2756e-01]], grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.7765, -1.8182], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.7984], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.1941, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.2366, requires_grad=True))\n",
      "Result:\n",
      "tensor([[3.8825e-01, 3.8681e-01, 3.8252e-01,  ..., 1.0469e-04, 7.3519e-05,\n",
      "         5.1247e-05],\n",
      "        [3.8681e-01, 3.8825e-01, 3.8681e-01,  ..., 1.4797e-04, 1.0469e-04,\n",
      "         7.3519e-05],\n",
      "        [3.8252e-01, 3.8681e-01, 3.8825e-01,  ..., 2.0759e-04, 1.4797e-04,\n",
      "         1.0469e-04],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.8825e-01, 3.8681e-01,\n",
      "         3.8252e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.8681e-01, 3.8825e-01,\n",
      "         3.8681e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.8252e-01, 3.8681e-01,\n",
      "         3.8825e-01]], grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[3.8825e-01, 3.8681e-01, 3.8252e-01,  ..., 1.0469e-04, 7.3519e-05,\n",
      "         5.1247e-05],\n",
      "        [3.8681e-01, 3.8825e-01, 3.8681e-01,  ..., 1.4797e-04, 1.0469e-04,\n",
      "         7.3519e-05],\n",
      "        [3.8252e-01, 3.8681e-01, 3.8825e-01,  ..., 2.0759e-04, 1.4797e-04,\n",
      "         1.0469e-04],\n",
      "        ...,\n",
      "        [1.0469e-04, 1.4797e-04, 2.0759e-04,  ..., 3.8825e-01, 3.8681e-01,\n",
      "         3.8252e-01],\n",
      "        [7.3519e-05, 1.0469e-04, 1.4797e-04,  ..., 3.8681e-01, 3.8825e-01,\n",
      "         3.8681e-01],\n",
      "        [5.1247e-05, 7.3519e-05, 1.0469e-04,  ..., 3.8252e-01, 3.8681e-01,\n",
      "         3.8825e-01]], grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[3.8825e-01, 3.8825e-01, 3.8681e-01,  ..., 7.3519e-05, 5.1247e-05,\n",
      "         5.1247e-05],\n",
      "        [3.8825e-01, 3.8825e-01, 3.8681e-01,  ..., 7.3519e-05, 5.1247e-05,\n",
      "         5.1247e-05],\n",
      "        [3.8681e-01, 3.8681e-01, 3.8825e-01,  ..., 1.0469e-04, 7.3519e-05,\n",
      "         7.3519e-05],\n",
      "        ...,\n",
      "        [7.3519e-05, 7.3519e-05, 1.0469e-04,  ..., 3.8825e-01, 3.8681e-01,\n",
      "         3.8681e-01],\n",
      "        [5.1247e-05, 5.1247e-05, 7.3519e-05,  ..., 3.8681e-01, 3.8825e-01,\n",
      "         3.8825e-01],\n",
      "        [5.1247e-05, 5.1247e-05, 7.3519e-05,  ..., 3.8681e-01, 3.8825e-01,\n",
      "         3.8825e-01]], grad_fn=<CatBackward>)\n",
      "tensor([[3.8825e-01, 3.8825e-01, 3.8681e-01,  ..., 7.3519e-05, 5.1247e-05,\n",
      "         5.1247e-05],\n",
      "        [3.8825e-01, 3.8825e-01, 3.8681e-01,  ..., 7.3519e-05, 5.1247e-05,\n",
      "         5.1247e-05],\n",
      "        [3.8681e-01, 3.8681e-01, 3.8825e-01,  ..., 1.0469e-04, 7.3519e-05,\n",
      "         7.3519e-05],\n",
      "        ...,\n",
      "        [7.3519e-05, 7.3519e-05, 1.0469e-04,  ..., 3.8825e-01, 3.8681e-01,\n",
      "         3.8681e-01],\n",
      "        [5.1247e-05, 5.1247e-05, 7.3519e-05,  ..., 3.8681e-01, 3.8825e-01,\n",
      "         3.8825e-01],\n",
      "        [5.1247e-05, 5.1247e-05, 7.3519e-05,  ..., 3.8681e-01, 3.8825e-01,\n",
      "         3.8825e-01]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(20)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    for parameter in model.named_parameters():\n",
    "        print(parameter)\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75730997",
   "metadata": {},
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.8404, -1.8868], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.8648], requires_grad=True))\n",
      "('covar_module.11503130320.var', Parameter containing:\n",
      "tensor(0.1134, requires_grad=True))\n",
      "('covar_module.11503130320.length', Parameter containing:\n",
      "tensor(0.2223, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "tensor([[2.2682e-01, 2.2586e-01, 2.2302e-01,  ..., 2.0524e-05, 1.3752e-05,\n",
      "         9.1375e-06],\n",
      "        [2.2586e-01, 2.2682e-01, 2.2586e-01,  ..., 3.0374e-05, 2.0524e-05,\n",
      "         1.3752e-05],\n",
      "        [2.2302e-01, 2.2586e-01, 2.2682e-01,  ..., 4.4572e-05, 3.0374e-05,\n",
      "         2.0524e-05],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2682e-01, 2.2586e-01,\n",
      "         2.2302e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2586e-01, 2.2682e-01,\n",
      "         2.2586e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2302e-01, 2.2586e-01,\n",
      "         2.2682e-01]])\n",
      "Symmetric result:\n",
      "tensor([[2.2682e-01, 2.2586e-01, 2.2302e-01,  ..., 2.0524e-05, 1.3752e-05,\n",
      "         9.1375e-06],\n",
      "        [2.2586e-01, 2.2682e-01, 2.2586e-01,  ..., 3.0374e-05, 2.0524e-05,\n",
      "         1.3752e-05],\n",
      "        [2.2302e-01, 2.2586e-01, 2.2682e-01,  ..., 4.4572e-05, 3.0374e-05,\n",
      "         2.0524e-05],\n",
      "        ...,\n",
      "        [2.0524e-05, 3.0374e-05, 4.4572e-05,  ..., 2.2682e-01, 2.2586e-01,\n",
      "         2.2302e-01],\n",
      "        [1.3752e-05, 2.0524e-05, 3.0374e-05,  ..., 2.2586e-01, 2.2682e-01,\n",
      "         2.2586e-01],\n",
      "        [9.1375e-06, 1.3752e-05, 2.0524e-05,  ..., 2.2302e-01, 2.2586e-01,\n",
      "         2.2682e-01]])\n",
      "Interleaved result:\n",
      "tensor([[2.2682e-01, 2.2682e-01, 2.2586e-01,  ..., 1.3752e-05, 9.1375e-06,\n",
      "         9.1375e-06],\n",
      "        [2.2682e-01, 2.2682e-01, 2.2586e-01,  ..., 1.3752e-05, 9.1375e-06,\n",
      "         9.1375e-06],\n",
      "        [2.2586e-01, 2.2586e-01, 2.2682e-01,  ..., 2.0524e-05, 1.3752e-05,\n",
      "         1.3752e-05],\n",
      "        ...,\n",
      "        [1.3752e-05, 1.3752e-05, 2.0524e-05,  ..., 2.2682e-01, 2.2586e-01,\n",
      "         2.2586e-01],\n",
      "        [9.1375e-06, 9.1375e-06, 1.3752e-05,  ..., 2.2586e-01, 2.2682e-01,\n",
      "         2.2682e-01],\n",
      "        [9.1375e-06, 9.1375e-06, 1.3752e-05,  ..., 2.2586e-01, 2.2682e-01,\n",
      "         2.2682e-01]])\n",
      "tensor([[2.2682e-01, 2.2682e-01, 2.2586e-01,  ..., 1.3752e-05, 9.1375e-06,\n",
      "         9.1375e-06],\n",
      "        [2.2682e-01, 2.2682e-01, 2.2586e-01,  ..., 1.3752e-05, 9.1375e-06,\n",
      "         9.1375e-06],\n",
      "        [2.2586e-01, 2.2586e-01, 2.2682e-01,  ..., 2.0524e-05, 1.3752e-05,\n",
      "         1.3752e-05],\n",
      "        ...,\n",
      "        [1.3752e-05, 1.3752e-05, 2.0524e-05,  ..., 2.2682e-01, 2.2586e-01,\n",
      "         2.2586e-01],\n",
      "        [9.1375e-06, 9.1375e-06, 1.3752e-05,  ..., 2.2586e-01, 2.2682e-01,\n",
      "         2.2682e-01],\n",
      "        [9.1375e-06, 9.1375e-06, 1.3752e-05,  ..., 2.2586e-01, 2.2682e-01,\n",
      "         2.2682e-01]])\n",
      "Result:\n",
      "tensor([[2.2682e-01, 2.2586e-01, 2.2302e-01,  ..., 1.5207e-17, 3.0654e-18,\n",
      "         5.9743e-19],\n",
      "        [2.2586e-01, 2.2682e-01, 2.2586e-01,  ..., 3.3446e-17, 6.8565e-18,\n",
      "         1.3590e-18],\n",
      "        [2.2302e-01, 2.2586e-01, 2.2682e-01,  ..., 7.2941e-17, 1.5207e-17,\n",
      "         3.0655e-18],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2682e-01, 2.2302e-01,\n",
      "         2.1202e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2302e-01, 2.2682e-01,\n",
      "         2.2302e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1202e-01, 2.2302e-01,\n",
      "         2.2682e-01]])\n",
      "Symmetric result:\n",
      "tensor([[2.2682e-01, 2.2586e-01, 2.2302e-01,  ..., 1.5207e-17, 3.0654e-18,\n",
      "         5.9743e-19],\n",
      "        [2.2586e-01, 2.2682e-01, 2.2586e-01,  ..., 3.3446e-17, 6.8565e-18,\n",
      "         1.3590e-18],\n",
      "        [2.2302e-01, 2.2586e-01, 2.2682e-01,  ..., 7.2941e-17, 1.5207e-17,\n",
      "         3.0655e-18],\n",
      "        ...,\n",
      "        [1.5207e-17, 3.3446e-17, 7.2941e-17,  ..., 2.2682e-01, 2.2302e-01,\n",
      "         2.1202e-01],\n",
      "        [3.0654e-18, 6.8565e-18, 1.5207e-17,  ..., 2.2302e-01, 2.2682e-01,\n",
      "         2.2302e-01],\n",
      "        [5.9743e-19, 1.3590e-18, 3.0655e-18,  ..., 2.1202e-01, 2.2302e-01,\n",
      "         2.2682e-01]])\n",
      "Interleaved result:\n",
      "tensor([[2.2682e-01, 2.2682e-01, 2.2586e-01,  ..., 3.0654e-18, 5.9743e-19,\n",
      "         5.9743e-19],\n",
      "        [2.2682e-01, 2.2682e-01, 2.2586e-01,  ..., 3.0654e-18, 5.9743e-19,\n",
      "         5.9743e-19],\n",
      "        [2.2586e-01, 2.2586e-01, 2.2682e-01,  ..., 6.8565e-18, 1.3590e-18,\n",
      "         1.3590e-18],\n",
      "        ...,\n",
      "        [3.0654e-18, 3.0654e-18, 6.8565e-18,  ..., 2.2682e-01, 2.2302e-01,\n",
      "         2.2302e-01],\n",
      "        [5.9743e-19, 5.9743e-19, 1.3590e-18,  ..., 2.2302e-01, 2.2682e-01,\n",
      "         2.2682e-01],\n",
      "        [5.9743e-19, 5.9743e-19, 1.3590e-18,  ..., 2.2302e-01, 2.2682e-01,\n",
      "         2.2682e-01]])\n",
      "tensor([[2.2682e-01, 2.2682e-01, 2.2586e-01,  ..., 3.0654e-18, 5.9743e-19,\n",
      "         5.9743e-19],\n",
      "        [2.2682e-01, 2.2682e-01, 2.2586e-01,  ..., 3.0654e-18, 5.9743e-19,\n",
      "         5.9743e-19],\n",
      "        [2.2586e-01, 2.2586e-01, 2.2682e-01,  ..., 6.8565e-18, 1.3590e-18,\n",
      "         1.3590e-18],\n",
      "        ...,\n",
      "        [3.0654e-18, 3.0654e-18, 6.8565e-18,  ..., 2.2682e-01, 2.2302e-01,\n",
      "         2.2302e-01],\n",
      "        [5.9743e-19, 5.9743e-19, 1.3590e-18,  ..., 2.2302e-01, 2.2682e-01,\n",
      "         2.2682e-01],\n",
      "        [5.9743e-19, 5.9743e-19, 1.3590e-18,  ..., 2.2302e-01, 2.2682e-01,\n",
      "         2.2682e-01]])\n"
     ]
    }
   ],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(50)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(0), float(2), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a03a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Observed Values (Likelihood)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(3)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-3, 8])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-3, 8])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b432934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0, -0.4060058497098381],\n",
       " [0.0, 1.0, 0.0],\n",
       " [-0.4060058497098381, 0.0, 1.0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = float(SE.diff(x2).diff(x1)(int(v1), int(v2), lengthscale, variance))\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sigma^2, e^(-1/2*(x1 - x2)^2/l^2)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.6065, -0.1353],\n",
       "        [-0.6065,  1.0000,  0.6065],\n",
       "        [-0.6767, -0.6065,  1.0000]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1 \n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "left_poly = dx2\n",
    "right_poly = 1\n",
    "diffed_kernel2 = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate() + diffed_kernel2(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[l_11 l_12 l_13]\n",
      "[l_21 l_22 l_23]\n",
      "[l_31 l_32 l_33]\n",
      "[m_11 m_12 m_13]\n",
      "[m_21 m_22 m_23]\n",
      "[m_31 m_32 m_33]\n",
      "[r_11 r_12 r_13]\n",
      "[r_21 r_22 r_23]\n",
      "[r_31 r_32 r_33]\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_11 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_21 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_31\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_12 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_22 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_32\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_13 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_23 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_33\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_11 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_21 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_31\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_12 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_22 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_32\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_13 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_23 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_33\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_11 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_21 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_31\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_12 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_22 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_32\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_13 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_23 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_33\n",
      "\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_11 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_21 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_12 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_22 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_13 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_23 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_33\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_11 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_21 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_12 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_22 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_13 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_23 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_33\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_11 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_21 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_12 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_22 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_13 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_23 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff_sage(L, M, R, context=None):\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "        map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    # Every row in 'M' is combined with each elem of the row given in 'R'\n",
    "    # Or: For each elemtn in row 'R' combine with 'row_M'\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        # Each element in L gets exactly one element in 'row_M' to multiply\n",
    "        # Or: Combine each element in row_M with exactly one element in 'L'\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp = m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp = m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp = m_elem.diff(l_elem)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp += m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp += m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp += m_elem.diff(l_elem)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "    return temp\n",
    "\n",
    "def diff_sage(matrix, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(matrix)[1])] for j in range(np.shape(matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = calc_cell_diff_sage(l, matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(matrix)[0])][\n",
    "                    int(i % np.shape(matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0d27f4c05b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mSEKernelMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_sage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEKernelMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcov_matr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "L = matrix(2, 2, (x1, x1, 0, x1))\n",
    "R = matrix(2, 2, (x2, 0, x2, x2))\n",
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), None], [None, sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "diffed_SE_sage_matrix_kernel = diff_sage(SEKernelMatrix, left_matrix=L, right_matrix=R)\n",
    "pprint.pprint(diffed_SE_sage_matrix_kernel)\n",
    "cov_matr = [[None for i in range(len(X)*len(diffed_SE_sage_matrix_kernel))] for j in range(len(X)*len(diffed_SE_sage_matrix_kernel))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    for row in range(len(diffed_SE_sage_matrix_kernel)):\n",
    "        for col in range(len(diffed_SE_sage_matrix_kernel)):\n",
    "            # Blockwise\n",
    "            cov_matr[int(i/len(X))+row*len(X)][int(i%len(X))+col*len(X)] = diffed_SE_sage_matrix_kernel[row][col].substitute(x1=int(v1), x2=int(v2), l=lengthscale, sigma=variance)\n",
    "            # Interleaved\n",
    "            #cov_matr[int(((i*len(diffed_SE_sage_matrix_kernel))+row)/(len(X)*len(diffed_SE_sage_matrix_kernel)))*2+row][int((i*len(diffed_SE_sage_matrix_kernel))+col)%(len(X)*len(diffed_SE_sage_matrix_kernel))] = float(diffed_SE_sage_matrix_kernel[row][col].substitute(x1=int(v1), x2=int(v2), l=lengthscale, sigma=variance))\n",
    "cov_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "\n",
    "covar_x = covar_module(X)\n",
    "covar_x.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = [[2, 0, -6*e^(-2), 1, e^(-1/2), -e^(-2)],\n",
    " [0, 2, 0, -e^(-1/2), 1, e^(-1/2)],\n",
    " [-6*e^(-2), 0, 2, -5*e^(-2), -e^(-1/2), 1],\n",
    " [1, e^(-1/2), -e^(-2), 1, 0, -3*e^(-2)],\n",
    " [-e^(-1/2), 1, e^(-1/2), 0, 1, 0],\n",
    " [-5*e^(-2), -e^(-1/2), 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = [[2, 0, -6*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 2, 0, 0, 1, 0],\n",
    " [-6*e^(-2), 0, 2, -3*e^(-2), 0, 1],\n",
    " [1, 0, -3*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 1, 0, 0, 1, 0],\n",
    " [-3*e^(-2), 0, 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = torch.Tensor(matr)\n",
    "import pprint\n",
    "pprint.pprint(matr)\n",
    "print(matr[0::3, 0::3])\n",
    "H_x = 3\n",
    "torch.vstack([torch.hstack([matr[k::H_x, l::H_x] for l in range(H_x)]) for k in range(H_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968eb98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = var('a, b, c, d')\n",
    "A = matrix(2,2, (a, b, c, d))\n",
    "B = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "C = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "print(A)\n",
    "print(B)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2885ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d2cc4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = ['a', 'b', 'c']\n",
    "y = x                 # x and y reference the same object\n",
    "z = ['a', 'b', 'c']   # x and z reference different objects\n",
    "#z\n",
    "\n",
    "\n",
    "print(x is z)\n",
    "z = x\n",
    "print(x is z)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
