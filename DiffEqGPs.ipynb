{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from kernels import *\n",
    "import pdb\n",
    "import gpytorch\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(float(0), float(1), int(50))\n",
    "one = torch.sin(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "two = torch.cos(train_x * (float(2) * math.pi)) + torch.randn(train_x.size()) * float(0.2)\n",
    "train_y = torch.stack([one, two], int(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8734672a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5dedb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all kernels: [Diff_SE_kernel()]\n"
     ]
    }
   ],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks=2\n",
    "        )\n",
    "        kernel = Diff_SE_kernel()\n",
    "        kernel2 = Diff_SE_kernel()\n",
    "        q, dx1, dx2 = var('q, dx1, dx2')\n",
    "        L = matrix(2, 2, (1, dx1, 0, dx1))\n",
    "        R = matrix(2, 2, (1, 0, dx2, dx2))\n",
    "        p = DiffMatrixKernel([[kernel, None], [None, kernel]])\n",
    "        self.covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "        #kernel0 = Diff_SE_kernel()\n",
    "        #kernel1 = Diff_SE_kernel()\n",
    "        #kernel2 = Diff_SE_kernel()\n",
    "        #self.covar_module = MatrixKernel([[kernel0, None], [None, kernel2]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(f\"{covar_x.detach().evaluate()}\")\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x, validate_args=True)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0a9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([0., 0.], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([0.], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.1000, -0.1000], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.1000], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.2000, -0.2000], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.2000], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.3000, -0.3000], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.3000], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.4000, -0.3999], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.4000], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.4999, -0.4997], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.4998], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.5998, -0.5994], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.5996], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.6995, -0.6990], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.6992], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.7989, -0.7982], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.7986], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.8980, -0.8971], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.8976], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-0.9967, -0.9954], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-0.9961], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.0946, -1.0932], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.0939], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.1917, -1.1901], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.1909], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.2876, -1.2860], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.2869], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.3820, -1.3808], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.3814], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.4745, -1.4740], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.4743], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.5647, -1.5655], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.5651], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.6520, -1.6549], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.6534], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.7358, -1.7418], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.7387], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.8152, -1.8259], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.8203], requires_grad=True))\n",
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]],\n",
      "       grad_fn=<CopySlices>)\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = int(2) if smoke_test else int(20)\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(0.1))  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    for parameter in model.named_parameters():\n",
    "        print(parameter)\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f  variance: %.3f noise: %.3f' % (\n",
    "    #    i + 1, training_iter, loss.item(),\n",
    "    #    model.covar_module.length.item(),\n",
    "    #    model.covar_module.var.item(),\n",
    "    #    model.likelihood.noise.item()\n",
    "    #))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75730997",
   "metadata": {},
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1b8824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('likelihood.raw_task_noises', Parameter containing:\n",
      "tensor([-1.8895, -1.9068], requires_grad=True))\n",
      "('likelihood.raw_noise', Parameter containing:\n",
      "tensor([-1.8978], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c869eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9975, 0.9994, 1.0000]])\n",
      "Symmetric result:\n",
      "tensor([[2.0000, 1.9992, 1.9967,  ..., 0.0505, 0.0250, 0.0000],\n",
      "        [1.9992, 2.0000, 1.9992,  ..., 0.0764, 0.0505, 0.0250],\n",
      "        [1.9967, 1.9992, 2.0000,  ..., 0.1027, 0.0764, 0.0505],\n",
      "        ...,\n",
      "        [0.0505, 0.0764, 0.1027,  ..., 1.0000, 0.9994, 0.9975],\n",
      "        [0.0250, 0.0505, 0.0764,  ..., 0.9994, 1.0000, 0.9994],\n",
      "        [0.0000, 0.0250, 0.0505,  ..., 0.9975, 0.9994, 1.0000]])\n",
      "Interleaved result:\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]])\n",
      "tensor([[2.0000, 1.0000, 1.9992,  ..., 0.0250, 0.6065, 0.0000],\n",
      "        [1.0000, 1.0000, 0.9994,  ..., 0.0250, 0.0000, 0.0000],\n",
      "        [1.9992, 0.9994, 2.0000,  ..., 0.0505, 0.6439, 0.0250],\n",
      "        ...,\n",
      "        [0.0250, 0.0250, 0.0505,  ..., 1.0000, 0.9994, 0.9994],\n",
      "        [0.6065, 0.0000, 0.6439,  ..., 0.9994, 2.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0250,  ..., 0.9994, 1.0000, 1.0000]])\n",
      "Result:\n",
      "tensor([[ 2.0000,  1.9992,  1.9967,  ..., -0.4256, -0.4165, -0.4060],\n",
      "        [ 1.9992,  2.0000,  1.9992,  ..., -0.4297, -0.4212, -0.4114],\n",
      "        [ 1.9967,  1.9992,  2.0000,  ..., -0.4333, -0.4256, -0.4165],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.9975,  0.9900],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.9975,  1.0000,  0.9975],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.9900,  0.9975,  1.0000]])\n",
      "Symmetric result:\n",
      "tensor([[ 2.0000,  1.9992,  1.9967,  ..., -0.4256, -0.4165, -0.4060],\n",
      "        [ 1.9992,  2.0000,  1.9992,  ..., -0.4297, -0.4212, -0.4114],\n",
      "        [ 1.9967,  1.9992,  2.0000,  ..., -0.4333, -0.4256, -0.4165],\n",
      "        ...,\n",
      "        [-0.4256, -0.4297, -0.4333,  ...,  1.0000,  0.9975,  0.9900],\n",
      "        [-0.4165, -0.4212, -0.4256,  ...,  0.9975,  1.0000,  0.9975],\n",
      "        [-0.4060, -0.4114, -0.4165,  ...,  0.9900,  0.9975,  1.0000]])\n",
      "Interleaved result:\n",
      "tensor([[ 2.0000,  1.0000,  1.9992,  ..., -0.4165, -0.2707, -0.4060],\n",
      "        [ 1.0000,  1.0000,  0.9994,  ..., -0.4165, -0.4060, -0.4060],\n",
      "        [ 1.9992,  0.9994,  2.0000,  ..., -0.4212, -0.2704, -0.4114],\n",
      "        ...,\n",
      "        [-0.4165, -0.4165, -0.4212,  ...,  1.0000,  0.9975,  0.9975],\n",
      "        [-0.2707, -0.4060, -0.2704,  ...,  0.9975,  2.0000,  1.0000],\n",
      "        [-0.4060, -0.4060, -0.4114,  ...,  0.9975,  1.0000,  1.0000]])\n",
      "tensor([[ 2.0000,  1.0000,  1.9992,  ..., -0.4165, -0.2707, -0.4060],\n",
      "        [ 1.0000,  1.0000,  0.9994,  ..., -0.4165, -0.4060, -0.4060],\n",
      "        [ 1.9992,  0.9994,  2.0000,  ..., -0.4212, -0.2704, -0.4114],\n",
      "        ...,\n",
      "        [-0.4165, -0.4165, -0.4212,  ...,  1.0000,  0.9975,  0.9975],\n",
      "        [-0.2707, -0.4060, -0.2704,  ...,  0.9975,  2.0000,  1.0000],\n",
      "        [-0.4060, -0.4060, -0.4114,  ...,  0.9975,  1.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "\n",
    "number_of_samples = int(50)\n",
    "# Make predictions\n",
    "with torch.no_grad():#, gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(float(0), float(2), number_of_samples)\n",
    "    #pdb.set_trace()\n",
    "    outputs = model(test_x)\n",
    "    predictions = likelihood(outputs)\n",
    "    \n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "#print(mean)\n",
    "#print(lower)\n",
    "#print(upper)\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "#dims = int(2)\n",
    "#indices = [list(range(i, len(train_y), dims)) for i in range(dims)]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b79859",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4df72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a03a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Observed Values (Likelihood)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (y1_ax, y2_ax) = plt.subplots(int(1), int(2), figsize=(int(8), int(3)))\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-3, 8])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-3, 8])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf73a6c3",
   "metadata": {},
   "source": [
    "# Test Diffable SE Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b432934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([int(1), int(2), int(3)])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46856bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0, -0.4060058497098381],\n",
       " [0.0, 1.0, 0.0],\n",
       " [-0.4060058497098381, 0.0, 1.0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SE(x1, x2, l, sigma) = sigma^2*exp(-(x1-x2)^2/(2*l^2))\n",
    "cov_matr = [[None for i in range(len(X))] for j in range(len(X))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    cov_matr[int(i/len(X))][int(i%len(X))] = float(SE.diff(x2).diff(x1)(int(v1), int(v2), lengthscale, variance))\n",
    "cov_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bee06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sigma^2, e^(-1/2*(x1 - x2)^2/l^2)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4620c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.6065, -0.1353],\n",
       "        [-0.6065,  1.0000,  0.6065],\n",
       "        [-0.6767, -0.6065,  1.0000]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Diff_SE_kernel(var=int(variance), length=int(lengthscale))\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx2\n",
    "right_poly = dx1 \n",
    "diffed_kernel = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "left_poly = dx2\n",
    "right_poly = 1\n",
    "diffed_kernel2 = a.diff(left_poly=left_poly, right_poly=right_poly, left_d_var=var('dx2'), right_d_var=var('dx1'))\n",
    "diffed_kernel(X).evaluate() + diffed_kernel2(X).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff(L, M, R, context=None):\n",
    "    len_M = np.shape(M)[0]\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "       map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                if m_elem is not None:\n",
    "                    temp = l_elem * m_elem*r_elem\n",
    "                    #temp = l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                #if M_transpose[int(j/len_M)][j % len_M] is not None:\n",
    "                    temp += l_elem * m_elem*r_elem\n",
    "                    #temp += l_elem * M_transpose[int(j/len_M)][j % len_M]*r_elem\n",
    "                else:\n",
    "                    pass\n",
    "    return temp.simplify_full()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a14736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[l_11 l_12 l_13]\n",
      "[l_21 l_22 l_23]\n",
      "[l_31 l_32 l_33]\n",
      "[m_11 m_12 m_13]\n",
      "[m_21 m_22 m_23]\n",
      "[m_31 m_32 m_33]\n",
      "[r_11 r_12 r_13]\n",
      "[r_21 r_22 r_23]\n",
      "[r_31 r_32 r_33]\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_11 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_21 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_31\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_12 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_22 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_32\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_13 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_23 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_33\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_11 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_21 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_31\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_12 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_22 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_32\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_13 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_23 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_33\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_11 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_21 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_31\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_12 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_22 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_32\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_13 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_23 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_33\n",
      "\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_11 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_21 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_12 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_22 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_11*m_11 + l_12*m_21 + l_13*m_31)*r_13 + (l_11*m_12 + l_12*m_22 + l_13*m_32)*r_23 + (l_11*m_13 + l_12*m_23 + l_13*m_33)*r_33\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_11 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_21 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_12 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_22 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_21*m_11 + l_22*m_21 + l_23*m_31)*r_13 + (l_21*m_12 + l_22*m_22 + l_23*m_32)*r_23 + (l_21*m_13 + l_22*m_23 + l_23*m_33)*r_33\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_11 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_21 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_31\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_12 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_22 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_32\n",
      "\n",
      "\n",
      "(l_31*m_11 + l_32*m_21 + l_33*m_31)*r_13 + (l_31*m_12 + l_32*m_22 + l_33*m_32)*r_23 + (l_31*m_13 + l_32*m_23 + l_33*m_33)*r_33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimension = 3\n",
    "length = dimension*dimension +1\n",
    "L_list = [var(f'l_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "M_list = [var(f'm_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "R_list = [var(f'r_{i}{j}') for i in range(1, dimension+1) for j in range(1, dimension+1)]\n",
    "L = matrix(dimension, dimension, L_list)\n",
    "M = matrix(dimension, dimension, M_list)\n",
    "R = matrix(dimension, dimension, R_list)\n",
    "print(L)\n",
    "print(M)\n",
    "print(R)\n",
    "row = 0\n",
    "col = 0\n",
    "for row in range(dimension):\n",
    "    for col in range(dimension):\n",
    "        print((L*M*R)[row][col])\n",
    "print(\"\\n\\n\")\n",
    "for i, (l, r) in enumerate(itertools.product(L.rows(), R.columns())):\n",
    "\n",
    "    print(calc_cell_diff(l, M, r))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cbb4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cell_diff_sage(L, M, R, context=None):\n",
    "    temp = None\n",
    "    # https://stackoverflow.com/questions/6473679/transpose-list-\n",
    "    # of-lists\n",
    "    M_transpose = list(\n",
    "        map(list, itertools.zip_longest(*M, fillvalue=None)))\n",
    "    # Every row in 'M' is combined with each elem of the row given in 'R'\n",
    "    # Or: For each elemtn in row 'R' combine with 'row_M'\n",
    "    for r_elem, row_M in zip(R, M_transpose):\n",
    "        # Each element in L gets exactly one element in 'row_M' to multiply\n",
    "        # Or: Combine each element in row_M with exactly one element in 'L'\n",
    "        for l_elem, m_elem in zip(L, row_M):\n",
    "            if temp is None:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp = m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp = m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp = m_elem.diff(l_elem)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if m_elem is not None:\n",
    "                    if not l_elem == 0 and not r_elem == 0:\n",
    "                        temp += m_elem.diff(l_elem).diff(r_elem)\n",
    "                    #elif l_elem == 0 and not r_elem == 0:\n",
    "                    #    temp += m_elem.diff(r_elem)\n",
    "                    #elif not l_elem == 0 and r_elem == 0:\n",
    "                    #    temp += m_elem.diff(l_elem)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "    return temp\n",
    "\n",
    "def diff_sage(matrix, left_matrix=None, right_matrix=None):\n",
    "    # iterate left matrix by rows and right matrix by columns and call the\n",
    "    # respective diff command of the kernels with the row/cols as params\n",
    "    kernel = MatrixKernel(None)\n",
    "    output_matrix = [[0 for i in range(np.shape(matrix)[1])] for j in range(np.shape(matrix)[0])]\n",
    "    for i, (l, r) in enumerate(itertools.product(left_matrix.rows(), right_matrix.columns())):\n",
    "        res = calc_cell_diff_sage(l, matrix, r, context=kernel)\n",
    "        output_matrix[int(i/np.shape(matrix)[0])][\n",
    "                    int(i % np.shape(matrix)[0])]  = res\n",
    "    kernel.set_matrix(output_matrix)\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f7f9d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0d27f4c05b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mSEKernelMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_sage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEKernelMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcov_matr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffed_SE_sage_matrix_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "L = matrix(2, 2, (x1, x1, 0, x1))\n",
    "R = matrix(2, 2, (x2, 0, x2, x2))\n",
    "x1, x2, l, sigma = var('x1, x2, l, sigma')\n",
    "lengthscale = 1\n",
    "variance = 1\n",
    "SEKernelMatrix = [[sigma^2*exp(-(x1-x2)^2/(2*l^2)), None], [None, sigma^2*exp(-(x1-x2)^2/(2*l^2))]]\n",
    "diffed_SE_sage_matrix_kernel = diff_sage(SEKernelMatrix, left_matrix=L, right_matrix=R)\n",
    "pprint.pprint(diffed_SE_sage_matrix_kernel)\n",
    "cov_matr = [[None for i in range(len(X)*len(diffed_SE_sage_matrix_kernel))] for j in range(len(X)*len(diffed_SE_sage_matrix_kernel))]\n",
    "for i, (v1, v2) in enumerate(product(X, X)):\n",
    "    for row in range(len(diffed_SE_sage_matrix_kernel)):\n",
    "        for col in range(len(diffed_SE_sage_matrix_kernel)):\n",
    "            # Blockwise\n",
    "            cov_matr[int(i/len(X))+row*len(X)][int(i%len(X))+col*len(X)] = diffed_SE_sage_matrix_kernel[row][col].substitute(x1=int(v1), x2=int(v2), l=lengthscale, sigma=variance)\n",
    "            # Interleaved\n",
    "            #cov_matr[int(((i*len(diffed_SE_sage_matrix_kernel))+row)/(len(X)*len(diffed_SE_sage_matrix_kernel)))*2+row][int((i*len(diffed_SE_sage_matrix_kernel))+col)%(len(X)*len(diffed_SE_sage_matrix_kernel))] = float(diffed_SE_sage_matrix_kernel[row][col].substitute(x1=int(v1), x2=int(v2), l=lengthscale, sigma=variance))\n",
    "cov_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2224cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Diff_SE_kernel()\n",
    "kernel2 = Diff_SE_kernel()\n",
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "L = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "\n",
    "p = DiffMatrixKernel([[kernel, None], [None, kernel2]])\n",
    "covar_module = p.diff(left_matrix=L, right_matrix=R)\n",
    "\n",
    "covar_x = covar_module(X)\n",
    "covar_x.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = [[2, 0, -6*e^(-2), 1, e^(-1/2), -e^(-2)],\n",
    " [0, 2, 0, -e^(-1/2), 1, e^(-1/2)],\n",
    " [-6*e^(-2), 0, 2, -5*e^(-2), -e^(-1/2), 1],\n",
    " [1, e^(-1/2), -e^(-2), 1, 0, -3*e^(-2)],\n",
    " [-e^(-1/2), 1, e^(-1/2), 0, 1, 0],\n",
    " [-5*e^(-2), -e^(-1/2), 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = [[2, 0, -6*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 2, 0, 0, 1, 0],\n",
    " [-6*e^(-2), 0, 2, -3*e^(-2), 0, 1],\n",
    " [1, 0, -3*e^(-2), 1, 0, -3*e^(-2)],\n",
    " [0, 1, 0, 0, 1, 0],\n",
    " [-3*e^(-2), 0, 1, -3*e^(-2), 0, 1]]\n",
    "\n",
    "matr = torch.Tensor(matr)\n",
    "import pprint\n",
    "pprint.pprint(matr)\n",
    "print(matr[0::3, 0::3])\n",
    "H_x = 3\n",
    "torch.vstack([torch.hstack([matr[k::H_x, l::H_x] for l in range(H_x)]) for k in range(H_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760ceb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testobject():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def printVal(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = testobject(42)\n",
    "t2 = testobject(21)\n",
    "t3 = testobject(17)\n",
    "l = [[t1, t2], [t2, t3]]\n",
    "print(l)\n",
    "t2.setVal(170)\n",
    "print(l[0][1].printVal())\n",
    "print(l[1][0].printVal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, dx1, dx2 = var('q, dx1, dx2')\n",
    "left_poly = dx1\n",
    "right_poly = dx2\n",
    "L = matrix(2, 2, (dx1, 0, 0, dx1))\n",
    "R = matrix(2, 2, (dx2, 0, 0, dx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.diff(left_matrix=L, right_matrix=R).forward(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a46303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, q, dx1, dx2 = var('w, q, dx1, dx2')\n",
    "a = dx1^2\n",
    "#a.degree(dx1)\n",
    "a.operands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[int(1), int(2), int(3)], [int(4), int(5), int(6)], [int(7), int(8), int(9)]])\n",
    "for i, row in enumerate(a):\n",
    "    for j, elem in enumerate(row[i:]):\n",
    "        print(f\"row: {i}, col: {i+j}\")\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d80634",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = var('a, b, c, d')\n",
    "A = matrix(2,2, (a, b, c, d))\n",
    "B = matrix(2, 2, (dx1, dx1, 0, dx1))\n",
    "C = matrix(2, 2, (dx2, 0, dx2, dx2))\n",
    "print(A)\n",
    "print(B)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0d93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['a', 'b', 'c']\n",
    "y = x                 # x and y reference the same object\n",
    "z = ['a', 'b', 'c']   # x and z reference different objects\n",
    "#z\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
